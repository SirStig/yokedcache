{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"YokedCache - Python Caching Library for FastAPI","text":"<p>High-Performance Redis Caching with Auto-Invalidation for Modern Python Applications</p> <p>YokedCache is a powerful, async-first Python caching library that brings enterprise-grade Redis caching capabilities to FastAPI applications. With multi-backend support, intelligent auto-invalidation, and production-ready monitoring, it's designed to scale from development to enterprise deployment.</p>"},{"location":"#why-choose-yokedcache-for-python-fastapi-development","title":"Why Choose YokedCache for Python FastAPI Development?","text":"<ul> <li>\ud83d\ude80 Performance: Async-first design with Redis connection pooling and batch operations</li> <li>\ud83d\udd27 Flexible: Multiple backends (Memory, Redis, Memcached) with unified Python API</li> <li>\ud83e\udde0 Intelligent: Auto-invalidation, vector search caching, and fuzzy matching</li> <li>\ud83d\udcca Observable: Built-in metrics, monitoring, and comprehensive CLI tools</li> <li>\ud83d\udee1\ufe0f Production-Ready: Health checks, error handling, and security features</li> <li>\ud83d\udd10 Resilient: Circuit breaker, retry logic, and graceful fallbacks v0.2.1</li> <li>\u26a1 Enhanced: Smart async/sync context handling and performance optimizations v0.2.1</li> <li>\ud83c\udf10 Advanced Patterns: HTTP middleware, single-flight protection, stale-while-revalidate v0.3.0</li> <li>\ud83d\udd0d Observability: OpenTelemetry tracing and per-prefix backend routing v0.3.0</li> </ul>"},{"location":"#quick-start-python-fastapi-redis-caching","title":"Quick Start - Python FastAPI Redis Caching","text":"<pre><code># Install with all features\npip install yokedcache[full]\n</code></pre> <pre><code>from fastapi import FastAPI, Depends\nfrom yokedcache import YokedCache, cached_dependency\n\napp = FastAPI()\ncache = YokedCache()  # Uses Redis by default\n\n# Cache database dependencies automatically\ncached_get_db = cached_dependency(get_db, cache=cache, ttl=300)\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db=Depends(cached_get_db)):\n    # Database queries are automatically cached and invalidated\n    return db.query(User).filter(User.id == user_id).first()\n</code></pre>"},{"location":"#documentation-guide","title":"Documentation Guide","text":""},{"location":"#start-here","title":"\ud83d\udcda Start Here","text":"<p>Perfect for newcomers and quick setups:</p> <ul> <li>Getting Started - Installation, first setup, and basic usage</li> <li>Core Concepts - Keys, TTL, tags, serialization, and architecture</li> <li>Configuration Guide - Complete configuration reference and best practices</li> </ul>"},{"location":"#usage-guide","title":"\ud83d\udcbb Usage Guide","text":"<p>Learn different ways to use YokedCache:</p> <ul> <li>Usage Patterns - Function caching, auto-invalidation, and fuzzy search</li> <li>FastAPI Integration - Complete FastAPI tutorial with examples</li> <li>SQLAlchemy Integration - Database ORM integration patterns</li> </ul>"},{"location":"#advanced-features","title":"\ud83d\udd0d Advanced Features","text":"<p>Powerful capabilities for complex use cases:</p> <ul> <li>Backends &amp; Setup - Memory, Redis, Memcached backends with setup guides</li> <li>Vector Search - Semantic similarity search capabilities</li> <li>Monitoring &amp; Health - Comprehensive monitoring, health checks, and alerting v0.2.1</li> <li>Advanced Caching Patterns - HTTP middleware, SWR, single-flight protection v0.3.0</li> </ul>"},{"location":"#reference","title":"\ud83d\udcd6 Reference","text":"<p>Detailed technical documentation:</p> <ul> <li>CLI Tool - Complete command-line interface guide</li> <li>Performance Guide - Optimization and tuning</li> <li>Security Guide - Security best practices</li> <li>Testing Guide - Testing patterns and best practices</li> <li>Troubleshooting - Common issues and solutions</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#multi-backend-architecture","title":"Multi-Backend Architecture","text":"<p>Switch between backends without changing your code: - Memory: Fast in-memory caching with LRU eviction - Redis: Distributed caching with clustering and persistence - Memcached: Lightweight distributed caching</p>"},{"location":"#intelligent-caching","title":"Intelligent Caching","text":"<ul> <li>Auto-Invalidation: Automatically invalidate cache on database writes</li> <li>Tag-Based Grouping: Group related cache entries for bulk operations</li> <li>Pattern Matching: Wildcard-based key operations and cleanup</li> <li>TTL with Jitter: Prevent thundering herd problems</li> </ul>"},{"location":"#advanced-search","title":"Advanced Search","text":"<ul> <li>Vector Similarity: Semantic search using TF-IDF and multiple distance metrics</li> <li>Fuzzy Matching: Find approximate matches across cached keys</li> <li>Real-time Indexing: Automatic search index maintenance</li> </ul>"},{"location":"#production-features","title":"Production Features","text":"<ul> <li>Metrics &amp; Monitoring: Prometheus, StatsD, and custom collectors</li> <li>Health Checks: Monitor cache and backend health</li> <li>Security: TLS support, input validation, and access controls</li> <li>CLI Tools: Comprehensive command-line interface</li> </ul>"},{"location":"#installation-options","title":"Installation Options","text":"<pre><code># Basic installation\npip install yokedcache\n\n# Full installation (recommended)\npip install yokedcache[full]\n\n# Specific features\npip install yokedcache[vector]      # Vector search\npip install yokedcache[monitoring]  # Prometheus &amp; StatsD\npip install yokedcache[memcached]   # Memcached backend\npip install yokedcache[fuzzy]       # Fuzzy search\npip install yokedcache[disk]        # DiskCache backend (v0.3.0)\npip install yokedcache[tracing]     # OpenTelemetry tracing (v0.3.0)\n</code></pre>"},{"location":"#recent-releases","title":"Recent Releases","text":""},{"location":"#v030","title":"v0.3.0","text":"<ul> <li>HTTP Response Middleware: ETag/Cache-Control headers with 304 Not Modified responses</li> <li>Single-Flight Protection: Prevents cache stampede with automatic deduplication</li> <li>Stale-While-Revalidate: Serve stale data while refreshing in background</li> <li>Stale-If-Error: Fallback to cached data during service failures</li> <li>Per-Prefix Routing: Shard cache keys across multiple backends by prefix</li> <li>OpenTelemetry Integration: Distributed tracing with spans and metrics</li> <li>New Backends: DiskCache and SQLite backends for persistent caching</li> </ul>"},{"location":"#v021","title":"v0.2.1","text":"<ul> <li>Production Resilience: Circuit breaker, retry logic, and graceful fallbacks</li> <li>Enhanced Async/Sync Support: Smart context detection and explicit method variants</li> </ul>"},{"location":"#v020","title":"v0.2.0","text":"<ul> <li>Multi-Backend Support: Memory, Redis, and Memcached backends</li> <li>Vector Search: Semantic similarity search capabilities</li> <li>Production Monitoring: Prometheus and StatsD integration</li> <li>Enhanced CLI: CSV export, file output, and improved UX</li> <li>Comprehensive Testing: 200+ tests with complete coverage</li> </ul> <p>Ready to get started? Begin with our Getting Started Guide for a step-by-step introduction.</p>"},{"location":"backends/","title":"Multi-Backend Architecture","text":"<p>YokedCache 0.2.0 introduces a flexible multi-backend architecture that allows you to choose the best caching solution for your specific needs. Whether you need the speed of in-memory caching, the persistence of Redis, or the simplicity of Memcached, YokedCache provides a unified interface.</p>"},{"location":"backends/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Available Backends</li> <li>Backend Selection</li> <li>Configuration</li> <li>Performance Characteristics</li> <li>Migration Guide</li> </ul>"},{"location":"backends/#overview","title":"Overview","text":"<p>The multi-backend system is built around a common <code>CacheBackend</code> interface that ensures consistent behavior across all implementations. This means you can switch between backends without changing your application code.</p>"},{"location":"backends/#key-benefits","title":"Key Benefits","text":"<ul> <li>Flexibility: Choose the right backend for each use case</li> <li>Consistency: Unified API across all backends</li> <li>Performance: Optimized implementations for each backend type</li> <li>Scalability: Easy backend switching as requirements change</li> <li>Testing: Use memory backend for tests, Redis for production</li> </ul>"},{"location":"backends/#available-backends","title":"Available Backends","text":""},{"location":"backends/#memory-backend","title":"Memory Backend","text":"<p>In-memory caching with LRU eviction and TTL support.</p> <p>Use Cases: - Single-server applications - Development and testing - Fast access to frequently used data - When data persistence is not required</p> <p>Features: - Thread-safe operations - LRU eviction when max size reached - TTL expiration support - Tag-based invalidation - Pattern-based invalidation - Fuzzy search capabilities</p> <p>Configuration: <pre><code>from yokedcache import YokedCache, CacheConfig\nfrom yokedcache.backends import MemoryBackend\n\n# Basic configuration\nconfig = CacheConfig(\n    backend=MemoryBackend(\n        max_size=10000,        # Maximum number of keys\n        key_prefix=\"myapp\"\n    )\n)\n\ncache = YokedCache(config)\n</code></pre></p> <p>Advanced Configuration: <pre><code>backend = MemoryBackend(\n    max_size=50000,\n    key_prefix=\"prod\",\n    default_ttl=3600,         # 1 hour default TTL\n    cleanup_interval=300      # Clean expired keys every 5 minutes\n)\n</code></pre></p>"},{"location":"backends/#redis-backend","title":"Redis Backend","text":"<p>Distributed caching with Redis for scalable applications.</p> <p>Use Cases: - Multi-server applications - Shared cache across services - High availability requirements - Large datasets that don't fit in memory</p> <p>Features: - Connection pooling - Persistence options - Clustering support - Pub/sub capabilities - Advanced data structures - Production-ready reliability</p> <p>Configuration: <pre><code>from yokedcache.backends import RedisBackend\n\n# Basic Redis configuration\nbackend = RedisBackend(\n    redis_url=\"redis://localhost:6379/0\",\n    key_prefix=\"myapp\",\n    connection_pool_size=20\n)\n\n# With authentication and SSL\nbackend = RedisBackend(\n    redis_url=\"rediss://username:password@redis.example.com:6380/0\",\n    key_prefix=\"secure_app\",\n    ssl_cert_reqs=\"required\",\n    ssl_ca_certs=\"/path/to/ca-certificates.crt\"\n)\n</code></pre></p> <p>Connection Options: <pre><code>backend = RedisBackend(\n    host=\"localhost\",\n    port=6379,\n    db=0,\n    password=\"secret\",\n    socket_timeout=5.0,\n    socket_connect_timeout=5.0,\n    retry_on_timeout=True,\n    health_check_interval=30\n)\n</code></pre></p>"},{"location":"backends/#memcached-backend","title":"Memcached Backend","text":"<p>Lightweight, distributed memory caching system.</p> <p>Use Cases: - Simple key-value caching - Legacy system integration - When you need a proven, stable solution - Memory-constrained environments</p> <p>Features: - Lightweight protocol - Automatic load balancing - Consistent hashing - Binary protocol support - Multi-server support</p> <p>Configuration: <pre><code>from yokedcache.backends import MemcachedBackend\n\n# Single server\nbackend = MemcachedBackend(\n    servers=[\"localhost:11211\"],\n    key_prefix=\"myapp\"\n)\n\n# Multiple servers with weights\nbackend = MemcachedBackend(\n    servers=[\n        (\"cache1.example.com:11211\", 3),  # Weight 3\n        (\"cache2.example.com:11211\", 1),  # Weight 1\n    ],\n    binary=True,              # Use binary protocol\n    behaviors={\n        \"tcp_nodelay\": True,\n        \"ketama\": True,       # Consistent hashing\n    }\n)\n</code></pre></p>"},{"location":"backends/#backend-selection","title":"Backend Selection","text":""},{"location":"backends/#decision-matrix","title":"Decision Matrix","text":"Feature Memory Redis Memcached Performance Excellent Very Good Very Good Persistence None Optional None Distribution Single Node Multi-Node Multi-Node Memory Usage Process RAM Dedicated Dedicated Complexity Low Medium Low Features Basic Advanced Basic"},{"location":"backends/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"backends/#memory-backend_1","title":"Memory Backend","text":"<ul> <li>Latency: &lt; 1\u03bcs</li> <li>Throughput: 1M+ ops/sec</li> <li>Memory: Uses process heap</li> <li>Scalability: Single process only</li> </ul>"},{"location":"backends/#redis-backend_1","title":"Redis Backend","text":"<ul> <li>Latency: 0.1-1ms (local), 1-10ms (network)</li> <li>Throughput: 100K+ ops/sec</li> <li>Memory: Dedicated Redis memory</li> <li>Scalability: Horizontal with clustering</li> </ul>"},{"location":"backends/#memcached-backend_1","title":"Memcached Backend","text":"<ul> <li>Latency: 0.5-2ms (network)</li> <li>Throughput: 50K+ ops/sec</li> <li>Memory: Dedicated Memcached memory</li> <li>Scalability: Horizontal with consistent hashing</li> </ul>"},{"location":"backends/#configuration","title":"Configuration","text":""},{"location":"backends/#environment-based-configuration","title":"Environment-Based Configuration","text":"<pre><code>import os\nfrom yokedcache import YokedCache, CacheConfig\nfrom yokedcache.backends import MemoryBackend, RedisBackend\n\ndef create_cache():\n    \"\"\"Create cache based on environment.\"\"\"\n    env = os.getenv(\"ENVIRONMENT\", \"development\")\n\n    if env == \"development\":\n        backend = MemoryBackend(max_size=1000)\n    elif env == \"testing\":\n        backend = MemoryBackend(max_size=100)\n    else:  # production\n        backend = RedisBackend(\n            redis_url=os.getenv(\"REDIS_URL\", \"redis://localhost:6379/0\"),\n            connection_pool_size=int(os.getenv(\"REDIS_POOL_SIZE\", \"20\"))\n        )\n\n    config = CacheConfig(backend=backend)\n    return YokedCache(config)\n</code></pre>"},{"location":"backends/#yaml-configuration","title":"YAML Configuration","text":"<pre><code># config.yaml\ncache:\n  development:\n    backend: memory\n    memory:\n      max_size: 1000\n      key_prefix: \"dev\"\n\n  production:\n    backend: redis\n    redis:\n      url: \"redis://prod-redis:6379/0\"\n      pool_size: 50\n      key_prefix: \"prod\"\n\n  testing:\n    backend: memory\n    memory:\n      max_size: 100\n      key_prefix: \"test\"\n</code></pre> <p>Loading YAML configuration: <pre><code>import yaml\nfrom yokedcache import YokedCache, CacheConfig\nfrom yokedcache.backends import MemoryBackend, RedisBackend\n\ndef load_cache_from_config(config_file: str, environment: str):\n    \"\"\"Load cache configuration from YAML file.\"\"\"\n    with open(config_file) as f:\n        config = yaml.safe_load(f)\n\n    cache_config = config[\"cache\"][environment]\n    backend_type = cache_config[\"backend\"]\n\n    if backend_type == \"memory\":\n        backend = MemoryBackend(**cache_config[\"memory\"])\n    elif backend_type == \"redis\":\n        backend = RedisBackend(**cache_config[\"redis\"])\n    else:\n        raise ValueError(f\"Unknown backend: {backend_type}\")\n\n    return YokedCache(CacheConfig(backend=backend))\n</code></pre></p>"},{"location":"backends/#runtime-backend-switching","title":"Runtime Backend Switching","text":"<pre><code>class AdaptiveCache:\n    \"\"\"Cache that can switch backends at runtime.\"\"\"\n\n    def __init__(self):\n        self.memory_backend = MemoryBackend(max_size=1000)\n        self.redis_backend = RedisBackend()\n        self.current_backend = self.memory_backend\n\n    async def switch_to_redis(self):\n        \"\"\"Switch to Redis backend.\"\"\"\n        await self.current_backend.disconnect()\n        await self.redis_backend.connect()\n        self.current_backend = self.redis_backend\n\n    async def switch_to_memory(self):\n        \"\"\"Switch to memory backend.\"\"\"\n        await self.current_backend.disconnect()\n        await self.memory_backend.connect()\n        self.current_backend = self.memory_backend\n\n    async def get(self, key: str):\n        \"\"\"Get value using current backend.\"\"\"\n        return await self.current_backend.get(key)\n</code></pre>"},{"location":"backends/#migration-guide","title":"Migration Guide","text":""},{"location":"backends/#from-single-backend-to-multi-backend","title":"From Single Backend to Multi-Backend","text":"<p>Before (v0.1.x): <pre><code>from yokedcache import YokedCache, CacheConfig\n\nconfig = CacheConfig(redis_url=\"redis://localhost:6379/0\")\ncache = YokedCache(config)\n</code></pre></p> <p>After (v0.2.0): <pre><code>from yokedcache import YokedCache, CacheConfig\nfrom yokedcache.backends import RedisBackend\n\nbackend = RedisBackend(redis_url=\"redis://localhost:6379/0\")\nconfig = CacheConfig(backend=backend)\ncache = YokedCache(config)\n</code></pre></p>"},{"location":"backends/#migrating-data-between-backends","title":"Migrating Data Between Backends","text":"<pre><code>async def migrate_cache_data(source_backend, target_backend):\n    \"\"\"Migrate data from one backend to another.\"\"\"\n    await source_backend.connect()\n    await target_backend.connect()\n\n    try:\n        # Get all keys from source\n        keys = await source_backend.get_all_keys(\"*\")\n\n        migrated = 0\n        for key in keys:\n            value = await source_backend.get(key)\n            if value is not None:\n                await target_backend.set(key, value)\n                migrated += 1\n\n        print(f\"Migrated {migrated} keys successfully\")\n\n    finally:\n        await source_backend.disconnect()\n        await target_backend.disconnect()\n\n# Example usage\nmemory_backend = MemoryBackend()\nredis_backend = RedisBackend()\n\nawait migrate_cache_data(memory_backend, redis_backend)\n</code></pre>"},{"location":"backends/#best-practices","title":"Best Practices","text":""},{"location":"backends/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Use Memory Backend for Tests <pre><code>@pytest.fixture\nasync def cache():\n    backend = MemoryBackend(max_size=100)\n    config = CacheConfig(backend=backend)\n    cache = YokedCache(config)\n    await cache.connect()\n    yield cache\n    await cache.disconnect()\n</code></pre></p> </li> <li> <p>Environment-Specific Backends</p> </li> <li>Development: Memory backend for fast iteration</li> <li>Testing: Memory backend for isolation</li> <li>Staging: Redis backend to match production</li> <li> <p>Production: Redis backend with proper configuration</p> </li> <li> <p>Backend Health Monitoring <pre><code>async def check_backend_health(backend):\n    \"\"\"Check if backend is healthy.\"\"\"\n    try:\n        return await backend.health_check()\n    except Exception as e:\n        logger.error(f\"Backend health check failed: {e}\")\n        return False\n</code></pre></p> </li> <li> <p>Graceful Degradation <pre><code>class ResilientCache:\n    def __init__(self):\n        self.primary = RedisBackend()\n        self.fallback = MemoryBackend(max_size=1000)\n\n    async def get(self, key: str):\n        try:\n            return await self.primary.get(key)\n        except Exception:\n            logger.warning(\"Primary backend failed, using fallback\")\n            return await self.fallback.get(key)\n</code></pre></p> </li> </ol>"},{"location":"backends/#production-considerations","title":"Production Considerations","text":"<ol> <li>Connection Pooling: Use appropriate pool sizes for Redis</li> <li>Memory Management: Monitor memory usage for all backends</li> <li>Error Handling: Implement proper error handling and fallbacks</li> <li>Monitoring: Use the monitoring features to track backend performance</li> <li>Backup Strategies: Plan for data backup with persistent backends</li> </ol>"},{"location":"backends/#redis-setup-configuration","title":"Redis Setup &amp; Configuration","text":""},{"location":"backends/#local-development","title":"Local Development","text":""},{"location":"backends/#using-docker-recommended","title":"Using Docker (Recommended)","text":"<pre><code># Basic Redis setup\ndocker run -d --name redis -p 6379:6379 redis:7\n\n# Redis with persistence\ndocker run -d --name redis -p 6379:6379 \\\n  -v redis-data:/data redis:7 redis-server --appendonly yes\n</code></pre> <p>Then connect with <code>redis://localhost:6379/0</code>.</p>"},{"location":"backends/#native-installation","title":"Native Installation","text":"<p>macOS: <pre><code>brew install redis\nbrew services start redis\n</code></pre></p> <p>Ubuntu/Debian: <pre><code>sudo apt install redis-server\nsudo systemctl start redis-server\n</code></pre></p> <p>Windows: Use Docker or WSL2 with Linux installation.</p> <p>Verify Installation: <pre><code>redis-cli ping\n# Should return: PONG\n</code></pre></p>"},{"location":"backends/#production-deployment","title":"Production Deployment","text":""},{"location":"backends/#cloud-providers","title":"Cloud Providers","text":"<p>AWS ElastiCache: - Create Redis cluster in ElastiCache - Use cluster endpoint: <code>redis://cluster.abc123.cache.amazonaws.com:6379</code> - Enable encryption in transit: <code>rediss://cluster.abc123.cache.amazonaws.com:6380</code></p> <p>Azure Cache for Redis: - Create Redis instance in Azure portal - Use primary connection string: <code>rediss://cache-name.redis.cache.windows.net:6380</code></p> <p>Google Cloud Memorystore: - Create Redis instance in GCP console - Use internal IP: <code>redis://10.0.0.3:6379</code></p>"},{"location":"backends/#tlsssl-configuration","title":"TLS/SSL Configuration","text":"<p>For encrypted connections, use the <code>rediss://</code> protocol:</p> <pre><code>from yokedcache import YokedCache, CacheConfig\n\n# TLS configuration\nconfig = CacheConfig(\n    redis_url=\"rediss://user:pass@my-redis.example.com:6380/0\",\n    connection_pool_kwargs={\n        \"ssl_cert_reqs\": \"required\",\n        \"ssl_ca_certs\": \"/path/to/ca.crt\",\n        \"ssl_check_hostname\": True\n    }\n)\n\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"backends/#authentication","title":"Authentication","text":"<p>Password Authentication: <pre><code>config = CacheConfig(\n    redis_url=\"redis://:mypassword@localhost:6379/0\"\n)\n</code></pre></p> <p>Username/Password (Redis 6+): <pre><code>config = CacheConfig(\n    redis_url=\"redis://username:password@localhost:6379/0\"\n)\n</code></pre></p> <p>ACL Configuration: <pre><code># Create user for YokedCache\nACL SETUSER yokedcache_user on &gt;password123 +@all ~*\n</code></pre></p>"},{"location":"backends/#performance-tuning","title":"Performance Tuning","text":""},{"location":"backends/#redis-configuration","title":"Redis Configuration","text":"<p>Add these settings to <code>redis.conf</code>:</p> <pre><code># Memory optimization\nmaxmemory 2gb\nmaxmemory-policy allkeys-lru\n\n# Network optimization\ntcp-keepalive 300\ntimeout 0\n\n# Persistence (optional)\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# Performance\ntcp-nodelay yes\n</code></pre>"},{"location":"backends/#connection-pool-tuning","title":"Connection Pool Tuning","text":"<pre><code>config = CacheConfig(\n    redis_url=\"redis://localhost:6379/0\",\n    max_connections=100,\n    connection_pool_kwargs={\n        \"socket_keepalive\": True,\n        \"socket_keepalive_options\": {\n            \"TCP_KEEPIDLE\": 1,\n            \"TCP_KEEPINTVL\": 3,\n            \"TCP_KEEPCNT\": 5\n        },\n        \"socket_connect_timeout\": 5,\n        \"socket_timeout\": 5,\n        \"retry_on_timeout\": True,\n        \"health_check_interval\": 30\n    }\n)\n</code></pre>"},{"location":"backends/#connectivity-troubleshooting","title":"Connectivity Troubleshooting","text":""},{"location":"backends/#pre-deployment-checklist","title":"Pre-deployment Checklist","text":"<ul> <li>[ ] Network Access: Security groups/firewalls allow Redis port (6379/6380)</li> <li>[ ] DNS Resolution: Hostname resolves correctly from application servers</li> <li>[ ] Authentication: Credentials are correct and user has necessary permissions</li> <li>[ ] TLS: Certificate validation passes for SSL connections</li> <li>[ ] Latency: Network latency is acceptable (&lt;10ms preferred)</li> <li>[ ] Memory: Redis has sufficient memory for expected cache size</li> </ul>"},{"location":"backends/#connection-testing","title":"Connection Testing","text":"<pre><code>import redis\nimport asyncio\nfrom yokedcache import YokedCache\n\nasync def test_connection():\n    try:\n        cache = YokedCache(redis_url=\"redis://localhost:6379/0\")\n\n        # Test basic connectivity\n        health = await cache.health()\n        print(f\"Health check: {health}\")\n\n        # Test operations\n        await cache.set(\"test_key\", \"test_value\", ttl=60)\n        value = await cache.get(\"test_key\")\n        print(f\"Test operation: {value}\")\n\n        # Test detailed health check\n        detailed = await cache.detailed_health_check()\n        print(f\"Detailed health: {detailed}\")\n\n    except Exception as e:\n        print(f\"Connection failed: {e}\")\n\n# Run test\nasyncio.run(test_connection())\n</code></pre>"},{"location":"backends/#common-issues","title":"Common Issues","text":"Issue Cause Solution Connection refused Redis not running Start Redis service Authentication failed Wrong credentials Check username/password SSL handshake failed Certificate issues Verify TLS configuration Timeout errors Network latency Increase timeouts, check network Memory errors Redis out of memory Increase Redis memory limit <p>For more information about specific backend implementations and advanced configuration options, see the API documentation for each backend class.</p>"},{"location":"cli/","title":"CLI Reference","text":"<p>YokedCache provides a comprehensive command-line interface for cache management, monitoring, and troubleshooting. This guide covers all available commands and their options.</p>"},{"location":"cli/#installation-and-setup","title":"Installation and Setup","text":"<p>The CLI is automatically available after installing YokedCache:</p> <pre><code># Install YokedCache\npip install yokedcache\n\n# Verify CLI installation\nyokedcache --version\n\n# Get help\nyokedcache --help\n</code></pre>"},{"location":"cli/#global-options","title":"Global Options","text":"<p>All commands support these global options:</p> <pre><code>yokedcache [GLOBAL_OPTIONS] COMMAND [COMMAND_OPTIONS]\n\nGlobal Options:\n  --config-file PATH     Configuration file path\n  --redis-url URL        Redis connection URL\n  --key-prefix PREFIX    Key prefix for cache operations\n  --log-level LEVEL      Logging level (DEBUG, INFO, WARNING, ERROR)\n  --help                 Show help message\n  --version              Show version information\n</code></pre>"},{"location":"cli/#core-commands","title":"Core Commands","text":""},{"location":"cli/#ping-test-connection","title":"<code>ping</code> - Test Connection","text":"<p>Test connectivity to your cache backend:</p> <pre><code># Basic connection test\nyokedcache ping\n\n# With custom Redis URL\nyokedcache ping --redis-url redis://localhost:6380/1\n\n# Include response time\nyokedcache ping --show-timing\n\n# Test multiple times\nyokedcache ping --count 5 --interval 1\n</code></pre>"},{"location":"cli/#stats-cache-statistics","title":"<code>stats</code> - Cache Statistics","text":"<p>View detailed cache statistics and performance metrics:</p> <pre><code># Basic statistics\nyokedcache stats\n\n# Watch mode (auto-refresh)\nyokedcache stats --watch\n\n# Custom refresh interval\nyokedcache stats --watch --interval 5\n\n# JSON output\nyokedcache stats --format json\n\n# CSV output for analysis\nyokedcache stats --format csv --output stats.csv\n</code></pre>"},{"location":"cli/#list-list-cache-keys","title":"<code>list</code> - List Cache Keys","text":"<p>List and filter cache keys:</p> <pre><code># List all keys\nyokedcache list\n\n# List with pattern matching\nyokedcache list --pattern \"user:*\"\n\n# List by prefix\nyokedcache list --prefix users:\n\n# List by tags\nyokedcache list --tags user_data,active\n\n# Include values\nyokedcache list --include-values\n\n# Output formats\nyokedcache list --format json --output keys.json\n</code></pre>"},{"location":"cli/#search-fuzzy-search","title":"<code>search</code> - Fuzzy Search","text":"<p>Perform fuzzy search across cache keys:</p> <pre><code># Basic fuzzy search\nyokedcache search \"alice\"\n\n# Adjust similarity threshold\nyokedcache search \"alice\" --threshold 80\n\n# Limit results\nyokedcache search \"alice\" --max-results 10\n\n# Search within specific tags\nyokedcache search \"alice\" --tags users,active\n</code></pre>"},{"location":"cli/#flush-clear-cache-data","title":"<code>flush</code> - Clear Cache Data","text":"<p>Clear cache data in bulk:</p> <pre><code># Flush by tags\nyokedcache flush --tags \"user_data,expired\"\n\n# Flush by pattern\nyokedcache flush --pattern \"temp:*\" --force\n\n# Confirm before flushing\nyokedcache flush --tags \"test_data\" --confirm\n</code></pre>"},{"location":"cli/#export-config-export-configuration","title":"<code>export-config</code> - Export Configuration","text":"<p>Export current configuration:</p> <pre><code># Export to YAML\nyokedcache export-config --output config.yaml\n\n# Export to JSON\nyokedcache export-config --format json --output config.json\n</code></pre>"},{"location":"cli/#warm-cache-warming","title":"<code>warm</code> - Cache Warming","text":"<p>Pre-populate cache with data:</p> <pre><code># Warm from configuration file\nyokedcache warm --config-file warming_config.yaml\n\n# Warm with progress tracking\nyokedcache warm --config-file warming_config.yaml --verbose\n</code></pre>"},{"location":"cli/#cli-cookbook","title":"CLI Cookbook","text":""},{"location":"cli/#monitor-cache-performance","title":"Monitor Cache Performance","text":"<pre><code># Watch cache statistics continuously\nyokedcache stats --watch\n\n# Monitor with custom interval\nyokedcache stats --watch --interval 5\n</code></pre>"},{"location":"cli/#export-configuration","title":"Export Configuration","text":"<pre><code># Export current config to YAML\nyokedcache export-config --output config.yaml\n\n# Export to JSON format\nyokedcache export-config --format json --output config.json\n</code></pre>"},{"location":"cli/#list-keys-by-prefix","title":"List Keys by Prefix","text":"<pre><code># List all user keys\nyokedcache list --prefix users:\n\n# List with pattern matching\nyokedcache list --pattern \"session:*\"\n</code></pre>"},{"location":"cli/#delete-by-pattern","title":"Delete by Pattern","text":"<pre><code># Delete temporary keys (with confirmation)\nyokedcache flush --pattern \"temp:*\" --confirm\n\n# Force delete without confirmation\nyokedcache flush --pattern \"cache:test:*\" --force\n</code></pre>"},{"location":"cli/#invalidate-by-tags","title":"Invalidate by Tags","text":"<pre><code># Clear user data cache\nyokedcache flush --tags \"user_data\" --confirm\n\n# Clear multiple tag categories\nyokedcache flush --tags \"user_data,session_data\" --force\n</code></pre>"},{"location":"cli/#search-cache-contents","title":"Search Cache Contents","text":"<pre><code># Find keys containing \"alice\"\nyokedcache search \"alice\" --threshold 80\n\n# Search with higher precision\nyokedcache search \"alice\" --threshold 90 --max-results 5\n</code></pre>"},{"location":"cli/#output-formats","title":"Output Formats","text":"<p>Most commands support multiple output formats:</p> <ul> <li>table: Human-readable table format (default)</li> <li>json: JSON format for programmatic processing</li> <li>csv: CSV format for data analysis</li> </ul> <p>Example: <pre><code># JSON output for scripting\nyokedcache stats --format json\n\n# CSV output for analysis\nyokedcache list --format csv --output keys.csv\n</code></pre></p>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>Configure CLI behavior:</p> <pre><code># Default Redis URL\nexport YOKEDCACHE_REDIS_URL=\"redis://localhost:6379/0\"\n\n# Default configuration file\nexport YOKEDCACHE_CONFIG_FILE=\"/etc/yokedcache/config.yaml\"\n\n# Default log level\nexport YOKEDCACHE_LOG_LEVEL=\"INFO\"\n</code></pre>"},{"location":"cli/#scripting-and-automation","title":"Scripting and Automation","text":"<p>Commands return standard exit codes for scripting:</p> <ul> <li><code>0</code>: Success</li> <li><code>1</code>: General error</li> <li><code>2</code>: Configuration error</li> <li><code>3</code>: Connection error</li> </ul> <p>Process JSON output with tools like <code>jq</code>:</p> <pre><code># Get cache hit rate\nyokedcache stats --format json | jq '.hit_rate'\n\n# List keys with high TTL\nyokedcache list --format json | jq '.[] | select(.ttl &gt; 3600) | .key'\n</code></pre> <p>The YokedCache CLI provides powerful tools for cache management, monitoring, and troubleshooting.</p>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>YokedCache offers flexible configuration options to adapt to your specific environment and requirements. This guide covers all configuration methods and options.</p>"},{"location":"configuration/#configuration-methods","title":"Configuration Methods","text":""},{"location":"configuration/#1-programmatic-configuration","title":"1. Programmatic Configuration","text":"<p>The most common approach for application integration:</p> <pre><code>from yokedcache import YokedCache, CacheConfig\nfrom yokedcache.models import SerializationMethod\n\n# Basic configuration\nconfig = CacheConfig(\n    redis_url=\"redis://localhost:6379/0\",\n    default_ttl=300,\n    key_prefix=\"myapp\"\n)\ncache = YokedCache(config=config)\n\n# Advanced configuration with v0.2.1 features\nconfig = CacheConfig(\n    # Connection settings\n    redis_url=\"redis://localhost:6379/0\",\n    max_connections=50,\n    connection_timeout=30,\n\n    # Cache behavior\n    default_ttl=300,\n    key_prefix=\"myapp\",\n\n    # Features\n    enable_fuzzy=True,\n    fuzzy_threshold=80,\n\n    # Serialization\n    default_serialization=SerializationMethod.JSON,\n\n    # Circuit breaker settings v0.2.1\n    enable_circuit_breaker=True,\n    circuit_breaker_failure_threshold=5,\n    circuit_breaker_timeout=60.0,\n\n    # Connection pool customization v0.2.1\n    connection_pool_kwargs={\n        \"socket_connect_timeout\": 5.0,\n        \"socket_timeout\": 5.0,\n        \"socket_keepalive\": True,\n        \"retry_on_timeout\": True,\n        \"health_check_interval\": 30\n    },\n\n    # Error handling and resilience v0.2.1\n    fallback_enabled=True,\n    connection_retries=3,\n    retry_delay=0.1,\n\n    # Logging\n    log_level=\"INFO\"\n)\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"configuration/#2-yaml-configuration","title":"2. YAML Configuration","text":"<p>Ideal for deployment environments and external configuration:</p> <pre><code># cache_config.yaml\nredis_url: redis://localhost:6379/0\ndefault_ttl: 300\nkey_prefix: myapp\nmax_connections: 50\nenable_fuzzy: true\nfuzzy_threshold: 80\nlog_level: INFO\n\n# Table-specific configurations\ntables:\n  users:\n    ttl: 3600\n    tags: [\"user_data\"]\n    serialization_method: JSON\n    enable_fuzzy: true\n    fuzzy_threshold: 85\n\n  products:\n    ttl: 1800\n    tags: [\"product_data\", \"catalog\"]\n    serialization_method: PICKLE\n\n  sessions:\n    ttl: 900\n    tags: [\"session_data\"]\n    serialization_method: JSON\n    query_specific_ttls:\n      \"SELECT * FROM sessions WHERE active = true\": 300\n      \"SELECT * FROM sessions WHERE user_id = ?\": 600\n\n# Monitoring configuration\nmonitoring:\n  enable_metrics: true\n  prometheus_port: 8000\n  statsd_host: \"localhost\"\n  statsd_port: 8125\n</code></pre> <p>Load YAML configuration:</p> <pre><code>import yaml\nfrom yokedcache import YokedCache, CacheConfig\n\n# Load from file\nwith open(\"cache_config.yaml\", \"r\") as f:\n    config_dict = yaml.safe_load(f)\n\nconfig = CacheConfig.from_dict(config_dict)\ncache = YokedCache(config=config)\n\n# Or load directly\ncache = YokedCache.from_yaml(\"cache_config.yaml\")\n</code></pre>"},{"location":"configuration/#3-environment-variables","title":"3. Environment Variables","text":"<p>Perfect for containerized deployments and CI/CD:</p> <pre><code># Basic settings\nexport YOKEDCACHE_REDIS_URL=\"redis://localhost:6379/0\"\nexport YOKEDCACHE_DEFAULT_TTL=\"300\"\nexport YOKEDCACHE_KEY_PREFIX=\"myapp\"\n\n# Connection settings\nexport YOKEDCACHE_MAX_CONNECTIONS=\"50\"\nexport YOKEDCACHE_CONNECTION_TIMEOUT=\"30\"\n\n# Feature flags\nexport YOKEDCACHE_ENABLE_FUZZY=\"true\"\nexport YOKEDCACHE_FUZZY_THRESHOLD=\"80\"\n\n# Logging\nexport YOKEDCACHE_LOG_LEVEL=\"INFO\"\n\n# Monitoring\nexport YOKEDCACHE_ENABLE_METRICS=\"true\"\nexport YOKEDCACHE_PROMETHEUS_PORT=\"8000\"\n</code></pre> <p>Use environment variables in code:</p> <pre><code>from yokedcache import YokedCache\n\n# Automatically loads from environment variables\ncache = YokedCache.from_env()\n\n# Or combine with programmatic config\nconfig = CacheConfig.from_env()\nconfig.default_ttl = 600  # Override specific settings\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"configuration/#4-configuration-precedence","title":"4. Configuration Precedence","text":"<p>When multiple configuration methods are used, values are applied in this order (highest to lowest precedence):</p> <ol> <li>Explicit parameters passed to methods</li> <li>Programmatic configuration via <code>CacheConfig</code></li> <li>YAML configuration files</li> <li>Environment variables</li> <li>Default values</li> </ol>"},{"location":"configuration/#configuration-reference","title":"Configuration Reference","text":""},{"location":"configuration/#core-settings","title":"Core Settings","text":""},{"location":"configuration/#redis_url-str","title":"<code>redis_url</code> (str)","text":"<p>Default: <code>\"redis://localhost:6379/0\"</code> Environment: <code>YOKEDCACHE_REDIS_URL</code></p> <p>Redis connection string. Supports various formats:</p> <pre><code># Basic Redis\n\"redis://localhost:6379/0\"\n\n# With authentication\n\"redis://:password@localhost:6379/0\"\n\"redis://username:password@localhost:6379/0\"\n\n# TLS/SSL\n\"rediss://localhost:6380/0\"\n\n# Sentinel\n\"redis+sentinel://sentinel1:26379,sentinel2:26379/mymaster/0\"\n\n# Cluster\n\"redis://localhost:7000,localhost:7001,localhost:7002/0\"\n</code></pre>"},{"location":"configuration/#default_ttl-int","title":"<code>default_ttl</code> (int)","text":"<p>Default: <code>300</code> Environment: <code>YOKEDCACHE_DEFAULT_TTL</code></p> <p>Default time-to-live in seconds for cache entries when no explicit TTL is provided.</p>"},{"location":"configuration/#key_prefix-str","title":"<code>key_prefix</code> (str)","text":"<p>Default: <code>\"yokedcache\"</code> Environment: <code>YOKEDCACHE_KEY_PREFIX</code></p> <p>Prefix added to all cache keys to avoid conflicts with other applications using the same Redis instance.</p>"},{"location":"configuration/#connection-settings","title":"Connection Settings","text":""},{"location":"configuration/#max_connections-int","title":"<code>max_connections</code> (int)","text":"<p>Default: <code>50</code> Environment: <code>YOKEDCACHE_MAX_CONNECTIONS</code></p> <p>Maximum number of connections in the Redis connection pool.</p>"},{"location":"configuration/#connection_timeout-int","title":"<code>connection_timeout</code> (int)","text":"<p>Default: <code>30</code></p>"},{"location":"configuration/#connection_pool_kwargs-dictstr-any-v021","title":"<code>connection_pool_kwargs</code> (Dict[str, Any]) v0.2.1","text":"<p>Default: <code>{}</code></p> <p>Advanced Redis connection pool configuration options. Allows fine-tuning of Redis connection behavior:</p> <pre><code>connection_pool_kwargs={\n    \"socket_connect_timeout\": 5.0,  # Connection timeout\n    \"socket_timeout\": 5.0,          # Socket read/write timeout\n    \"socket_keepalive\": True,       # Enable TCP keepalive\n    \"socket_keepalive_options\": {   # Keepalive settings\n        \"TCP_KEEPIDLE\": 1,\n        \"TCP_KEEPINTVL\": 3,\n        \"TCP_KEEPCNT\": 5\n    },\n    \"retry_on_timeout\": True,       # Retry on timeout\n    \"health_check_interval\": 30     # Health check frequency\n}\n</code></pre>"},{"location":"configuration/#resilience-settings-v021","title":"Resilience Settings v0.2.1","text":""},{"location":"configuration/#enable_circuit_breaker-bool","title":"<code>enable_circuit_breaker</code> (bool)","text":"<p>Default: <code>False</code> Environment: <code>YOKEDCACHE_ENABLE_CIRCUIT_BREAKER</code></p> <p>Enable circuit breaker pattern to prevent cascading failures during Redis outages.</p>"},{"location":"configuration/#circuit_breaker_failure_threshold-int","title":"<code>circuit_breaker_failure_threshold</code> (int)","text":"<p>Default: <code>5</code></p> <p>Number of consecutive failures before opening the circuit breaker.</p>"},{"location":"configuration/#circuit_breaker_timeout-float","title":"<code>circuit_breaker_timeout</code> (float)","text":"<p>Default: <code>60.0</code></p> <p>Time in seconds to wait before attempting to close the circuit breaker.</p>"},{"location":"configuration/#fallback_enabled-bool","title":"<code>fallback_enabled</code> (bool)","text":"<p>Default: <code>True</code> Environment: <code>YOKEDCACHE_FALLBACK_ENABLED</code></p> <p>Enable graceful fallback behavior when cache operations fail.</p>"},{"location":"configuration/#connection_retries-int","title":"<code>connection_retries</code> (int)","text":"<p>Default: <code>3</code> Environment: <code>YOKEDCACHE_CONNECTION_RETRIES</code></p> <p>Number of retry attempts for failed Redis operations.</p>"},{"location":"configuration/#retry_delay-float","title":"<code>retry_delay</code> (float)","text":"<p>Default: <code>0.1</code></p> <p>Base delay between retry attempts (with exponential backoff). Environment: <code>YOKEDCACHE_CONNECTION_TIMEOUT</code></p> <p>Connection timeout in seconds for Redis operations.</p>"},{"location":"configuration/#retry_attempts-int","title":"<code>retry_attempts</code> (int)","text":"<p>Default: <code>3</code> Environment: <code>YOKEDCACHE_RETRY_ATTEMPTS</code></p> <p>Number of retry attempts for failed operations.</p>"},{"location":"configuration/#retry_delay-float_1","title":"<code>retry_delay</code> (float)","text":"<p>Default: <code>1.0</code> Environment: <code>YOKEDCACHE_RETRY_DELAY</code></p> <p>Delay in seconds between retry attempts.</p>"},{"location":"configuration/#feature-settings","title":"Feature Settings","text":""},{"location":"configuration/#enable_fuzzy-bool","title":"<code>enable_fuzzy</code> (bool)","text":"<p>Default: <code>False</code> Environment: <code>YOKEDCACHE_ENABLE_FUZZY</code></p> <p>Enable fuzzy search capabilities. Requires <code>yokedcache[fuzzy]</code> installation.</p>"},{"location":"configuration/#fuzzy_threshold-int","title":"<code>fuzzy_threshold</code> (int)","text":"<p>Default: <code>80</code> Environment: <code>YOKEDCACHE_FUZZY_THRESHOLD</code></p> <p>Minimum similarity score (0-100) for fuzzy search matches.</p>"},{"location":"configuration/#enable_compression-bool","title":"<code>enable_compression</code> (bool)","text":"<p>Default: <code>False</code> Environment: <code>YOKEDCACHE_ENABLE_COMPRESSION</code></p> <p>Enable automatic compression for large cache values.</p>"},{"location":"configuration/#compression_threshold-int","title":"<code>compression_threshold</code> (int)","text":"<p>Default: <code>1024</code> Environment: <code>YOKEDCACHE_COMPRESSION_THRESHOLD</code></p> <p>Minimum size in bytes before compression is applied.</p>"},{"location":"configuration/#serialization-settings","title":"Serialization Settings","text":""},{"location":"configuration/#default_serialization-serializationmethod","title":"<code>default_serialization</code> (SerializationMethod)","text":"<p>Default: <code>SerializationMethod.JSON</code> Environment: <code>YOKEDCACHE_DEFAULT_SERIALIZATION</code></p> <p>Default serialization method for cache values:</p> <ul> <li><code>JSON</code>: Best for simple data types and interoperability</li> <li><code>PICKLE</code>: Best for complex Python objects</li> <li><code>MSGPACK</code>: Best for binary efficiency</li> </ul>"},{"location":"configuration/#logging-settings","title":"Logging Settings","text":""},{"location":"configuration/#log_level-str","title":"<code>log_level</code> (str)","text":"<p>Default: <code>\"INFO\"</code> Environment: <code>YOKEDCACHE_LOG_LEVEL</code></p> <p>Logging level for YokedCache operations. Options: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>.</p>"},{"location":"configuration/#log_format-str","title":"<code>log_format</code> (str)","text":"<p>Default: <code>\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"</code> Environment: <code>YOKEDCACHE_LOG_FORMAT</code></p> <p>Custom log format string.</p>"},{"location":"configuration/#monitoring-settings","title":"Monitoring Settings","text":""},{"location":"configuration/#enable_metrics-bool","title":"<code>enable_metrics</code> (bool)","text":"<p>Default: <code>False</code> Environment: <code>YOKEDCACHE_ENABLE_METRICS</code></p> <p>Enable metrics collection for monitoring.</p>"},{"location":"configuration/#prometheus_port-int","title":"<code>prometheus_port</code> (int)","text":"<p>Default: <code>8000</code> Environment: <code>YOKEDCACHE_PROMETHEUS_PORT</code></p> <p>Port for Prometheus metrics endpoint.</p>"},{"location":"configuration/#statsd_host-str","title":"<code>statsd_host</code> (str)","text":"<p>Default: <code>None</code> Environment: <code>YOKEDCACHE_STATSD_HOST</code></p> <p>StatsD host for metrics collection.</p>"},{"location":"configuration/#statsd_port-int","title":"<code>statsd_port</code> (int)","text":"<p>Default: <code>8125</code> Environment: <code>YOKEDCACHE_STATSD_PORT</code></p> <p>StatsD port for metrics collection.</p>"},{"location":"configuration/#table-specific-configuration","title":"Table-Specific Configuration","text":"<p>Configure different behaviors for different data types:</p> <pre><code>from yokedcache import CacheConfig, TableCacheConfig\nfrom yokedcache.models import SerializationMethod\n\nconfig = CacheConfig(\n    default_ttl=300,\n    tables={\n        \"users\": TableCacheConfig(\n            ttl=3600,                                    # Longer TTL for user data\n            tags={\"user_data\"},                         # Default tags\n            serialization_method=SerializationMethod.JSON,\n            enable_fuzzy=True,\n            fuzzy_threshold=85,\n\n            # Query-specific TTL overrides\n            query_specific_ttls={\n                \"SELECT * FROM users WHERE active = true\": 600,\n                \"SELECT COUNT(*) FROM users\": 60\n            }\n        ),\n\n        \"products\": TableCacheConfig(\n            ttl=1800,\n            tags={\"product_data\", \"catalog\"},\n            serialization_method=SerializationMethod.PICKLE,\n            enable_compression=True,\n            compression_threshold=512\n        ),\n\n        \"sessions\": TableCacheConfig(\n            ttl=900,                                    # Short TTL for sessions\n            tags={\"session_data\"},\n            serialization_method=SerializationMethod.JSON,\n            enable_fuzzy=False                          # Disable fuzzy for sessions\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/#tablecacheconfig-options","title":"TableCacheConfig Options","text":""},{"location":"configuration/#ttl-int","title":"<code>ttl</code> (int)","text":"<p>Override default TTL for this table.</p>"},{"location":"configuration/#tags-setstr","title":"<code>tags</code> (set[str])","text":"<p>Default tags applied to all cache entries for this table.</p>"},{"location":"configuration/#serialization_method-serializationmethod","title":"<code>serialization_method</code> (SerializationMethod)","text":"<p>Override default serialization method for this table.</p>"},{"location":"configuration/#enable_fuzzy-bool_1","title":"<code>enable_fuzzy</code> (bool)","text":"<p>Override global fuzzy search setting for this table.</p>"},{"location":"configuration/#fuzzy_threshold-int_1","title":"<code>fuzzy_threshold</code> (int)","text":"<p>Override global fuzzy threshold for this table.</p>"},{"location":"configuration/#query_specific_ttls-dictstr-int","title":"<code>query_specific_ttls</code> (dict[str, int])","text":"<p>Map of SQL query patterns to specific TTL values.</p>"},{"location":"configuration/#enable_compression-bool_1","title":"<code>enable_compression</code> (bool)","text":"<p>Override global compression setting for this table.</p>"},{"location":"configuration/#compression_threshold-int_1","title":"<code>compression_threshold</code> (int)","text":"<p>Override global compression threshold for this table.</p>"},{"location":"configuration/#backend-specific-configuration","title":"Backend-Specific Configuration","text":""},{"location":"configuration/#redis-configuration","title":"Redis Configuration","text":"<pre><code>from yokedcache import CacheConfig\nfrom yokedcache.backends import RedisBackend\n\n# Advanced Redis configuration\nredis_config = {\n    \"host\": \"localhost\",\n    \"port\": 6379,\n    \"db\": 0,\n    \"password\": \"secret\",\n    \"ssl\": True,\n    \"ssl_cert_reqs\": \"required\",\n    \"socket_connect_timeout\": 30,\n    \"socket_timeout\": 30,\n    \"retry_on_timeout\": True,\n    \"health_check_interval\": 30\n}\n\nbackend = RedisBackend(**redis_config)\nconfig = CacheConfig(backend=backend)\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"configuration/#memory-backend-configuration","title":"Memory Backend Configuration","text":"<pre><code>from yokedcache.backends import MemoryBackend\n\n# Memory backend for development/testing\nbackend = MemoryBackend(\n    max_size=10000,        # Maximum number of entries\n    max_memory_mb=512,     # Maximum memory usage in MB\n    eviction_policy=\"LRU\"  # LRU, LFU, or FIFO\n)\n\nconfig = CacheConfig(backend=backend)\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"configuration/#memcached-configuration","title":"Memcached Configuration","text":"<pre><code>from yokedcache.backends import MemcachedBackend\n\n# Memcached backend\nbackend = MemcachedBackend(\n    servers=[\"localhost:11211\", \"localhost:11212\"],\n    binary_protocol=True,\n    username=\"myuser\",\n    password=\"mypassword\"\n)\n\nconfig = CacheConfig(backend=backend)\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"configuration/#environment-specific-configurations","title":"Environment-Specific Configurations","text":""},{"location":"configuration/#development-environment","title":"Development Environment","text":"<pre><code># config/development.yaml\nredis_url: redis://localhost:6379/0\ndefault_ttl: 60          # Short TTL for quick testing\nkey_prefix: dev_myapp\nenable_fuzzy: true\nlog_level: DEBUG         # Verbose logging\n\ntables:\n  users:\n    ttl: 300\n    tags: [\"user_data\"]\n</code></pre>"},{"location":"configuration/#staging-environment","title":"Staging Environment","text":"<pre><code># config/staging.yaml\nredis_url: redis://staging-redis:6379/0\ndefault_ttl: 300\nkey_prefix: staging_myapp\nenable_fuzzy: true\nlog_level: INFO\nmax_connections: 25\n\nmonitoring:\n  enable_metrics: true\n  prometheus_port: 8000\n</code></pre>"},{"location":"configuration/#production-environment","title":"Production Environment","text":"<pre><code># config/production.yaml\nredis_url: rediss://prod-redis.example.com:6380/0\ndefault_ttl: 600\nkey_prefix: prod_myapp\nenable_fuzzy: false      # Disable for performance\nlog_level: WARNING\nmax_connections: 100\nconnection_timeout: 10\nretry_attempts: 5\n\n# Compression for large values\nenable_compression: true\ncompression_threshold: 1024\n\nmonitoring:\n  enable_metrics: true\n  prometheus_port: 8000\n  statsd_host: \"statsd.example.com\"\n  statsd_port: 8125\n\ntables:\n  users:\n    ttl: 3600\n    tags: [\"user_data\"]\n    enable_compression: true\n\n  products:\n    ttl: 7200           # Long TTL for stable product data\n    tags: [\"product_data\"]\n    serialization_method: MSGPACK  # Efficient binary format\n</code></pre>"},{"location":"configuration/#configuration-validation","title":"Configuration Validation","text":"<p>YokedCache validates configuration at startup:</p> <pre><code>from yokedcache import CacheConfig, ConfigValidationError\n\ntry:\n    config = CacheConfig(\n        default_ttl=-1,  # Invalid: negative TTL\n        redis_url=\"invalid://url\"  # Invalid: bad URL format\n    )\nexcept ConfigValidationError as e:\n    print(f\"Configuration error: {e}\")\n\n# Validate configuration manually\nconfig = CacheConfig(default_ttl=300)\nvalidation_errors = config.validate()\nif validation_errors:\n    for error in validation_errors:\n        print(f\"Validation error: {error}\")\n</code></pre>"},{"location":"configuration/#dynamic-configuration-updates","title":"Dynamic Configuration Updates","text":"<p>Update configuration at runtime:</p> <pre><code># Initial configuration\ncache = YokedCache(CacheConfig(default_ttl=300))\n\n# Update configuration\nnew_config = CacheConfig(\n    default_ttl=600,\n    enable_fuzzy=True\n)\nawait cache.update_config(new_config)\n\n# Update specific settings\nawait cache.update_setting(\"default_ttl\", 900)\nawait cache.update_table_config(\"users\", TableCacheConfig(ttl=7200))\n</code></pre>"},{"location":"configuration/#configuration-export","title":"Configuration Export","text":"<p>Export current configuration for backup or deployment:</p> <pre><code># Export to YAML\nconfig_yaml = cache.config.to_yaml()\nwith open(\"exported_config.yaml\", \"w\") as f:\n    f.write(config_yaml)\n\n# Export to dict\nconfig_dict = cache.config.to_dict()\n\n# CLI export\n# yokedcache export-config --output config.yaml\n</code></pre>"},{"location":"configuration/#best-practices","title":"Best Practices","text":""},{"location":"configuration/#security","title":"Security","text":"<ul> <li>Use TLS (<code>rediss://</code>) for production Redis connections</li> <li>Store sensitive configuration in environment variables or secret management systems</li> <li>Use different key prefixes for different environments</li> <li>Rotate Redis passwords regularly</li> </ul>"},{"location":"configuration/#performance","title":"Performance","text":"<ul> <li>Set appropriate connection pool sizes based on application concurrency</li> <li>Use compression for large cache values</li> <li>Choose serialization methods based on data types and performance requirements</li> <li>Configure table-specific TTLs based on data volatility</li> </ul>"},{"location":"configuration/#monitoring","title":"Monitoring","text":"<ul> <li>Enable metrics in production environments</li> <li>Use appropriate log levels (WARNING/ERROR for production)</li> <li>Monitor cache hit rates and performance metrics</li> <li>Set up alerts for cache failures</li> </ul>"},{"location":"configuration/#environment-management","title":"Environment Management","text":"<ul> <li>Use separate configuration files for each environment</li> <li>Validate configuration in CI/CD pipelines</li> <li>Document configuration changes</li> <li>Use configuration templates for consistency</li> </ul> <p>This comprehensive configuration guide should help you set up YokedCache optimally for your specific environment and requirements.</p>"},{"location":"core-concepts/","title":"Core Concepts","text":"<p>Understanding YokedCache's core concepts will help you use it effectively and troubleshoot issues when they arise.</p>"},{"location":"core-concepts/#architecture-overview","title":"Architecture Overview","text":"<p>YokedCache follows a simple but powerful architecture:</p> <pre><code>graph TB\n    A[Application Code] --&gt; B[YokedCache Wrapper]\n    B --&gt; C{Cache Hit?}\n    C --&gt;|Yes| D[Return Cached Data]\n    C --&gt;|No| E[Execute Function/Query]\n    E --&gt; F[Store in Backend]\n    F --&gt; G[Return Data]\n    H[Write Operation] --&gt; I[Auto-Invalidation]\n    I --&gt; J[Clear Related Cache Tags]\n\n    subgraph \"Backends\"\n        K[Memory Backend]\n        L[Redis Backend]\n        M[Memcached Backend]\n    end\n\n    B --&gt; K\n    B --&gt; L\n    B --&gt; M\n</code></pre>"},{"location":"core-concepts/#cache-keys","title":"Cache Keys","text":"<p>Cache keys are unique identifiers for cached values. YokedCache builds keys systematically to ensure consistency and prevent conflicts.</p>"},{"location":"core-concepts/#key-structure","title":"Key Structure","text":"<p>All cache keys follow this pattern: <pre><code>{key_prefix}:{context}:{hash}\n</code></pre></p> <ul> <li>key_prefix: Configurable namespace (default: <code>yokedcache</code>)</li> <li>context: Function name, table name, or operation type</li> <li>hash: Stable hash of arguments/parameters</li> </ul>"},{"location":"core-concepts/#key-generation","title":"Key Generation","text":"<p>YokedCache automatically generates keys using several inputs:</p> <pre><code>from yokedcache.utils import generate_cache_key\n\n# Function caching\nkey = generate_cache_key(\n    prefix=\"myapp\",\n    function_name=\"get_user\",\n    args=(123,),\n    kwargs={\"active\": True}\n)\n# Result: \"myapp:get_user:a1b2c3d4...\"\n\n# Database query caching\nkey = generate_cache_key(\n    prefix=\"myapp\",\n    table=\"users\",\n    query=\"SELECT * FROM users WHERE id = ?\",\n    params=[123]\n)\n# Result: \"myapp:users:query:e5f6g7h8...\"\n</code></pre>"},{"location":"core-concepts/#key-sanitization","title":"Key Sanitization","text":"<p>Keys are automatically sanitized to ensure compatibility with all backends:</p> <ul> <li>Non-ASCII characters are encoded</li> <li>Special characters are escaped or replaced</li> <li>Length is limited to prevent backend issues</li> <li>Dangerous patterns are removed</li> </ul> <pre><code>from yokedcache.utils import sanitize_key\n\n# Automatically applied to all generated keys\nsafe_key = sanitize_key(\"my-app:user:jos\u00e9@example.com\")\n# Result: \"my-app:user:jos__at__example.com\"\n</code></pre>"},{"location":"core-concepts/#ttl-and-expiration","title":"TTL and Expiration","text":"<p>Time-To-Live (TTL) controls how long cache entries remain valid.</p>"},{"location":"core-concepts/#ttl-calculation","title":"TTL Calculation","text":"<p>YokedCache applies jitter to TTL values to prevent thundering herd problems:</p> <pre><code>from yokedcache.utils import calculate_ttl_with_jitter\n\n# Base TTL: 300 seconds, Jitter: 10%\nactual_ttl = calculate_ttl_with_jitter(300, jitter_percent=10.0)\n# Result: 270-330 seconds (random within range)\n</code></pre>"},{"location":"core-concepts/#ttl-sources","title":"TTL Sources","text":"<p>TTL values are determined in this order of precedence:</p> <ol> <li>Explicit TTL: Passed directly to cache operations</li> <li>Table-specific TTL: Configured per table in config</li> <li>Default TTL: Global default from configuration</li> <li>Backend default: Backend-specific fallback</li> </ol> <pre><code># Explicit TTL (highest precedence)\nawait cache.set(\"key\", value, ttl=600)\n\n# Table-specific TTL in config\nconfig = CacheConfig(\n    tables={\n        \"users\": TableCacheConfig(ttl=3600),\n        \"products\": TableCacheConfig(ttl=1800)\n    }\n)\n\n# Global default TTL\nconfig = CacheConfig(default_ttl=300)\n</code></pre>"},{"location":"core-concepts/#ttl-best-practices","title":"TTL Best Practices","text":"<ul> <li>Hot data: Short TTL (30-300 seconds) for frequently changing data</li> <li>Cold data: Long TTL (1-24 hours) for stable reference data</li> <li>User sessions: Medium TTL (15-60 minutes) for user-specific data</li> <li>Always use jitter: Prevents synchronized cache misses</li> </ul>"},{"location":"core-concepts/#tags-and-grouping","title":"Tags and Grouping","text":"<p>Tags allow you to group related cache entries and perform bulk operations.</p>"},{"location":"core-concepts/#tag-structure","title":"Tag Structure","text":"<p>Tags are simple string identifiers that group related cache entries:</p> <pre><code># Table-based tags (automatic)\n\"table:users\"\n\"table:products\"\n\n# Feature-based tags (manual)\n\"user_data\"\n\"product_catalog\"\n\"session_data\"\n\n# Composite tags\n\"user:123\"\n\"tenant:company_a\"\n</code></pre>"},{"location":"core-concepts/#automatic-tagging","title":"Automatic Tagging","text":"<p>YokedCache automatically applies tags based on context:</p> <pre><code># Function caching with explicit tags\n@cached(ttl=300, tags=[\"user_data\", \"api_v1\"])\nasync def get_user_profile(user_id: int):\n    return fetch_user_from_db(user_id)\n\n# Database dependency caching (automatic table tags)\ncached_get_db = cached_dependency(\n    get_db,\n    cache=cache,\n    ttl=300,\n    table_name=\"users\"  # Automatically adds \"table:users\" tag\n)\n</code></pre>"},{"location":"core-concepts/#tag-based-operations","title":"Tag-Based Operations","text":"<p>Tags enable powerful bulk operations:</p> <pre><code># Invalidate all user-related data\nawait cache.invalidate_tags([\"user_data\", \"table:users\"])\n\n# Invalidate specific user's data\nawait cache.invalidate_tags([f\"user:{user_id}\"])\n\n# Search by tags\nresults = await cache.fuzzy_search(\"john\", tags={\"user_data\"})\n\n# Pattern-based invalidation\nawait cache.invalidate_pattern(\"user:*\")\n</code></pre>"},{"location":"core-concepts/#auto-invalidation","title":"Auto-Invalidation","text":"<p>Auto-invalidation automatically clears cache entries when related data changes.</p>"},{"location":"core-concepts/#how-it-works","title":"How It Works","text":"<ol> <li>Read Operations: Cached with appropriate tags</li> <li>Write Operations: Tracked and queued for invalidation</li> <li>Transaction Commit: Triggers invalidation of affected tags</li> <li>Cache Cleared: Related entries removed from cache</li> </ol> <pre><code># Setup auto-invalidation\ncached_get_db = cached_dependency(\n    get_db,\n    cache=cache,\n    ttl=300,\n    table_name=\"users\"\n)\n\n# Read operation (cached with \"table:users\" tag)\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db=Depends(cached_get_db)):\n    return db.query(User).filter(User.id == user_id).first()\n\n# Write operation (triggers invalidation on commit)\n@app.post(\"/users\")\nasync def create_user(user: UserCreate, db=Depends(cached_get_db)):\n    new_user = User(**user.dict())\n    db.add(new_user)\n    await db.commit()  # Auto-invalidates \"table:users\" tag\n    return new_user\n</code></pre>"},{"location":"core-concepts/#table-detection","title":"Table Detection","text":"<p>YokedCache automatically detects affected tables from SQL queries:</p> <pre><code># Simple patterns detected automatically\n\"SELECT * FROM users WHERE id = ?\"           # \u2192 users\n\"INSERT INTO products (name) VALUES (?)\"     # \u2192 products\n\"UPDATE orders SET status = ? WHERE id = ?\"  # \u2192 orders\n\"DELETE FROM sessions WHERE expired &lt; ?\"     # \u2192 sessions\n</code></pre> <p>For complex queries, specify tables explicitly:</p> <pre><code>cached_get_db = cached_dependency(\n    get_db,\n    cache=cache,\n    ttl=300,\n    table_name=\"users\"  # Explicit table specification\n)\n</code></pre>"},{"location":"core-concepts/#serialization","title":"Serialization","text":"<p>YokedCache supports multiple serialization methods for different use cases.</p>"},{"location":"core-concepts/#serialization-methods","title":"Serialization Methods","text":"<pre><code>from yokedcache.models import SerializationMethod\n\n# JSON (default) - Best for simple data and interoperability\nawait cache.set(\"key\", {\"name\": \"John\"}, serialization=SerializationMethod.JSON)\n\n# Pickle - Best for complex Python objects\nawait cache.set(\"key\", complex_object, serialization=SerializationMethod.PICKLE)\n\n# MessagePack - Best for binary efficiency\nawait cache.set(\"key\", data, serialization=SerializationMethod.MSGPACK)\n</code></pre>"},{"location":"core-concepts/#json-serialization","title":"JSON Serialization","text":"<p>JSON is the default serialization method with custom encoders for common Python types:</p> <pre><code># Automatically handles these types\ndata = {\n    \"timestamp\": datetime.now(),\n    \"tags\": {\"user\", \"active\"},  # Sets converted to lists\n    \"decimal\": Decimal(\"123.45\"),\n    \"uuid\": uuid4()\n}\n\nawait cache.set(\"key\", data)  # Automatically serialized\nresult = await cache.get(\"key\")  # Automatically deserialized\n</code></pre>"},{"location":"core-concepts/#custom-serialization","title":"Custom Serialization","text":"<p>Configure serialization per operation or globally:</p> <pre><code># Per-operation\nawait cache.set(\"key\", data, serialization=SerializationMethod.PICKLE)\n\n# Per-table configuration\nconfig = CacheConfig(\n    tables={\n        \"users\": TableCacheConfig(\n            serialization_method=SerializationMethod.JSON\n        ),\n        \"sessions\": TableCacheConfig(\n            serialization_method=SerializationMethod.PICKLE\n        )\n    }\n)\n</code></pre>"},{"location":"core-concepts/#serialization-best-practices","title":"Serialization Best Practices","text":"<ul> <li>JSON: Use for simple data types, APIs, and cross-language compatibility</li> <li>Pickle: Use for complex Python objects, but only within Python ecosystems</li> <li>MessagePack: Use for binary efficiency and cross-language support</li> <li>Consistency: Use the same serialization method for related data</li> </ul>"},{"location":"core-concepts/#error-handling-and-resilience","title":"Error Handling and Resilience","text":"<p>YokedCache is designed to fail gracefully and maintain application stability.</p>"},{"location":"core-concepts/#graceful-degradation","title":"Graceful Degradation","text":"<p>When cache operations fail, YokedCache falls back to the original function:</p> <pre><code>@cached(ttl=300)\nasync def get_expensive_data():\n    # If cache fails, function still executes normally\n    return expensive_computation()\n</code></pre>"},{"location":"core-concepts/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<p>YokedCache implements circuit breaker patterns to prevent cascade failures:</p> <ul> <li>Closed: Normal operation, cache working</li> <li>Open: Cache failing, bypass cache temporarily</li> <li>Half-Open: Testing if cache has recovered</li> </ul>"},{"location":"core-concepts/#logging-and-monitoring","title":"Logging and Monitoring","text":"<p>Comprehensive logging helps with debugging and monitoring:</p> <pre><code>import logging\n\n# Configure YokedCache logging\nlogging.getLogger(\"yokedcache\").setLevel(logging.INFO)\n\n# Log levels:\n# DEBUG: Detailed operation logs\n# INFO: Key operations and stats\n# WARNING: Recoverable issues\n# ERROR: Serious problems\n</code></pre>"},{"location":"core-concepts/#performance-considerations","title":"Performance Considerations","text":""},{"location":"core-concepts/#memory-usage","title":"Memory Usage","text":"<ul> <li>Key Efficiency: Keep keys descriptive but concise</li> <li>Value Size: Avoid storing very large objects; consider pagination</li> <li>TTL Strategy: Balance freshness vs. performance</li> </ul>"},{"location":"core-concepts/#connection-management","title":"Connection Management","text":"<ul> <li>Connection Pooling: YokedCache maintains connection pools automatically</li> <li>Pool Sizing: Configure <code>max_connections</code> based on concurrency needs</li> <li>Async Operations: Use async/await consistently for best performance</li> </ul>"},{"location":"core-concepts/#batch-operations","title":"Batch Operations","text":"<p>YokedCache optimizes batch operations internally:</p> <pre><code># These are automatically batched\nawait cache.set_many({\n    \"key1\": value1,\n    \"key2\": value2,\n    \"key3\": value3\n}, ttl=300)\n\n# Tag operations are batched\nawait cache.invalidate_tags([\"tag1\", \"tag2\", \"tag3\"])\n</code></pre>"},{"location":"core-concepts/#configuration","title":"Configuration","text":"<p>Core concepts can be configured globally or per-operation:</p> <pre><code>from yokedcache import CacheConfig, YokedCache\n\nconfig = CacheConfig(\n    # Global settings\n    default_ttl=300,\n    key_prefix=\"myapp\",\n\n    # Performance settings\n    max_connections=50,\n\n    # Table-specific settings\n    tables={\n        \"users\": TableCacheConfig(\n            ttl=3600,\n            tags={\"user_data\"},\n            serialization_method=SerializationMethod.JSON\n        )\n    }\n)\n\ncache = YokedCache(config=config)\n</code></pre> <p>Understanding these core concepts will help you design effective caching strategies and troubleshoot issues when they arise. Next, explore the Configuration Guide for detailed setup options.</p>"},{"location":"getting-started/","title":"Getting Started with YokedCache - Python FastAPI Redis Caching","text":"<p>This guide will walk you through installing YokedCache and setting up your first Redis caching implementation in a FastAPI application. By the end, you'll have a working cache that dramatically improves your application's performance with automatic invalidation.</p>"},{"location":"getting-started/#installation-python-fastapi-redis-caching-library","title":"Installation - Python FastAPI Redis Caching Library","text":""},{"location":"getting-started/#basic-installation","title":"Basic Installation","text":"<pre><code># Install the core YokedCache package for Python FastAPI Redis caching\npip install yokedcache\n</code></pre>"},{"location":"getting-started/#recommended-installation-for-production-fastapi-applications","title":"Recommended Installation for Production FastAPI Applications","text":"<p>For production FastAPI applications, install YokedCache with all Redis caching features:</p> <pre><code># Install with all Redis caching features (recommended for FastAPI)\npip install yokedcache[full]\n</code></pre>"},{"location":"getting-started/#feature-specific-installation-for-custom-python-setups","title":"Feature-Specific Installation for Custom Python Setups","text":"<p>Install only the Redis caching features you need for your Python application:</p> <pre><code># Vector similarity search caching\npip install yokedcache[vector]\n\n# Production monitoring for Redis cache (Prometheus, StatsD)\npip install yokedcache[monitoring]\n\n# Memcached backend support\npip install yokedcache[memcached]\n\n# Fuzzy search capabilities for cached data\npip install yokedcache[fuzzy]\n\n# Combine multiple caching features\npip install yokedcache[vector,monitoring,fuzzy]\n</code></pre>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":""},{"location":"getting-started/#redis-setup","title":"Redis Setup","text":"<p>YokedCache uses Redis as its default backend. You'll need a Redis instance:</p> <p>Option 1: Docker (Recommended for development) <pre><code># Start Redis with Docker\ndocker run -d --name redis -p 6379:6379 redis:7\n\n# Verify Redis is running\ndocker exec redis redis-cli ping\n</code></pre></p> <p>Option 2: Local Installation <pre><code># macOS\nbrew install redis\nbrew services start redis\n\n# Ubuntu/Debian\nsudo apt-get install redis-server\nsudo systemctl start redis\n\n# Windows\n# Download and install from https://redis.io/download\n</code></pre></p> <p>Option 3: Cloud Redis Use managed Redis services like AWS ElastiCache, Azure Cache for Redis, or Google Cloud Memorystore.</p>"},{"location":"getting-started/#verify-installation","title":"Verify Installation","text":"<p>Test your YokedCache installation:</p> <pre><code># Check version\npython -c \"import yokedcache; print(yokedcache.__version__)\"\n\n# Test CLI\nyokedcache --version\n\n# Test Redis connection\nyokedcache ping\n</code></pre>"},{"location":"getting-started/#your-first-cache","title":"Your First Cache","text":"<p>Let's start with a simple example that demonstrates core caching concepts.</p>"},{"location":"getting-started/#basic-function-caching","title":"Basic Function Caching","text":"<pre><code># basic_cache.py\nimport asyncio\nfrom yokedcache import YokedCache, cached\n\n# Initialize cache (uses Redis at localhost:6379 by default)\ncache = YokedCache()\n\n@cached(ttl=300, tags=[\"api_data\"])\nasync def fetch_user_data(user_id: int):\n    \"\"\"Simulate an expensive API call or database query\"\"\"\n    print(f\"Fetching user {user_id} from database...\")  # You'll see this only once\n\n    # Simulate slow operation\n    await asyncio.sleep(1)\n\n    return {\n        \"id\": user_id,\n        \"name\": f\"User {user_id}\",\n        \"email\": f\"user{user_id}@example.com\"\n    }\n\nasync def main():\n    # First call - hits the database (slow)\n    print(\"First call:\")\n    user = await fetch_user_data(123)\n    print(f\"Result: {user}\")\n\n    # Second call - returns cached result (fast)\n    print(\"\\nSecond call:\")\n    user = await fetch_user_data(123)\n    print(f\"Result: {user}\")\n\n    # Check cache statistics\n    stats = await cache.get_stats()\n    print(f\"\\nCache statistics: {stats}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Run this example: <pre><code>python basic_cache.py\n</code></pre></p> <p>You should see: - First call takes ~1 second (database hit) - Second call is instant (cache hit) - Cache statistics showing hit/miss rates</p>"},{"location":"getting-started/#manual-cache-operations","title":"Manual Cache Operations","text":"<pre><code># manual_cache.py\nimport asyncio\nfrom yokedcache import YokedCache\n\nasync def main():\n    cache = YokedCache()\n\n    # Store data in cache\n    await cache.set(\"user:123\", {\"name\": \"Alice\", \"age\": 30}, ttl=300)\n    print(\"Data stored in cache\")\n\n    # Retrieve data from cache\n    user = await cache.get(\"user:123\")\n    print(f\"Retrieved from cache: {user}\")\n\n    # Check if key exists\n    exists = await cache.exists(\"user:123\")\n    print(f\"Key exists: {exists}\")\n\n    # Store with tags for grouping\n    await cache.set(\"product:456\", {\"name\": \"Laptop\", \"price\": 999},\n                   ttl=600, tags=[\"products\", \"electronics\"])\n\n    # Invalidate by tags\n    await cache.invalidate_tags([\"products\"])\n    print(\"Products cache cleared\")\n\n    # Verify product was removed\n    product = await cache.get(\"product:456\")\n    print(f\"Product after invalidation: {product}\")  # Should be None\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting-started/#fastapi-integration","title":"FastAPI Integration","text":"<p>YokedCache shines when integrated with web frameworks like FastAPI.</p>"},{"location":"getting-started/#simple-fastapi-example","title":"Simple FastAPI Example","text":"<pre><code># fastapi_cache.py\nfrom fastapi import FastAPI, Depends, HTTPException\nfrom yokedcache import YokedCache, cached\nimport asyncio\n\napp = FastAPI(title=\"YokedCache Demo\")\ncache = YokedCache()\n\n# Simulated database\nUSERS_DB = {\n    1: {\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"},\n    2: {\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\"},\n    3: {\"id\": 3, \"name\": \"Charlie\", \"email\": \"charlie@example.com\"},\n}\n\n@cached(ttl=300, tags=[\"users\"])\nasync def get_user_from_db(user_id: int):\n    \"\"\"Simulate database query\"\"\"\n    print(f\"Querying database for user {user_id}\")\n    await asyncio.sleep(0.5)  # Simulate DB latency\n\n    user = USERS_DB.get(user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    \"\"\"Get user by ID (cached)\"\"\"\n    return await get_user_from_db(user_id)\n\n@app.get(\"/users\")\nasync def list_users():\n    \"\"\"List all users (cached)\"\"\"\n    return list(USERS_DB.values())\n\n@app.post(\"/users/{user_id}/invalidate\")\nasync def invalidate_user_cache(user_id: int):\n    \"\"\"Manually invalidate user cache\"\"\"\n    await cache.invalidate_tags([\"users\"])\n    return {\"message\": f\"Cache invalidated for user {user_id}\"}\n\n@app.get(\"/cache/stats\")\nasync def cache_stats():\n    \"\"\"Get cache statistics\"\"\"\n    return await cache.get_stats()\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre> <p>Run the FastAPI example: <pre><code>pip install fastapi uvicorn\npython fastapi_cache.py\n</code></pre></p> <p>Test the endpoints: <pre><code># Get user (first call - slow)\ncurl http://localhost:8000/users/1\n\n# Get user again (second call - fast, cached)\ncurl http://localhost:8000/users/1\n\n# Check cache statistics\ncurl http://localhost:8000/cache/stats\n\n# Invalidate cache\ncurl -X POST http://localhost:8000/users/1/invalidate\n</code></pre></p>"},{"location":"getting-started/#database-integration-with-auto-invalidation","title":"Database Integration with Auto-Invalidation","text":"<p>For real applications, you'll want automatic cache invalidation when data changes:</p> <pre><code># database_integration.py\nfrom fastapi import FastAPI, Depends\nfrom sqlalchemy import create_engine, Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session\nfrom yokedcache import YokedCache, cached_dependency\n\n# Database setup\nSQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\nengine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False})\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String, index=True)\n    email = Column(String, unique=True, index=True)\n\nBase.metadata.create_all(bind=engine)\n\n# FastAPI app\napp = FastAPI()\ncache = YokedCache()\n\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n# Cached database dependency with auto-invalidation\ncached_get_db = cached_dependency(get_db, cache=cache, ttl=300, table_name=\"users\")\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db: Session = Depends(cached_get_db)):\n    \"\"\"Get user - automatically cached\"\"\"\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@app.post(\"/users\")\nasync def create_user(name: str, email: str, db: Session = Depends(cached_get_db)):\n    \"\"\"Create user - automatically invalidates cache on commit\"\"\"\n    user = User(name=name, email=email)\n    db.add(user)\n    await db.commit()  # This triggers cache invalidation\n    return user\n\n@app.put(\"/users/{user_id}\")\nasync def update_user(user_id: int, name: str, email: str, db: Session = Depends(cached_get_db)):\n    \"\"\"Update user - automatically invalidates cache on commit\"\"\"\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    user.name = name\n    user.email = email\n    await db.commit()  # This triggers cache invalidation\n    return user\n</code></pre>"},{"location":"getting-started/#configuration","title":"Configuration","text":""},{"location":"getting-started/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from yokedcache import YokedCache, CacheConfig\n\n# Basic configuration\nconfig = CacheConfig(\n    redis_url=\"redis://localhost:6379/0\",\n    default_ttl=300,  # 5 minutes default\n    key_prefix=\"myapp\"\n)\n\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"getting-started/#environment-based-configuration","title":"Environment-Based Configuration","text":"<pre><code># Set environment variables\nexport YOKEDCACHE_REDIS_URL=\"redis://localhost:6379/0\"\nexport YOKEDCACHE_DEFAULT_TTL=\"600\"\nexport YOKEDCACHE_KEY_PREFIX=\"myapp\"\n</code></pre> <pre><code># Automatically loads from environment\ncache = YokedCache.from_env()\n</code></pre>"},{"location":"getting-started/#yaml-configuration","title":"YAML Configuration","text":"<pre><code># config.yaml\nredis_url: redis://localhost:6379/0\ndefault_ttl: 300\nkey_prefix: myapp\nenable_fuzzy: true\n\ntables:\n  users:\n    ttl: 3600\n    tags: [\"user_data\"]\n  products:\n    ttl: 1800\n    tags: [\"product_data\"]\n</code></pre> <pre><code># Load from YAML\ncache = YokedCache.from_yaml(\"config.yaml\")\n</code></pre>"},{"location":"getting-started/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"getting-started/#using-the-cli","title":"Using the CLI","text":"<p>Monitor your cache in real-time:</p> <pre><code># Test connection\nyokedcache ping\n\n# View statistics\nyokedcache stats\n\n# Watch statistics (auto-refresh)\nyokedcache stats --watch\n\n# List cached keys\nyokedcache list --pattern \"user:*\"\n\n# Search for keys\nyokedcache search \"alice\" --threshold 80\n</code></pre>"},{"location":"getting-started/#application-monitoring","title":"Application Monitoring","text":"<pre><code>import asyncio\nfrom yokedcache import YokedCache\n\nasync def monitor_cache():\n    cache = YokedCache()\n\n    # Get basic statistics\n    stats = await cache.get_stats()\n    print(f\"Hit rate: {stats.hit_rate:.2%}\")\n    print(f\"Total keys: {stats.key_count}\")\n    print(f\"Memory usage: {stats.memory_usage_mb:.2f} MB\")\n\n    # Health check\n    health = await cache.health_check()\n    print(f\"Cache healthy: {health.is_healthy}\")\n\nasyncio.run(monitor_cache())\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you have YokedCache working, explore these advanced features:</p>"},{"location":"getting-started/#1-multi-backend-support","title":"1. Multi-Backend Support","text":"<p>Learn about different backends in the Backend Guide: - Memory backend for development - Redis backend for production - Memcached backend for specific use cases</p>"},{"location":"getting-started/#2-advanced-configuration","title":"2. Advanced Configuration","text":"<p>Dive deeper into configuration options in the Configuration Guide: - Table-specific settings - Performance tuning - Security configurations</p>"},{"location":"getting-started/#3-usage-patterns","title":"3. Usage Patterns","text":"<p>Explore different ways to use YokedCache in the Usage Patterns Guide: - Function caching patterns - Auto-invalidation strategies - Fuzzy search capabilities</p>"},{"location":"getting-started/#4-production-monitoring","title":"4. Production Monitoring","text":"<p>Set up comprehensive monitoring with the Monitoring Guide: - Prometheus integration - StatsD metrics - Health checks and alerting</p>"},{"location":"getting-started/#5-vector-search","title":"5. Vector Search","text":"<p>Add semantic search capabilities with the Vector Search Guide: - TF-IDF similarity - Multiple distance metrics - Real-time indexing</p>"},{"location":"getting-started/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/#connection-problems","title":"Connection Problems","text":"<p>If you get connection errors:</p> <pre><code># Test Redis connection\nredis-cli ping\n\n# Check Redis is running\ndocker ps | grep redis\n\n# Test YokedCache connection\nyokedcache ping --redis-url redis://localhost:6379/0\n</code></pre>"},{"location":"getting-started/#import-errors","title":"Import Errors","text":"<p>If imports fail:</p> <pre><code># Verify installation\npip list | grep yokedcache\n\n# Reinstall if needed\npip uninstall yokedcache\npip install yokedcache[full]\n</code></pre>"},{"location":"getting-started/#performance-issues","title":"Performance Issues","text":"<p>For slow cache operations:</p> <pre><code># Check cache statistics\nyokedcache stats\n\n# Monitor operations\nyokedcache stats --watch\n\n# Check Redis performance\nredis-cli --latency\n</code></pre>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Explore the full documentation for detailed guides</li> <li>Examples: Check the <code>examples/</code> directory for complete working examples</li> <li>CLI Help: Run <code>yokedcache --help</code> for command-line assistance</li> <li>Issues: Report bugs or request features on GitHub</li> </ul> <p>You're now ready to use YokedCache effectively! Start with simple function caching and gradually explore advanced features as your needs grow.</p>"},{"location":"monitoring/","title":"Production Monitoring &amp; Health Checks","text":"<p>YokedCache v0.2.1 includes comprehensive monitoring, health checking, and metrics collection capabilities for production environments. Monitor cache performance, track detailed metrics, and set up alerts using industry-standard tools like Prometheus and StatsD.</p>"},{"location":"monitoring/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Health Checks</li> <li>Metrics Collection</li> <li>Metrics Collectors</li> <li>Prometheus Integration</li> <li>StatsD Integration</li> <li>Custom Metrics</li> <li>Dashboards and Alerting</li> <li>Performance Monitoring</li> <li>Real-time Performance Tracking</li> <li>Alerting and Notifications</li> </ul>"},{"location":"monitoring/#overview","title":"Overview","text":"<p>The monitoring system provides real-time insights into your cache performance through multiple metrics collectors that can run simultaneously. Whether you're using Prometheus for metrics collection or StatsD for real-time monitoring, YokedCache adapts to your infrastructure.</p>"},{"location":"monitoring/#key-features","title":"Key Features","text":"<ul> <li>Multiple Collectors: Run Prometheus and StatsD simultaneously</li> <li>Cache Metrics: Hit rates, miss rates, operation latency, memory usage</li> <li>System Metrics: Connection health, error rates, throughput</li> <li>Custom Metrics: Add your own application-specific metrics</li> <li>Zero Configuration: Works out of the box with sensible defaults</li> <li>Production Ready: Designed for high-performance production environments</li> </ul>"},{"location":"monitoring/#available-metrics","title":"Available Metrics","text":"Metric Type Description <code>cache.gets.total</code> Counter Total number of GET operations <code>cache.sets.total</code> Counter Total number of SET operations <code>cache.deletes.total</code> Counter Total number of DELETE operations <code>cache.hits.total</code> Counter Total number of cache hits <code>cache.misses.total</code> Counter Total number of cache misses <code>cache.hit_rate</code> Gauge Current cache hit rate (0-1) <code>cache.size_bytes</code> Gauge Current memory usage in bytes <code>cache.keys_count</code> Gauge Current number of cached keys <code>cache.operation_duration</code> Histogram Operation latency distribution <code>cache.invalidations.total</code> Counter Total number of invalidations"},{"location":"monitoring/#health-checks","title":"Health Checks","text":""},{"location":"monitoring/#basic-health-check","title":"Basic Health Check","text":"<pre><code>from yokedcache import YokedCache\n\ncache = YokedCache()\n\n# Simple health check\nis_healthy = await cache.health()\nprint(f\"Cache is healthy: {is_healthy}\")\n</code></pre>"},{"location":"monitoring/#detailed-health-check-v021","title":"Detailed Health Check v0.2.1","text":"<p>Get comprehensive health information including connection status, pool statistics, and performance metrics:</p> <pre><code># Detailed health check with full diagnostics\nhealth_info = await cache.detailed_health_check()\n\nprint(f\"Status: {health_info['status']}\")\nprint(f\"Redis connected: {health_info['redis_connected']}\")\nprint(f\"Connection pool: {health_info['connection_pool']}\")\nprint(f\"Circuit breaker: {health_info['circuit_breaker']}\")\nprint(f\"Performance metrics: {health_info['performance_metrics']}\")\n</code></pre>"},{"location":"monitoring/#metrics-collection","title":"Metrics Collection","text":""},{"location":"monitoring/#enabling-metrics","title":"Enabling Metrics","text":"<pre><code>from yokedcache import YokedCache, CacheConfig\n\nconfig = CacheConfig(\n    enable_metrics=True,\n    metrics_retention_days=7\n)\n\ncache = YokedCache(config=config)\ncache.start_metrics_collection()\n</code></pre>"},{"location":"monitoring/#accessing-metrics","title":"Accessing Metrics","text":"<pre><code># Get current metrics snapshot\nmetrics = cache.get_comprehensive_metrics()\n\nprint(f\"Hit rate: {metrics.hit_rate:.2%}\")\nprint(f\"Average response time: {metrics.avg_response_time:.3f}s\")\nprint(f\"Total operations: {metrics.total_operations}\")\n</code></pre>"},{"location":"monitoring/#metrics-collectors","title":"Metrics Collectors","text":""},{"location":"monitoring/#basic-setup","title":"Basic Setup","text":"<pre><code>from yokedcache import YokedCache, CacheConfig\nfrom yokedcache.backends import RedisBackend\nfrom yokedcache.monitoring import CacheMetrics, PrometheusCollector, StatsDCollector\n\n# Setup backend\nbackend = RedisBackend(redis_url=\"redis://localhost:6379/0\")\n\n# Setup monitoring\nmetrics = CacheMetrics([\n    PrometheusCollector(namespace=\"myapp\", port=8000),\n    StatsDCollector(host=\"localhost\", port=8125, prefix=\"myapp.cache\")\n])\n\n# Create cache with monitoring\nconfig = CacheConfig(backend=backend, metrics=metrics)\ncache = YokedCache(config)\n</code></pre>"},{"location":"monitoring/#no-op-collector-default","title":"No-Op Collector (Default)","text":"<pre><code>from yokedcache.monitoring import CacheMetrics, NoOpCollector\n\n# Default behavior - no metrics collection\nmetrics = CacheMetrics()  # Uses NoOpCollector by default\n\n# Explicit no-op collector\nmetrics = CacheMetrics([NoOpCollector()])\n</code></pre> <p>The NoOpCollector allows you to disable metrics collection without changing your application code.</p>"},{"location":"monitoring/#prometheus-integration","title":"Prometheus Integration","text":""},{"location":"monitoring/#installation","title":"Installation","text":"<pre><code># Install Prometheus dependencies\npip install yokedcache[monitoring]\n\n# Or install manually\npip install prometheus_client\n</code></pre>"},{"location":"monitoring/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from yokedcache.monitoring import PrometheusCollector\n\n# Basic Prometheus setup\nprometheus_collector = PrometheusCollector(\n    namespace=\"yokedcache\",    # Metric prefix\n    port=8000,                 # HTTP port for metrics endpoint\n    registry=None              # Use default registry\n)\n\n# Custom configuration\nprometheus_collector = PrometheusCollector(\n    namespace=\"myapp_cache\",\n    port=9090,\n    subsystem=\"backend\",       # Additional prefix\n    labels={\"environment\": \"production\", \"service\": \"api\"}\n)\n</code></pre>"},{"location":"monitoring/#metrics-endpoint","title":"Metrics Endpoint","text":"<p>The Prometheus collector automatically exposes metrics on the specified port:</p> <pre><code># View metrics\ncurl http://localhost:8000/metrics\n\n# Example output:\n# HELP yokedcache_cache_gets_total Total number of cache GET operations\n# TYPE yokedcache_cache_gets_total counter\nyokedcache_cache_gets_total{result=\"hit\"} 1247.0\nyokedcache_cache_gets_total{result=\"miss\"} 153.0\n\n# HELP yokedcache_cache_hit_rate Current cache hit rate\n# TYPE yokedcache_cache_hit_rate gauge\nyokedcache_cache_hit_rate 0.89\n\n# HELP yokedcache_cache_operation_duration_seconds Cache operation duration\n# TYPE yokedcache_cache_operation_duration_seconds histogram\nyokedcache_cache_operation_duration_seconds_bucket{operation=\"get\",le=\"0.001\"} 1024.0\nyokedcache_cache_operation_duration_seconds_bucket{operation=\"get\",le=\"0.01\"} 1389.0\n</code></pre>"},{"location":"monitoring/#custom-labels-and-registry","title":"Custom Labels and Registry","text":"<pre><code>from prometheus_client import CollectorRegistry\nfrom yokedcache.monitoring import PrometheusCollector\n\n# Custom registry for isolation\ncustom_registry = CollectorRegistry()\n\ncollector = PrometheusCollector(\n    namespace=\"myapp\",\n    port=8001,\n    registry=custom_registry,\n    labels={\n        \"environment\": \"production\",\n        \"region\": \"us-east-1\",\n        \"service\": \"user-service\"\n    }\n)\n</code></pre>"},{"location":"monitoring/#statsd-integration","title":"StatsD Integration","text":""},{"location":"monitoring/#installation_1","title":"Installation","text":"<pre><code># Install StatsD dependencies\npip install yokedcache[monitoring]\n\n# Or install manually\npip install statsd\n</code></pre>"},{"location":"monitoring/#basic-configuration_1","title":"Basic Configuration","text":"<pre><code>from yokedcache.monitoring import StatsDCollector\n\n# Basic StatsD setup\nstatsd_collector = StatsDCollector(\n    host=\"localhost\",\n    port=8125,\n    prefix=\"yokedcache\"\n)\n\n# Advanced configuration\nstatsd_collector = StatsDCollector(\n    host=\"statsd.example.com\",\n    port=8125,\n    prefix=\"myapp.cache\",\n    sample_rate=1.0,           # Sample all metrics\n    timeout=5.0                # Socket timeout\n)\n</code></pre>"},{"location":"monitoring/#datadog-integration","title":"DataDog Integration","text":"<pre><code># DataDog StatsD configuration\nstatsd_collector = StatsDCollector(\n    host=\"localhost\",\n    port=8125,\n    prefix=\"myapp.cache\",\n    use_tags=True              # Enable DataDog-style tags\n)\n</code></pre>"},{"location":"monitoring/#metric-examples","title":"Metric Examples","text":"<p>StatsD metrics are sent in real-time:</p> <pre><code># Counter metrics\nmyapp.cache.gets:1|c|#result:hit\nmyapp.cache.gets:1|c|#result:miss\nmyapp.cache.sets:1|c\n\n# Gauge metrics\nmyapp.cache.hit_rate:0.89|g\nmyapp.cache.size_bytes:1048576|g\nmyapp.cache.keys_count:1500|g\n\n# Histogram metrics\nmyapp.cache.operation_duration:0.002|h|#operation:get\nmyapp.cache.operation_duration:0.005|h|#operation:set\n</code></pre>"},{"location":"monitoring/#custom-metrics","title":"Custom Metrics","text":""},{"location":"monitoring/#adding-custom-collectors","title":"Adding Custom Collectors","text":"<pre><code>from yokedcache.monitoring import CacheMetrics\nimport asyncio\n\nclass CustomMetricsCollector:\n    \"\"\"Custom metrics collector example.\"\"\"\n\n    def __init__(self, webhook_url: str):\n        self.webhook_url = webhook_url\n\n    async def increment(self, metric: str, value: float = 1, tags: dict = None):\n        \"\"\"Send increment to webhook.\"\"\"\n        data = {\n            \"type\": \"increment\",\n            \"metric\": metric,\n            \"value\": value,\n            \"tags\": tags or {},\n            \"timestamp\": time.time()\n        }\n        # Send to webhook (implementation depends on your system)\n        await self._send_webhook(data)\n\n    async def gauge(self, metric: str, value: float, tags: dict = None):\n        \"\"\"Send gauge to webhook.\"\"\"\n        data = {\n            \"type\": \"gauge\",\n            \"metric\": metric,\n            \"value\": value,\n            \"tags\": tags or {},\n            \"timestamp\": time.time()\n        }\n        await self._send_webhook(data)\n\n    async def histogram(self, metric: str, value: float, tags: dict = None):\n        \"\"\"Send histogram to webhook.\"\"\"\n        # Implementation for histogram metrics\n        pass\n\n    async def timing(self, metric: str, value: float, tags: dict = None):\n        \"\"\"Send timing to webhook.\"\"\"\n        # Implementation for timing metrics\n        pass\n\n    async def _send_webhook(self, data: dict):\n        \"\"\"Send data to webhook endpoint.\"\"\"\n        # Implement webhook sending logic\n        pass\n\n# Use custom collector\ncustom_collector = CustomMetricsCollector(\"https://metrics.example.com/webhook\")\nmetrics = CacheMetrics([custom_collector])\n</code></pre>"},{"location":"monitoring/#application-specific-metrics","title":"Application-Specific Metrics","text":"<pre><code>async def track_business_metrics(cache_metrics: CacheMetrics):\n    \"\"\"Track business-specific metrics.\"\"\"\n\n    # Track user actions\n    await cache_metrics.increment(\n        \"user.login\",\n        tags={\"source\": \"api\", \"method\": \"oauth\"}\n    )\n\n    # Track application state\n    await cache_metrics.gauge(\n        \"active_sessions\",\n        value=get_active_session_count(),\n        tags={\"server\": \"web-01\"}\n    )\n\n    # Track request processing time\n    timer_id = cache_metrics.start_timer(\"request_processing\")\n\n    # ... process request ...\n\n    await cache_metrics.end_timer(timer_id, \"request_processing\", {\n        \"endpoint\": \"/api/users\",\n        \"status_code\": \"200\"\n    })\n</code></pre>"},{"location":"monitoring/#dashboards-and-alerting","title":"Dashboards and Alerting","text":""},{"location":"monitoring/#prometheus-grafana-dashboard","title":"Prometheus + Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"YokedCache Monitoring\",\n    \"panels\": [\n      {\n        \"title\": \"Cache Hit Rate\",\n        \"type\": \"singlestat\",\n        \"targets\": [\n          {\n            \"expr\": \"yokedcache_cache_hit_rate\",\n            \"format\": \"time_series\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Operations per Second\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(yokedcache_cache_gets_total[5m])\",\n            \"legendFormat\": \"Gets/sec\"\n          },\n          {\n            \"expr\": \"rate(yokedcache_cache_sets_total[5m])\",\n            \"legendFormat\": \"Sets/sec\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Operation Latency\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(yokedcache_cache_operation_duration_seconds_bucket[5m]))\",\n            \"legendFormat\": \"95th percentile\"\n          },\n          {\n            \"expr\": \"histogram_quantile(0.50, rate(yokedcache_cache_operation_duration_seconds_bucket[5m]))\",\n            \"legendFormat\": \"Median\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"monitoring/#prometheus-alerting-rules","title":"Prometheus Alerting Rules","text":"<pre><code># prometheus-alerts.yml\ngroups:\n- name: yokedcache\n  rules:\n  - alert: CacheHitRateLow\n    expr: yokedcache_cache_hit_rate &lt; 0.8\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Cache hit rate is below 80%\"\n      description: \"Cache hit rate is {{ $value | humanizePercentage }}\"\n\n  - alert: CacheOperationLatencyHigh\n    expr: histogram_quantile(0.95, rate(yokedcache_cache_operation_duration_seconds_bucket[5m])) &gt; 0.1\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Cache operation latency is high\"\n      description: \"95th percentile latency is {{ $value }}s\"\n\n  - alert: CacheMemoryUsageHigh\n    expr: yokedcache_cache_size_bytes &gt; 1000000000  # 1GB\n    for: 1m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Cache memory usage is high\"\n      description: \"Cache is using {{ $value | humanizeBytes }} of memory\"\n</code></pre>"},{"location":"monitoring/#datadog-dashboard","title":"DataDog Dashboard","text":"<pre><code># datadog_dashboard.py\nfrom datadog import initialize, api\n\n# Setup DataDog\ninitialize(api_key='your-api-key', app_key='your-app-key')\n\n# Create dashboard\ndashboard = {\n    'title': 'YokedCache Monitoring',\n    'description': 'Monitor YokedCache performance and health',\n    'widgets': [\n        {\n            'definition': {\n                'type': 'timeseries',\n                'title': 'Cache Hit Rate',\n                'requests': [\n                    {\n                        'q': 'avg:myapp.cache.hit_rate{*}',\n                        'display_type': 'line'\n                    }\n                ]\n            }\n        },\n        {\n            'definition': {\n                'type': 'timeseries',\n                'title': 'Cache Operations',\n                'requests': [\n                    {\n                        'q': 'sum:myapp.cache.gets{*}.as_rate()',\n                        'display_type': 'line'\n                    },\n                    {\n                        'q': 'sum:myapp.cache.sets{*}.as_rate()',\n                        'display_type': 'line'\n                    }\n                ]\n            }\n        }\n    ]\n}\n\napi.Dashboard.create(dashboard=dashboard)\n</code></pre>"},{"location":"monitoring/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"monitoring/#health-monitoring","title":"Health Monitoring","text":"<pre><code>import asyncio\nimport time\nfrom yokedcache.monitoring import CacheMetrics\n\nclass CacheHealthMonitor:\n    \"\"\"Monitor cache health and performance.\"\"\"\n\n    def __init__(self, cache: YokedCache, metrics: CacheMetrics):\n        self.cache = cache\n        self.metrics = metrics\n        self.monitoring = True\n\n    async def start_monitoring(self, interval: int = 60):\n        \"\"\"Start health monitoring loop.\"\"\"\n        while self.monitoring:\n            await self._collect_health_metrics()\n            await asyncio.sleep(interval)\n\n    async def _collect_health_metrics(self):\n        \"\"\"Collect and report health metrics.\"\"\"\n        try:\n            # Check backend health\n            start_time = time.time()\n            is_healthy = await self.cache.health_check()\n            response_time = time.time() - start_time\n\n            # Report health metrics\n            await self.metrics.gauge(\"cache.health\", 1.0 if is_healthy else 0.0)\n            await self.metrics.timing(\"cache.health_check_duration\", response_time)\n\n            if is_healthy:\n                # Collect performance metrics\n                stats = await self.cache.get_stats()\n\n                await self.metrics.gauge(\"cache.hit_rate\", stats.hit_rate)\n                await self.metrics.gauge(\"cache.size_bytes\", stats.total_memory_bytes)\n                await self.metrics.gauge(\"cache.keys_count\", stats.total_keys)\n                await self.metrics.gauge(\"cache.uptime_seconds\", stats.uptime_seconds)\n\n        except Exception as e:\n            await self.metrics.increment(\"cache.health_check_errors\")\n            print(f\"Health check failed: {e}\")\n\n    def stop_monitoring(self):\n        \"\"\"Stop health monitoring.\"\"\"\n        self.monitoring = False\n\n# Usage\nmonitor = CacheHealthMonitor(cache, metrics)\nasyncio.create_task(monitor.start_monitoring(interval=30))\n</code></pre>"},{"location":"monitoring/#performance-benchmarking","title":"Performance Benchmarking","text":"<pre><code>import asyncio\nimport statistics\nimport time\n\nasync def benchmark_cache_performance(cache: YokedCache, metrics: CacheMetrics):\n    \"\"\"Benchmark cache performance and report metrics.\"\"\"\n\n    # Warm up cache\n    print(\"Warming up cache...\")\n    for i in range(1000):\n        await cache.set(f\"benchmark:warm:{i}\", f\"value_{i}\")\n\n    # Benchmark GET operations\n    print(\"Benchmarking GET operations...\")\n    get_times = []\n\n    for i in range(1000):\n        start = time.time()\n        await cache.get(f\"benchmark:warm:{i % 1000}\")\n        get_times.append(time.time() - start)\n\n    # Report GET performance\n    await metrics.gauge(\"benchmark.get.avg_latency\", statistics.mean(get_times))\n    await metrics.gauge(\"benchmark.get.p95_latency\", statistics.quantiles(get_times, n=20)[18])\n    await metrics.gauge(\"benchmark.get.p99_latency\", statistics.quantiles(get_times, n=100)[98])\n\n    # Benchmark SET operations\n    print(\"Benchmarking SET operations...\")\n    set_times = []\n\n    for i in range(1000):\n        start = time.time()\n        await cache.set(f\"benchmark:set:{i}\", f\"benchmark_value_{i}\")\n        set_times.append(time.time() - start)\n\n    # Report SET performance\n    await metrics.gauge(\"benchmark.set.avg_latency\", statistics.mean(set_times))\n    await metrics.gauge(\"benchmark.set.p95_latency\", statistics.quantiles(set_times, n=20)[18])\n    await metrics.gauge(\"benchmark.set.p99_latency\", statistics.quantiles(set_times, n=100)[98])\n\n    # Calculate throughput\n    total_ops = len(get_times) + len(set_times)\n    total_time = max(get_times) + max(set_times)\n    throughput = total_ops / total_time\n\n    await metrics.gauge(\"benchmark.throughput_ops_per_sec\", throughput)\n\n    print(f\"Benchmark complete:\")\n    print(f\"  GET avg: {statistics.mean(get_times)*1000:.2f}ms\")\n    print(f\"  SET avg: {statistics.mean(set_times)*1000:.2f}ms\")\n    print(f\"  Throughput: {throughput:.0f} ops/sec\")\n</code></pre>"},{"location":"monitoring/#error-rate-monitoring","title":"Error Rate Monitoring","text":"<pre><code>class ErrorTrackingMetrics:\n    \"\"\"Track and report error rates.\"\"\"\n\n    def __init__(self, metrics: CacheMetrics):\n        self.metrics = metrics\n        self.error_counts = {}\n\n    async def track_error(self, operation: str, error_type: str, error: Exception):\n        \"\"\"Track an error occurrence.\"\"\"\n        error_key = f\"{operation}.{error_type}\"\n\n        await self.metrics.increment(\"cache.errors.total\", tags={\n            \"operation\": operation,\n            \"error_type\": error_type,\n            \"error_class\": error.__class__.__name__\n        })\n\n        # Track error rate\n        self.error_counts[error_key] = self.error_counts.get(error_key, 0) + 1\n\n    async def calculate_error_rates(self, total_operations: dict):\n        \"\"\"Calculate and report error rates.\"\"\"\n        for error_key, error_count in self.error_counts.items():\n            operation = error_key.split('.')[0]\n            total_ops = total_operations.get(operation, 1)\n            error_rate = error_count / total_ops\n\n            await self.metrics.gauge(f\"cache.error_rate.{operation}\", error_rate)\n\n# Usage with cache operations\nerror_tracker = ErrorTrackingMetrics(metrics)\n\nasync def safe_cache_get(key: str):\n    \"\"\"Cache GET with error tracking.\"\"\"\n    try:\n        return await cache.get(key)\n    except ConnectionError as e:\n        await error_tracker.track_error(\"get\", \"connection\", e)\n        return None\n    except Exception as e:\n        await error_tracker.track_error(\"get\", \"unknown\", e)\n        return None\n</code></pre>"},{"location":"monitoring/#real-time-performance-tracking","title":"Real-time Performance Tracking","text":"<p>Monitor performance in real-time and alert on issues:</p> <pre><code># Monitor performance in real-time\nasync def monitor_cache_performance():\n    while True:\n        metrics = cache.get_comprehensive_metrics()\n\n        # Alert on poor performance\n        if metrics.hit_rate &lt; 0.70:\n            await send_alert(f\"Low hit rate: {metrics.hit_rate:.2%}\")\n\n        if metrics.avg_response_time &gt; 0.100:\n            await send_alert(f\"High latency: {metrics.avg_response_time:.3f}s\")\n\n        if metrics.error_rate &gt; 0.01:\n            await send_alert(f\"High error rate: {metrics.error_rate:.3%}\")\n\n        await asyncio.sleep(30)  # Check every 30 seconds\n</code></pre>"},{"location":"monitoring/#alerting-and-notifications","title":"Alerting and Notifications","text":""},{"location":"monitoring/#configuring-alerts","title":"Configuring Alerts","text":"<p>Set up automated alerting based on metrics thresholds:</p> <pre><code>from yokedcache.monitoring import AlertManager\n\nalert_manager = AlertManager(cache)\n\n# Configure alert thresholds\nalert_manager.add_alert(\n    name=\"low_hit_rate\",\n    metric=\"hit_rate\",\n    threshold=0.70,\n    comparison=\"less_than\",\n    webhook_url=\"https://your-webhook.com/alerts\"\n)\n\nalert_manager.add_alert(\n    name=\"high_latency\",\n    metric=\"avg_response_time\",\n    threshold=0.100,\n    comparison=\"greater_than\",\n    email_recipients=[\"admin@yourcompany.com\"]\n)\n\n# Start monitoring\nalert_manager.start()\n</code></pre>"},{"location":"monitoring/#common-alert-patterns","title":"Common Alert Patterns","text":"<p>Performance Alerts: - Hit rate below 70% - Average response time above 100ms - Error rate above 1%</p> <p>Availability Alerts: - Redis connection failures - Circuit breaker opened - Connection pool exhaustion</p> <p>Capacity Alerts: - Memory usage above 80% - Connection pool utilization above 90% - Cache eviction rate above threshold</p> <p>Production monitoring with YokedCache provides comprehensive visibility and insights needed to maintain high-performance caching systems. Use these tools to optimize performance, detect issues early, and ensure reliable operation in production environments.</p>"},{"location":"performance/","title":"Performance","text":""},{"location":"performance/#redis","title":"Redis","text":"<ul> <li>Use a dedicated Redis instance; avoid shared noisy neighbors.</li> <li>Increase <code>max_connections</code> for high concurrency.</li> <li>Prefer cluster or read replicas for scale.</li> </ul>"},{"location":"performance/#ttl-jitter","title":"TTL &amp; jitter","text":"<ul> <li>Tune TTL per table: hot data short TTL; cold data longer.</li> <li>Keep jitter (default 10%) to avoid synchronized expirations.</li> </ul>"},{"location":"performance/#keys","title":"Keys","text":"<ul> <li>Keep keys compact but descriptive.</li> <li>Avoid storing huge values; consider pagination or partial caching.</li> </ul>"},{"location":"performance/#serialization","title":"Serialization","text":"<ul> <li>JSON is portable; PICKLE/MSGPACK can be faster for complex types.</li> <li>Benchmark with realistic payloads.</li> </ul>"},{"location":"performance/#async-usage","title":"Async usage","text":"<ul> <li>Reuse a single <code>YokedCache</code> instance; avoid reconnecting per request.</li> <li>Use pipeline where appropriate (handled internally for set/tag ops).</li> </ul>"},{"location":"security/","title":"Security","text":"<ul> <li>Use <code>rediss://</code> and TLS-enabled Redis in production.</li> <li>Limit Redis access to your VPC/private network; avoid public endpoints.</li> <li>For multi-tenant apps, include tenant namespace in keys and enforce isolation.</li> <li>Avoid caching sensitive data unless encrypted; consider encrypt-at-rest.</li> <li>Rotate credentials; prefer ACL users per service.</li> <li>Validate untrusted input that can influence keys to prevent key scanning attacks.</li> </ul>"},{"location":"testing/","title":"Testing Guide","text":"<p>This guide covers testing YokedCache, including running the test suite, writing custom tests, and validating new features.</p>"},{"location":"testing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Quick Start</li> <li>Test Structure</li> <li>Running Tests</li> <li>Writing Tests</li> <li>Testing New Features</li> <li>Continuous Integration</li> <li>Troubleshooting</li> </ul>"},{"location":"testing/#quick-start","title":"Quick Start","text":""},{"location":"testing/#prerequisites","title":"Prerequisites","text":"<p>Install the development dependencies:</p> <pre><code># Install with development dependencies\npip install -e \".[dev]\"\n\n# Or install manually\npip install pytest pytest-asyncio pytest-cov fakeredis\n</code></pre>"},{"location":"testing/#quick-verification","title":"Quick Verification","text":"<p>Run the quick verification script to test all features:</p> <pre><code>python test_quick_verification.py\n</code></pre> <p>This script tests: - \u2705 Basic YokedCache functionality - \u2705 Memory backend operations - \u2705 Vector similarity search - \u2705 Monitoring integrations - \u2705 Backend imports and availability</p>"},{"location":"testing/#full-test-suite","title":"Full Test Suite","text":"<p>Run the complete test suite:</p> <pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=yokedcache\n\n# Run specific test modules\npytest tests/test_backends.py\npytest tests/test_vector_search.py\npytest tests/test_monitoring.py\n</code></pre>"},{"location":"testing/#test-structure","title":"Test Structure","text":"<p>The test suite is organized by functionality:</p> <pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared fixtures and configuration\n\u251c\u2500\u2500 test_cache.py            # Core cache functionality tests\n\u251c\u2500\u2500 test_backends.py         # Backend implementation tests\n\u251c\u2500\u2500 test_decorators.py       # Decorator tests\n\u251c\u2500\u2500 test_vector_search.py    # Vector search tests\n\u251c\u2500\u2500 test_monitoring.py       # Monitoring and metrics tests\n\u2514\u2500\u2500 test_cli.py             # CLI functionality tests\n</code></pre>"},{"location":"testing/#test-categories","title":"Test Categories","text":""},{"location":"testing/#unit-tests","title":"Unit Tests","text":"<ul> <li>Individual component testing</li> <li>Mock external dependencies</li> <li>Fast execution (&lt; 1 second per test)</li> </ul>"},{"location":"testing/#integration-tests","title":"Integration Tests","text":"<ul> <li>Cross-component functionality</li> <li>Real backend connections (when available)</li> <li>End-to-end workflows</li> </ul>"},{"location":"testing/#feature-tests","title":"Feature Tests","text":"<ul> <li>New feature validation</li> <li>Edge case coverage</li> <li>Performance benchmarks</li> </ul>"},{"location":"testing/#running-tests","title":"Running Tests","text":""},{"location":"testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\npytest\n\n# Run with verbose output\npytest -v\n\n# Run specific test file\npytest tests/test_backends.py\n\n# Run specific test class\npytest tests/test_backends.py::TestMemoryBackend\n\n# Run specific test method\npytest tests/test_backends.py::TestMemoryBackend::test_memory_backend_connection\n</code></pre>"},{"location":"testing/#test-configuration","title":"Test Configuration","text":"<pre><code># Run with coverage reporting\npytest --cov=yokedcache --cov-report=html\n\n# Run with specific markers\npytest -m \"not slow\"\n\n# Run with parallel execution\npytest -n auto\n\n# Stop on first failure\npytest -x\n\n# Show local variables on failure\npytest -l --tb=long\n</code></pre>"},{"location":"testing/#environment-specific-testing","title":"Environment-Specific Testing","text":""},{"location":"testing/#testing-with-redis","title":"Testing with Redis","text":"<pre><code># Start Redis (Docker)\ndocker run -d -p 6379:6379 redis:alpine\n\n# Run Redis-dependent tests\npytest tests/test_backends.py::TestRedisBackend\n</code></pre>"},{"location":"testing/#testing-with-memcached","title":"Testing with Memcached","text":"<pre><code># Start Memcached (Docker)\ndocker run -d -p 11211:11211 memcached:alpine\n\n# Run Memcached tests\npytest tests/test_backends.py::TestMemcachedBackend\n</code></pre>"},{"location":"testing/#testing-optional-dependencies","title":"Testing Optional Dependencies","text":"<pre><code># Test vector search features\npytest tests/test_vector_search.py\n\n# Test monitoring features\npytest tests/test_monitoring.py\n\n# Skip tests for missing dependencies\npytest --disable-warnings\n</code></pre>"},{"location":"testing/#writing-tests","title":"Writing Tests","text":""},{"location":"testing/#test-structure_1","title":"Test Structure","text":"<p>Follow this structure for new tests:</p> <pre><code>import pytest\nfrom unittest.mock import Mock, AsyncMock, patch\n\nfrom yokedcache import YokedCache\nfrom yokedcache.backends import MemoryBackend\n\n\nclass TestNewFeature:\n    \"\"\"Test new feature functionality.\"\"\"\n\n    @pytest.fixture\n    async def setup_feature(self):\n        \"\"\"Setup test environment.\"\"\"\n        # Setup code\n        yield test_object\n        # Cleanup code\n\n    @pytest.mark.asyncio\n    async def test_basic_functionality(self, setup_feature):\n        \"\"\"Test basic feature operation.\"\"\"\n        # Arrange\n        test_data = {\"key\": \"value\"}\n\n        # Act\n        result = await setup_feature.method(test_data)\n\n        # Assert\n        assert result is not None\n        assert isinstance(result, expected_type)\n\n    @pytest.mark.asyncio\n    async def test_error_handling(self, setup_feature):\n        \"\"\"Test error conditions.\"\"\"\n        with pytest.raises(ExpectedException):\n            await setup_feature.method(invalid_data)\n</code></pre>"},{"location":"testing/#async-testing","title":"Async Testing","text":"<p>Use <code>pytest.mark.asyncio</code> for async tests:</p> <pre><code>@pytest.mark.asyncio\nasync def test_async_operation():\n    \"\"\"Test asynchronous operation.\"\"\"\n    backend = MemoryBackend()\n    await backend.connect()\n\n    result = await backend.set(\"key\", \"value\")\n    assert result is True\n\n    await backend.disconnect()\n</code></pre>"},{"location":"testing/#mocking-external-dependencies","title":"Mocking External Dependencies","text":"<p>Mock external services and dependencies:</p> <pre><code>@pytest.mark.asyncio\nasync def test_with_mocked_redis():\n    \"\"\"Test with mocked Redis.\"\"\"\n    with patch('redis.asyncio.Redis') as mock_redis_class:\n        mock_redis = AsyncMock()\n        mock_redis.ping = AsyncMock()\n        mock_redis_class.return_value = mock_redis\n\n        backend = RedisBackend()\n        await backend.connect()\n\n        mock_redis.ping.assert_called_once()\n</code></pre>"},{"location":"testing/#testing-optional-features","title":"Testing Optional Features","text":"<p>Handle optional dependencies gracefully:</p> <pre><code>@pytest.mark.skipif(\n    not pytest.importorskip(\"numpy\", reason=\"numpy not available\"),\n    reason=\"Vector search dependencies not available\"\n)\ndef test_vector_search_feature():\n    \"\"\"Test vector search when dependencies are available.\"\"\"\n    from yokedcache.vector_search import VectorSimilaritySearch\n\n    search = VectorSimilaritySearch()\n    # Test implementation\n</code></pre>"},{"location":"testing/#testing-new-features","title":"Testing New Features","text":""},{"location":"testing/#backend-testing","title":"Backend Testing","text":"<p>When adding a new backend:</p> <ol> <li>Create backend tests in <code>tests/test_backends.py</code></li> <li>Test interface compliance - ensure all abstract methods are implemented</li> <li>Test error handling - connection failures, timeouts, etc.</li> <li>Test performance - basic benchmarks for operations</li> </ol> <pre><code>class TestNewBackend:\n    \"\"\"Test new backend implementation.\"\"\"\n\n    @pytest.fixture\n    async def backend(self):\n        \"\"\"Create backend instance.\"\"\"\n        backend = NewBackend(config_params)\n        await backend.connect()\n        yield backend\n        await backend.disconnect()\n\n    @pytest.mark.asyncio\n    async def test_interface_compliance(self, backend):\n        \"\"\"Test that backend implements required interface.\"\"\"\n        # Test all CacheBackend methods\n        assert await backend.health_check()\n        assert await backend.set(\"key\", \"value\")\n        assert await backend.get(\"key\") == \"value\"\n        assert await backend.delete(\"key\")\n</code></pre>"},{"location":"testing/#feature-testing","title":"Feature Testing","text":"<p>For new cache features:</p> <ol> <li>Unit tests - individual components</li> <li>Integration tests - feature interaction with cache</li> <li>Edge case tests - boundary conditions</li> <li>Performance tests - ensure no regression</li> </ol>"},{"location":"testing/#cli-testing","title":"CLI Testing","text":"<p>Test CLI functionality with Click's test runner:</p> <pre><code>from click.testing import CliRunner\nfrom yokedcache.cli import cli\n\ndef test_cli_command():\n    \"\"\"Test CLI command execution.\"\"\"\n    runner = CliRunner()\n    result = runner.invoke(cli, ['stats', '--format', 'json'])\n\n    assert result.exit_code == 0\n    assert 'total_hits' in result.output\n</code></pre>"},{"location":"testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"testing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Install and configure pre-commit hooks:</p> <pre><code># Install pre-commit\npip install pre-commit\n\n# Install hooks\npre-commit install\n\n# Run manually\npre-commit run --all-files\n</code></pre> <p>The <code>.pre-commit-config.yaml</code> includes: - Black - Code formatting - isort - Import sorting - MyPy - Type checking - Pytest - Test execution</p>"},{"location":"testing/#ci-pipeline","title":"CI Pipeline","text":"<p>The CI pipeline runs:</p> <ol> <li>Code Quality Checks</li> <li>Black formatting</li> <li>Import sorting</li> <li>Type checking</li> <li> <p>Linting</p> </li> <li> <p>Test Execution</p> </li> <li>Unit tests</li> <li>Integration tests</li> <li> <p>Coverage reporting</p> </li> <li> <p>Feature Validation</p> </li> <li>Optional dependency tests</li> <li>Cross-platform testing</li> <li>Performance benchmarks</li> </ol>"},{"location":"testing/#test-matrix","title":"Test Matrix","text":"<p>Tests run across: - Python versions: 3.8, 3.9, 3.10, 3.11, 3.12 - Operating systems: Ubuntu, Windows, macOS - Dependency sets: minimal, full, optional features</p>"},{"location":"testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"testing/#common-issues","title":"Common Issues","text":""},{"location":"testing/#test-hanging","title":"Test Hanging","text":"<p>If tests hang indefinitely:</p> <pre><code># Run with timeout\npytest --timeout=30\n\n# Run single test to isolate\npytest tests/test_specific.py::test_method -v\n\n# Check for resource leaks\npytest --capture=no\n</code></pre>"},{"location":"testing/#import-errors","title":"Import Errors","text":"<p>For missing dependencies:</p> <pre><code># Check installed packages\npip list\n\n# Install missing dependencies\npip install -r requirements-dev.txt\n\n# Verify imports\npython -c \"import yokedcache; print('OK')\"\n</code></pre>"},{"location":"testing/#mock-issues","title":"Mock Issues","text":"<p>For async mocking problems:</p> <pre><code># Use AsyncMock for async methods\nmock_method = AsyncMock()\n\n# Proper async context manager mocking\nmock_context = AsyncMock()\nmock_context.__aenter__ = AsyncMock(return_value=mock_context)\nmock_context.__aexit__ = AsyncMock(return_value=None)\n</code></pre>"},{"location":"testing/#redis-connection-issues","title":"Redis Connection Issues","text":"<p>For Redis-related test failures:</p> <pre><code># Check Redis availability\nredis-cli ping\n\n# Use fake Redis for tests\npip install fakeredis\n\n# Skip Redis tests if not available\npytest -k \"not redis\"\n</code></pre>"},{"location":"testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"testing/#verbose-output","title":"Verbose Output","text":"<pre><code># Show print statements\npytest -s\n\n# Show local variables on failure\npytest -l\n\n# Full traceback\npytest --tb=long\n\n# Show warnings\npytest -W ignore::DeprecationWarning\n</code></pre>"},{"location":"testing/#test-selection","title":"Test Selection","text":"<pre><code># Run only failed tests\npytest --lf\n\n# Run failed tests first\npytest --ff\n\n# Run tests matching pattern\npytest -k \"test_memory\"\n\n# Run specific markers\npytest -m \"slow\"\n</code></pre>"},{"location":"testing/#coverage-analysis","title":"Coverage Analysis","text":"<pre><code># Generate HTML coverage report\npytest --cov=yokedcache --cov-report=html\n\n# Show missing lines\npytest --cov=yokedcache --cov-report=term-missing\n\n# Fail if coverage below threshold\npytest --cov=yokedcache --cov-fail-under=80\n</code></pre>"},{"location":"testing/#performance-testing","title":"Performance Testing","text":""},{"location":"testing/#benchmarking","title":"Benchmarking","text":"<p>Run performance tests to ensure no regression:</p> <pre><code># Basic performance test\npython -m pytest tests/test_performance.py\n\n# With profiling\npython -m pytest tests/test_performance.py --profile\n\n# Memory usage analysis\npython -m pytest tests/test_performance.py --memray\n</code></pre>"},{"location":"testing/#load-testing","title":"Load Testing","text":"<p>Test with high concurrency:</p> <pre><code>import asyncio\nimport pytest\nfrom yokedcache.backends import MemoryBackend\n\n@pytest.mark.asyncio\nasync def test_concurrent_operations():\n    \"\"\"Test high concurrency operations.\"\"\"\n    backend = MemoryBackend()\n    await backend.connect()\n\n    # Simulate 100 concurrent operations\n    tasks = []\n    for i in range(100):\n        tasks.append(backend.set(f\"key_{i}\", f\"value_{i}\"))\n\n    results = await asyncio.gather(*tasks)\n    assert all(results)\n\n    await backend.disconnect()\n</code></pre>"},{"location":"testing/#best-practices","title":"Best Practices","text":""},{"location":"testing/#test-organization","title":"Test Organization","text":"<ol> <li>Group related tests in classes</li> <li>Use descriptive names for test methods</li> <li>Follow AAA pattern (Arrange, Act, Assert)</li> <li>Keep tests independent - no shared state</li> <li>Use fixtures for common setup</li> </ol>"},{"location":"testing/#test-data","title":"Test Data","text":"<ol> <li>Use realistic data that represents actual usage</li> <li>Test edge cases - empty data, large data, special characters</li> <li>Parameterize tests for multiple input scenarios</li> <li>Mock external services to ensure test reliability</li> </ol>"},{"location":"testing/#maintenance","title":"Maintenance","text":"<ol> <li>Update tests when adding features</li> <li>Remove obsolete tests when refactoring</li> <li>Keep tests fast - use mocks for slow operations</li> <li>Document complex test scenarios</li> <li>Review test coverage regularly</li> </ol> <p>For more information about specific testing scenarios, see the individual test files in the <code>tests/</code> directory. Each file contains comprehensive examples and documentation for testing specific components.</p>"},{"location":"troubleshooting/","title":"Troubleshooting &amp; FAQ","text":""},{"location":"troubleshooting/#common-issues","title":"Common issues","text":""},{"location":"troubleshooting/#cache-not-updating-after-writes","title":"Cache not updating after writes","text":"<ul> <li>Ensure you use <code>cached_dependency</code> and call <code>commit()</code> to trigger invalidation.</li> <li>Pass <code>table_name</code> when wrapping the dependency.</li> </ul>"},{"location":"troubleshooting/#redis-connection-errors","title":"Redis connection errors","text":"<ul> <li>Verify <code>redis_url</code> and network connectivity.</li> <li>Test with <code>yokedcache ping</code>.</li> </ul>"},{"location":"troubleshooting/#serialization-errors","title":"Serialization errors","text":"<ul> <li>Switch serialization: <code>SerializationMethod.PICKLE</code>.</li> <li>Ensure objects are JSON-serializable or provide custom encoders.</li> </ul>"},{"location":"troubleshooting/#keys-not-found","title":"Keys not found","text":"<ul> <li>Confirm <code>key_prefix</code> matches in producer/consumer.</li> <li>Check tags and patterns when invalidating.</li> </ul>"},{"location":"troubleshooting/#faq","title":"FAQ","text":"<ul> <li>How do I disable caching for a route? Call the underlying function directly or set <code>ttl=0</code>.</li> <li>How do I warm the cache? Use <code>warm_cache</code> helper or CLI <code>warm</code> with a config file.</li> <li>Does it work without FastAPI? Yes, use <code>@cached</code> and <code>YokedCache</code> directly.</li> </ul>"},{"location":"usage-patterns/","title":"Usage Patterns","text":"<p>YokedCache offers several patterns for caching data in your applications. Choose the approach that best fits your use case and architectural needs.</p>"},{"location":"usage-patterns/#function-caching","title":"Function Caching","text":"<p>The most straightforward way to add caching to your application is through function decorators.</p>"},{"location":"usage-patterns/#basic-function-caching","title":"Basic Function Caching","text":"<p>Use the <code>@cached</code> decorator to cache function results:</p> <pre><code>from yokedcache import cached\n\n@cached(ttl=600, tags=[\"products\"])\nasync def get_products(category: str, active_only: bool = True):\n    \"\"\"Expensive database query or API call\"\"\"\n    return await database.fetch_products(category, active_only)\n\n# First call hits the database\nproducts = await get_products(\"electronics\", active_only=True)\n\n# Second call returns cached result\nproducts = await get_products(\"electronics\", active_only=True)\n</code></pre>"},{"location":"usage-patterns/#advanced-function-caching","title":"Advanced Function Caching","text":"<p>Customize caching behavior with additional parameters:</p> <pre><code>from yokedcache import cached\nfrom yokedcache.models import SerializationMethod\n\n@cached(\n    ttl=1800,                                    # 30 minutes\n    tags=[\"user_data\", \"api_v1\"],              # Multiple tags\n    serialization=SerializationMethod.PICKLE,   # Custom serialization\n    cache_key_prefix=\"api\"                      # Custom key prefix\n)\nasync def get_user_profile(user_id: int, include_permissions: bool = False):\n    profile = await database.get_user(user_id)\n    if include_permissions:\n        profile.permissions = await database.get_user_permissions(user_id)\n    return profile\n</code></pre>"},{"location":"usage-patterns/#conditional-caching","title":"Conditional Caching","text":"<p>Skip caching based on runtime conditions:</p> <pre><code>@cached(ttl=300, tags=[\"search_results\"])\nasync def search_products(query: str, use_cache: bool = True):\n    if not use_cache:\n        # Skip cache for this call\n        return await perform_live_search(query)\n\n    return await database.search_products(query)\n\n# Force fresh data\nresults = await search_products(\"laptop\", use_cache=False)\n</code></pre>"},{"location":"usage-patterns/#manual-cache-operations","title":"Manual Cache Operations","text":"<p>For more control, use YokedCache directly for manual cache operations.</p>"},{"location":"usage-patterns/#basic-operations","title":"Basic Operations","text":"<pre><code>from yokedcache import YokedCache\n\ncache = YokedCache()\n\n# Store data\nawait cache.set(\"user:123\", {\"name\": \"John\", \"email\": \"john@example.com\"}, ttl=300)\n\n# Retrieve data\nuser = await cache.get(\"user:123\")\n\n# Check if key exists\nexists = await cache.exists(\"user:123\")\n\n# Delete specific key\nawait cache.delete(\"user:123\")\n</code></pre>"},{"location":"usage-patterns/#batch-operations","title":"Batch Operations","text":"<p>Perform multiple operations efficiently:</p> <pre><code># Set multiple keys at once\ndata = {\n    \"user:123\": {\"name\": \"John\"},\n    \"user:124\": {\"name\": \"Jane\"},\n    \"user:125\": {\"name\": \"Bob\"}\n}\nawait cache.set_many(data, ttl=300, tags=[\"user_data\"])\n\n# Get multiple keys\nkeys = [\"user:123\", \"user:124\", \"user:125\"]\nresults = await cache.get_many(keys)\n\n# Delete multiple keys\nawait cache.delete_many(keys)\n</code></pre>"},{"location":"usage-patterns/#tag-based-operations","title":"Tag-Based Operations","text":"<p>Use tags to group and manage related cache entries:</p> <pre><code># Store with tags\nawait cache.set(\"product:1\", product_data, ttl=600, tags=[\"products\", \"category:electronics\"])\nawait cache.set(\"product:2\", product_data, ttl=600, tags=[\"products\", \"category:books\"])\n\n# Invalidate by tags\nawait cache.invalidate_tags([\"products\"])           # Clear all products\nawait cache.invalidate_tags([\"category:electronics\"]) # Clear electronics only\n\n# Pattern-based invalidation\nawait cache.invalidate_pattern(\"user:*\")           # Clear all user data\nawait cache.invalidate_pattern(\"session:temp:*\")   # Clear temporary sessions\n</code></pre>"},{"location":"usage-patterns/#fastapi-integration","title":"FastAPI Integration","text":"<p>YokedCache integrates seamlessly with FastAPI through dependency caching.</p>"},{"location":"usage-patterns/#database-dependency-caching","title":"Database Dependency Caching","text":"<p>Replace your database dependencies with cached versions:</p> <pre><code>from fastapi import FastAPI, Depends\nfrom yokedcache import YokedCache, cached_dependency\n\napp = FastAPI()\ncache = YokedCache()\n\n# Original database dependency\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n# Cached version\ncached_get_db = cached_dependency(get_db, cache=cache, ttl=300, table_name=\"users\")\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db=Depends(cached_get_db)):\n    # Database queries are automatically cached\n    return db.query(User).filter(User.id == user_id).first()\n</code></pre>"},{"location":"usage-patterns/#custom-dependencies","title":"Custom Dependencies","text":"<p>Cache any dependency, not just database connections:</p> <pre><code>from yokedcache import cached_dependency\n\n# Cache external API client\ndef get_external_api():\n    return ExternalAPIClient(api_key=settings.api_key)\n\ncached_api = cached_dependency(get_external_api, cache=cache, ttl=3600)\n\n@app.get(\"/external-data/{resource_id}\")\nasync def get_external_data(resource_id: str, api=Depends(cached_api)):\n    return await api.fetch_resource(resource_id)\n\n# Cache configuration objects\ndef get_config():\n    return load_configuration_from_database()\n\ncached_config = cached_dependency(get_config, cache=cache, ttl=600)\n\n@app.get(\"/settings\")\nasync def get_settings(config=Depends(cached_config)):\n    return config.public_settings\n</code></pre>"},{"location":"usage-patterns/#auto-invalidation","title":"Auto-Invalidation","text":"<p>Auto-invalidation automatically clears cache entries when related data changes, ensuring you never serve stale data.</p>"},{"location":"usage-patterns/#how-auto-invalidation-works","title":"How Auto-Invalidation Works","text":"<ol> <li>Read Operations: Cached with appropriate tags based on tables/entities</li> <li>Write Operations: Tracked and queued for invalidation</li> <li>Transaction Commit: Triggers invalidation of affected tags</li> <li>Cache Cleared: Related entries automatically removed</li> </ol>"},{"location":"usage-patterns/#database-write-tracking","title":"Database Write Tracking","text":"<p>YokedCache automatically tracks database writes and invalidates related cache entries:</p> <pre><code>from yokedcache import YokedCache\nfrom yokedcache.decorators import cached_dependency\n\ncache = YokedCache()\ncached_get_db = cached_dependency(get_db, cache=cache, ttl=300, table_name=\"users\")\n\n# Read operations are cached with \"table:users\" tag\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db=Depends(cached_get_db)):\n    # This query result is cached with tag \"table:users\"\n    return db.query(User).filter(User.id == user_id).first()\n\n# Write operations trigger automatic invalidation\n@app.post(\"/users\")\nasync def create_user(user: UserCreate, db=Depends(cached_get_db)):\n    new_user = User(**user.dict())\n    db.add(new_user)\n    await db.commit()  # Automatically invalidates \"table:users\" tag\n    return new_user\n\n@app.put(\"/users/{user_id}\")\nasync def update_user(user_id: int, user: UserUpdate, db=Depends(cached_get_db)):\n    db.query(User).filter(User.id == user_id).update(user.dict())\n    await db.commit()  # Automatically invalidates \"table:users\" tag\n    return {\"status\": \"updated\"}\n</code></pre>"},{"location":"usage-patterns/#automatic-table-detection","title":"Automatic Table Detection","text":"<p>YokedCache extracts table names from SQL queries automatically:</p> <pre><code># These patterns are automatically detected:\n\"SELECT * FROM users WHERE id = ?\"           # \u2192 table: users\n\"INSERT INTO products (name) VALUES (?)\"     # \u2192 table: products\n\"UPDATE orders SET status = ? WHERE id = ?\"  # \u2192 table: orders\n\"DELETE FROM sessions WHERE expired &lt; ?\"     # \u2192 table: sessions\n\n# Complex JOIN queries\n\"SELECT u.*, p.name FROM users u JOIN profiles p ON u.id = p.user_id\"  # \u2192 tables: users, profiles\n</code></pre>"},{"location":"usage-patterns/#manual-invalidation-control","title":"Manual Invalidation Control","text":"<p>For complex scenarios, manually control invalidation:</p> <pre><code># Specify table explicitly\ncached_get_db = cached_dependency(\n    get_db,\n    cache=cache,\n    ttl=300,\n    table_name=\"users\"  # Explicit table specification\n)\n\n# Multiple table invalidation\n@app.post(\"/users/{user_id}/change-role\")\nasync def change_user_role(user_id: int, role: str, db=Depends(cached_get_db)):\n    # This operation affects both users and permissions\n    db.execute(\"UPDATE users SET role = ? WHERE id = ?\", (role, user_id))\n    db.execute(\"DELETE FROM user_permissions WHERE user_id = ?\", (user_id,))\n\n    # Manually invalidate multiple tables\n    await cache.invalidate_tags([\"table:users\", \"table:user_permissions\"])\n\n    await db.commit()\n    return {\"status\": \"role_changed\"}\n</code></pre>"},{"location":"usage-patterns/#cross-service-invalidation","title":"Cross-Service Invalidation","text":"<p>Invalidate cache across multiple services:</p> <pre><code># Service A: User management\n@app.put(\"/users/{user_id}\")\nasync def update_user(user_id: int, user: UserUpdate):\n    # Update user in database\n    await update_user_in_db(user_id, user)\n\n    # Invalidate user-related cache across all services\n    await cache.invalidate_tags([f\"user:{user_id}\", \"table:users\"])\n\n    # Optionally publish event for other services\n    await publish_user_updated_event(user_id)\n\n# Service B: Order management\n@app.get(\"/orders/user/{user_id}\")\nasync def get_user_orders(user_id: int, db=Depends(cached_get_db)):\n    # This will use fresh user data after the update in Service A\n    return db.query(Order).filter(Order.user_id == user_id).all()\n</code></pre>"},{"location":"usage-patterns/#fuzzy-search","title":"Fuzzy Search","text":"<p>Find approximate matches across cached keys and optionally search within cached values.</p>"},{"location":"usage-patterns/#enabling-fuzzy-search","title":"Enabling Fuzzy Search","text":"<pre><code># Install the fuzzy search dependencies\n# pip install \"yokedcache[fuzzy]\"\n\nfrom yokedcache import YokedCache, CacheConfig\n\n# Enable fuzzy search in configuration\nconfig = CacheConfig(\n    enable_fuzzy=True,\n    fuzzy_threshold=80  # Minimum similarity score (0-100)\n)\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"usage-patterns/#basic-fuzzy-search","title":"Basic Fuzzy Search","text":"<p>Search for approximate matches in cache keys:</p> <pre><code># Store some user data\nawait cache.set(\"user:alice_johnson\", {\"name\": \"Alice Johnson\"}, tags={\"users\"})\nawait cache.set(\"user:bob_alice\", {\"name\": \"Bob Alice\"}, tags={\"users\"})\nawait cache.set(\"user:charlie_brown\", {\"name\": \"Charlie Brown\"}, tags={\"users\"})\n\n# Search for keys containing \"alice\" (case-insensitive, approximate)\nresults = await cache.fuzzy_search(\"alice\", threshold=70)\n\nfor result in results:\n    print(f\"Key: {result.key}, Score: {result.score}\")\n# Output:\n# Key: user:alice_johnson, Score: 85\n# Key: user:bob_alice, Score: 78\n</code></pre>"},{"location":"usage-patterns/#advanced-fuzzy-search","title":"Advanced Fuzzy Search","text":"<p>Customize search parameters for better results:</p> <pre><code># Search with filtering and limits\nresults = await cache.fuzzy_search(\n    query=\"alice\",\n    threshold=80,           # Higher threshold for more precise matches\n    max_results=10,         # Limit number of results\n    tags={\"users\"}          # Only search within user-tagged entries\n)\n\n# Search with custom similarity method\nresults = await cache.fuzzy_search(\n    query=\"alice\",\n    threshold=75,\n    similarity_method=\"partial_ratio\"  # Better for substring matches\n)\n</code></pre>"},{"location":"usage-patterns/#cli-fuzzy-search","title":"CLI Fuzzy Search","text":"<p>Use the command line for interactive fuzzy search:</p> <pre><code># Basic search\nyokedcache search \"alice\" --threshold 80\n\n# Search with filters\nyokedcache search \"alice\" --threshold 80 --max-results 5\n\n# Search specific tags\nyokedcache search \"alice\" --tags users,active\n\n# Export results to file\nyokedcache search \"alice\" --threshold 80 --output results.json\n</code></pre>"},{"location":"usage-patterns/#search-within-values","title":"Search Within Values","text":"<p>Search not just keys, but also cached values:</p> <pre><code># Store structured data\nuser_data = {\n    \"name\": \"Alice Johnson\",\n    \"email\": \"alice@example.com\",\n    \"department\": \"Engineering\",\n    \"skills\": [\"Python\", \"JavaScript\", \"Machine Learning\"]\n}\nawait cache.set(\"user:123\", user_data, tags={\"users\"})\n\n# Search within cached values (requires additional configuration)\nresults = await cache.fuzzy_search_values(\n    query=\"Machine Learning\",\n    threshold=80,\n    search_fields=[\"skills\", \"department\"]  # Specify which fields to search\n)\n</code></pre>"},{"location":"usage-patterns/#fuzzy-search-best-practices","title":"Fuzzy Search Best Practices","text":"<ul> <li>Meaningful Keys: Use descriptive keys that benefit from fuzzy matching</li> <li>Appropriate Thresholds: Start with 80, adjust based on your data</li> <li>Tag Filtering: Use tags to limit search scope and improve performance</li> <li>Index Management: Fuzzy search maintains an index; consider rebuild frequency</li> <li>Performance: Fuzzy search is slower than exact lookups; use judiciously</li> </ul>"},{"location":"usage-patterns/#cache-warming","title":"Cache Warming","text":"<p>Pre-populate cache with frequently accessed data to improve initial performance.</p>"},{"location":"usage-patterns/#programmatic-cache-warming","title":"Programmatic Cache Warming","text":"<pre><code>from yokedcache.decorators import warm_cache\n\n# Define warming functions\nwarming_tasks = [\n    {\"func\": get_products, \"args\": [\"electronics\"], \"ttl\": 600},\n    {\"func\": get_products, \"args\": [\"books\"], \"ttl\": 600},\n    {\"func\": get_user_profile, \"args\": [123], \"kwargs\": {\"include_permissions\": True}, \"ttl\": 300},\n]\n\n# Warm the cache\nwarmed_count = await warm_cache(cache, warming_tasks)\nprint(f\"Warmed {warmed_count} cache entries\")\n</code></pre>"},{"location":"usage-patterns/#configuration-based-warming","title":"Configuration-Based Warming","text":"<pre><code># cache_warming.yaml\nwarming_tasks:\n  - function: get_products\n    args: [\"electronics\"]\n    ttl: 600\n    tags: [\"products\", \"category:electronics\"]\n\n  - function: get_popular_items\n    args: []\n    ttl: 1800\n    tags: [\"popular\", \"homepage\"]\n\n  - function: get_user_preferences\n    args: [123, 456, 789]  # Warm for multiple users\n    ttl: 300\n    tags: [\"user_data\"]\n</code></pre> <pre><code># Load and execute warming configuration\nwith open(\"cache_warming.yaml\") as f:\n    warming_config = yaml.safe_load(f)\n\nawait execute_warming_config(cache, warming_config)\n</code></pre>"},{"location":"usage-patterns/#cli-cache-warming","title":"CLI Cache Warming","text":"<pre><code># Warm cache using configuration file\nyokedcache warm --config-file cache_warming.yaml\n\n# Warm specific functions\nyokedcache warm --function get_products --args electronics --ttl 600\n\n# Monitor warming progress\nyokedcache warm --config-file cache_warming.yaml --verbose\n</code></pre>"},{"location":"usage-patterns/#error-handling-patterns","title":"Error Handling Patterns","text":"<p>Implement robust error handling for cache operations.</p>"},{"location":"usage-patterns/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>async def get_user_data(user_id: int):\n    try:\n        # Try cache first\n        cached_data = await cache.get(f\"user:{user_id}\")\n        if cached_data is not None:\n            return cached_data\n    except Exception as e:\n        # Cache error - log but continue\n        logger.warning(f\"Cache read failed: {e}\")\n\n    # Fallback to database\n    user_data = await database.get_user(user_id)\n\n    try:\n        # Try to cache for next time\n        await cache.set(f\"user:{user_id}\", user_data, ttl=300)\n    except Exception as e:\n        # Cache write error - log but return data\n        logger.warning(f\"Cache write failed: {e}\")\n\n    return user_data\n</code></pre>"},{"location":"usage-patterns/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<pre><code>from datetime import datetime, timedelta\n\nclass CacheCircuitBreaker:\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure = None\n        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n\n    async def call_with_fallback(self, cache_operation, fallback_operation):\n        if self.state == \"OPEN\":\n            if datetime.now() - self.last_failure &gt; timedelta(seconds=self.timeout):\n                self.state = \"HALF_OPEN\"\n            else:\n                return await fallback_operation()\n\n        try:\n            result = await cache_operation()\n            if self.state == \"HALF_OPEN\":\n                self.state = \"CLOSED\"\n                self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure = datetime.now()\n\n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = \"OPEN\"\n\n            logger.warning(f\"Cache operation failed: {e}\")\n            return await fallback_operation()\n\n# Usage\ncircuit_breaker = CacheCircuitBreaker()\n\nasync def get_with_fallback(key):\n    return await circuit_breaker.call_with_fallback(\n        lambda: cache.get(key),\n        lambda: database.get_data(key)\n    )\n</code></pre>"},{"location":"usage-patterns/#advanced-caching-patterns-v030","title":"Advanced Caching Patterns v0.3.0","text":"<p>YokedCache 0.3.0 introduces powerful advanced caching patterns designed for high-performance, production-ready applications.</p>"},{"location":"usage-patterns/#http-response-middleware","title":"HTTP Response Middleware","text":"<p>Add HTTP caching middleware to FastAPI applications for automatic ETag and Cache-Control header management:</p> <pre><code>from fastapi import FastAPI\nfrom yokedcache import YokedCache\nfrom yokedcache.middleware import HTTPCacheMiddleware\n\napp = FastAPI()\ncache = YokedCache()\n\n# Add HTTP caching middleware\napp.add_middleware(\n    HTTPCacheMiddleware,\n    cache=cache,\n    default_ttl=300,\n    include_query=False,\n    cache_control=\"public, max-age=300\"\n)\n\n@app.get(\"/api/users/{user_id}\")\nasync def get_user(user_id: int):\n    # Response automatically cached with ETag headers\n    # Returns 304 Not Modified for unchanged data\n    return {\"id\": user_id, \"name\": \"John Doe\"}\n</code></pre>"},{"location":"usage-patterns/#single-flight-protection","title":"Single-Flight Protection","text":"<p>Prevent cache stampede by ensuring only one request computes a value while others wait:</p> <pre><code>from yokedcache import YokedCache, CacheConfig\n\nconfig = CacheConfig(\n    redis_url=\"redis://localhost:6379\",\n    enable_single_flight=True\n)\ncache = YokedCache(config)\n\nasync def expensive_computation():\n    # This will only run once, even with concurrent requests\n    await asyncio.sleep(5)\n    return compute_expensive_data()\n\n# Multiple concurrent requests - only one computation runs\nresults = await asyncio.gather(\n    cache.fetch_or_set(\"expensive_key\", expensive_computation, ttl=300),\n    cache.fetch_or_set(\"expensive_key\", expensive_computation, ttl=300),\n    cache.fetch_or_set(\"expensive_key\", expensive_computation, ttl=300),\n)\n# All results are identical, but computation only ran once\n</code></pre>"},{"location":"usage-patterns/#stale-while-revalidate-swr","title":"Stale-While-Revalidate (SWR)","text":"<p>Serve stale cached data immediately while refreshing in the background:</p> <pre><code>from yokedcache import YokedCache, CacheConfig\n\nconfig = CacheConfig(\n    redis_url=\"redis://localhost:6379\",\n    enable_stale_while_revalidate=True\n)\ncache = YokedCache(config)\n\n# Function that returns stale data immediately and refreshes in background\nasync def get_user_data(user_id: int):\n    return await cache.fetch_or_set(\n        f\"user:{user_id}\",\n        lambda: fetch_user_from_db(user_id),\n        ttl=60\n    )\n</code></pre>"},{"location":"usage-patterns/#stale-if-error","title":"Stale-If-Error","text":"<p>Fallback to cached data when the primary data source fails:</p> <pre><code>from yokedcache import YokedCache, CacheConfig\n\nconfig = CacheConfig(\n    redis_url=\"redis://localhost:6379\",\n    enable_stale_if_error=True,\n    stale_if_error_ttl=120  # Serve stale for up to 2 minutes after TTL expires\n)\ncache = YokedCache(config)\n\nasync def get_data_with_fallback(key: str):\n    try:\n        return await fetch_fresh_data(key)\n    except Exception:\n        # Returns stale cached data if available\n        return await cache.get(key, default=None)\n</code></pre>"},{"location":"usage-patterns/#per-prefix-backend-routing","title":"Per-Prefix Backend Routing","text":"<p>Route different cache keys to different backends based on key prefixes:</p> <pre><code>from yokedcache import YokedCache\nfrom yokedcache.backends import DiskCacheBackend, RedisBackend\n\ncache = YokedCache()\n\n# Setup prefix-based routing\ncache.setup_prefix_routing()\n\n# Route different data types to different backends\ncache.add_backend_route(\"user:\", RedisBackend(\"redis://localhost:6379/0\"))\ncache.add_backend_route(\"temp:\", DiskCacheBackend(\"/tmp/cache\"))\ncache.add_backend_route(\"session:\", RedisBackend(\"redis://localhost:6379/1\"))\n\n# Data automatically routed based on key prefix\nawait cache.set(\"user:123\", user_data)      # -&gt; Redis DB 0\nawait cache.set(\"temp:abc\", temp_data)      # -&gt; Disk cache\nawait cache.set(\"session:xyz\", session)     # -&gt; Redis DB 1\n</code></pre>"},{"location":"usage-patterns/#opentelemetry-distributed-tracing","title":"OpenTelemetry Distributed Tracing","text":"<p>Enable distributed tracing for cache operations:</p> <pre><code>from yokedcache import YokedCache, CacheConfig\nfrom yokedcache.tracing import initialize_tracing\n\n# Initialize global tracing\ninitialize_tracing(\n    service_name=\"my-api\",\n    enabled=True,\n    sample_rate=1.0\n)\n\nconfig = CacheConfig(\n    redis_url=\"redis://localhost:6379\",\n    enable_tracing=True\n)\ncache = YokedCache(config)\n\n# All cache operations automatically traced\nasync with cache._tracer.trace_operation(\"get_user\", \"user:123\"):\n    user = await cache.get(\"user:123\")\n    # Span includes timing, hit/miss, backend info\n</code></pre> <p>These advanced patterns enable sophisticated caching strategies for high-performance, production applications.</p>"},{"location":"usage-patterns/#performance-optimization-patterns","title":"Performance Optimization Patterns","text":""},{"location":"usage-patterns/#connection-reuse","title":"Connection Reuse","text":"<pre><code># Good: Reuse single cache instance\ncache = YokedCache()\n\nasync def handler1():\n    return await cache.get(\"key1\")\n\nasync def handler2():\n    return await cache.get(\"key2\")\n\n# Bad: Creating new instances\nasync def bad_handler():\n    cache = YokedCache()  # Don't do this\n    return await cache.get(\"key\")\n</code></pre>"},{"location":"usage-patterns/#batch-operations_1","title":"Batch Operations","text":"<pre><code># Good: Batch multiple operations\nkeys = [f\"user:{i}\" for i in user_ids]\nusers = await cache.get_many(keys)\n\n# Bad: Individual operations in loop\nusers = {}\nfor user_id in user_ids:\n    users[user_id] = await cache.get(f\"user:{user_id}\")  # Inefficient\n</code></pre>"},{"location":"usage-patterns/#optimal-ttl-strategy","title":"Optimal TTL Strategy","text":"<pre><code># Hot data: Short TTL\n@cached(ttl=30)\nasync def get_live_prices():\n    return await fetch_stock_prices()\n\n# Warm data: Medium TTL\n@cached(ttl=300)\nasync def get_user_profile(user_id):\n    return await database.get_user(user_id)\n\n# Cold data: Long TTL\n@cached(ttl=3600)\nasync def get_system_config():\n    return await database.get_config()\n</code></pre> <p>These usage patterns provide a foundation for implementing effective caching strategies in your applications. Choose the patterns that best fit your use case and combine them as needed for optimal performance.</p>"},{"location":"vector-search/","title":"Vector-Based Similarity Search","text":"<p>YokedCache 0.2.0 introduces advanced vector-based similarity search capabilities, enabling semantic search across your cached data. This feature goes beyond traditional string matching to provide intelligent, context-aware search results.</p>"},{"location":"vector-search/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>How It Works</li> <li>Configuration</li> <li>Usage Examples</li> <li>Similarity Methods</li> <li>Performance Optimization</li> <li>Integration with Cache</li> </ul>"},{"location":"vector-search/#overview","title":"Overview","text":"<p>Traditional fuzzy search relies on string similarity metrics like Levenshtein distance. Vector-based similarity search uses machine learning techniques to understand the semantic meaning of your data, providing more relevant and intelligent search results.</p>"},{"location":"vector-search/#key-features","title":"Key Features","text":"<ul> <li>Semantic Understanding: Finds conceptually related content, not just string matches</li> <li>Multiple Similarity Methods: Cosine, Euclidean, and Manhattan distance calculations</li> <li>TF-IDF Vectorization: Converts text to numerical vectors for comparison</li> <li>Configurable Parameters: Fine-tune search behavior for your specific use case</li> <li>Real-time Updates: Automatically updates search index when cache data changes</li> <li>Redis Integration: Optional Redis-backed vector storage for distributed systems</li> </ul>"},{"location":"vector-search/#use-cases","title":"Use Cases","text":"<ul> <li>Content Discovery: Find related articles, products, or documents</li> <li>Recommendation Systems: Suggest similar items based on user behavior</li> <li>Data Deduplication: Identify duplicate or near-duplicate content</li> <li>Smart Search: Provide search results that understand user intent</li> <li>Data Analysis: Group and analyze similar data patterns</li> </ul>"},{"location":"vector-search/#how-it-works","title":"How It Works","text":""},{"location":"vector-search/#1-text-extraction","title":"1. Text Extraction","text":"<p>The system extracts searchable text from cache keys and values:</p> <pre><code># For key-value pairs\nkey = \"user:123\"\nvalue = {\"name\": \"Alice Smith\", \"role\": \"engineer\", \"skills\": [\"python\", \"redis\"]}\n\n# Extracted text\nsearchable_text = \"user:123 name:Alice Smith role:engineer skills:python,redis\"\n</code></pre>"},{"location":"vector-search/#2-vectorization","title":"2. Vectorization","text":"<p>Text is converted to numerical vectors using TF-IDF (Term Frequency-Inverse Document Frequency):</p> <pre><code>from yokedcache.vector_search import VectorSimilaritySearch\n\nsearch = VectorSimilaritySearch(\n    max_features=1000,      # Maximum vocabulary size\n    min_df=1,               # Minimum document frequency\n    max_df=0.95,            # Maximum document frequency\n    ngram_range=(1, 2)      # Use unigrams and bigrams\n)\n</code></pre>"},{"location":"vector-search/#3-similarity-calculation","title":"3. Similarity Calculation","text":"<p>Vector similarities are calculated using mathematical distance metrics:</p> <ul> <li>Cosine Similarity: Measures angle between vectors (best for text)</li> <li>Euclidean Distance: Measures straight-line distance between points</li> <li>Manhattan Distance: Measures city-block distance between points</li> </ul>"},{"location":"vector-search/#4-result-ranking","title":"4. Result Ranking","text":"<p>Results are ranked by similarity score and filtered by threshold:</p> <pre><code>results = search.search(\n    query=\"python developer\",\n    cache_data=cache_data,\n    threshold=0.1,          # Minimum similarity score\n    max_results=10          # Maximum number of results\n)\n</code></pre>"},{"location":"vector-search/#configuration","title":"Configuration","text":""},{"location":"vector-search/#basic-setup","title":"Basic Setup","text":"<pre><code>from yokedcache.vector_search import VectorSimilaritySearch\n\n# Default configuration\nsearch = VectorSimilaritySearch()\n\n# Custom configuration\nsearch = VectorSimilaritySearch(\n    similarity_method=\"cosine\",     # \"cosine\", \"euclidean\", \"manhattan\"\n    max_features=2000,              # Vocabulary size\n    min_df=2,                       # Ignore rare terms\n    max_df=0.8,                     # Ignore common terms\n    ngram_range=(1, 3)              # Use 1-3 word phrases\n)\n</code></pre>"},{"location":"vector-search/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>search = VectorSimilaritySearch(\n    similarity_method=\"cosine\",\n    max_features=5000,\n    min_df=0.01,                    # Percentage-based frequency\n    max_df=0.95,\n    ngram_range=(1, 2),\n    stop_words=\"english\",           # Remove common English words\n    lowercase=True,                 # Convert to lowercase\n    strip_accents=\"unicode\"         # Remove accents\n)\n</code></pre>"},{"location":"vector-search/#installation-requirements","title":"Installation Requirements","text":"<p>Vector search requires additional dependencies:</p> <pre><code># Install vector search dependencies\npip install yokedcache[vector]\n\n# Or install manually\npip install numpy scipy scikit-learn\n</code></pre>"},{"location":"vector-search/#usage-examples","title":"Usage Examples","text":""},{"location":"vector-search/#basic-search","title":"Basic Search","text":"<pre><code>from yokedcache.vector_search import VectorSimilaritySearch\n\n# Sample cache data\ncache_data = {\n    \"user:1\": {\"name\": \"Alice\", \"role\": \"Python Developer\", \"skills\": [\"FastAPI\", \"Redis\"]},\n    \"user:2\": {\"name\": \"Bob\", \"role\": \"Data Scientist\", \"skills\": [\"Python\", \"ML\"]},\n    \"user:3\": {\"name\": \"Charlie\", \"role\": \"Frontend Developer\", \"skills\": [\"React\", \"TypeScript\"]},\n    \"post:1\": {\"title\": \"Python Best Practices\", \"content\": \"Tips for writing clean Python code\"},\n    \"post:2\": {\"title\": \"Redis Caching Guide\", \"content\": \"How to implement efficient caching\"}\n}\n\n# Initialize and fit the search engine\nsearch = VectorSimilaritySearch()\nsearch.fit(cache_data)\n\n# Search for Python-related content\nresults = search.search(\"Python programming\", cache_data, threshold=0.1)\n\nfor result in results:\n    print(f\"Key: {result.key}\")\n    print(f\"Score: {result.score:.3f}\")\n    print(f\"Value: {result.value}\")\n    print(\"---\")\n</code></pre>"},{"location":"vector-search/#integration-with-yokedcache","title":"Integration with YokedCache","text":"<pre><code>from yokedcache import YokedCache, CacheConfig\nfrom yokedcache.backends import MemoryBackend\nfrom yokedcache.vector_search import VectorSimilaritySearch\n\n# Setup cache with vector search\nbackend = MemoryBackend()\nconfig = CacheConfig(\n    backend=backend,\n    enable_fuzzy=True,\n    fuzzy_threshold=70\n)\n\ncache = YokedCache(config)\n\n# Add vector search capability\nvector_search = VectorSimilaritySearch(similarity_method=\"cosine\")\n\nasync def enhanced_search(query: str, use_vector: bool = True):\n    \"\"\"Search using both traditional fuzzy and vector search.\"\"\"\n\n    # Get all cache data\n    all_keys = await cache.get_all_keys(\"*\")\n    cache_data = {}\n\n    for key in all_keys:\n        value = await cache.get(key)\n        if value:\n            cache_data[key] = value\n\n    if use_vector and cache_data:\n        # Fit and search using vector similarity\n        vector_search.fit(cache_data)\n        vector_results = vector_search.search(query, cache_data, threshold=0.1)\n\n        # Convert to consistent format\n        results = [\n            {\n                \"key\": r.key,\n                \"value\": r.value,\n                \"score\": r.score,\n                \"method\": \"vector\"\n            }\n            for r in vector_results\n        ]\n    else:\n        # Fall back to traditional fuzzy search\n        fuzzy_results = await cache.fuzzy_search(query)\n        results = [\n            {\n                \"key\": r.key,\n                \"value\": r.value,\n                \"score\": r.score,\n                \"method\": \"fuzzy\"\n            }\n            for r in fuzzy_results\n        ]\n\n    return results\n</code></pre>"},{"location":"vector-search/#real-time-index-updates","title":"Real-time Index Updates","text":"<pre><code>class CacheWithVectorSearch:\n    \"\"\"Cache wrapper with automatic vector search updates.\"\"\"\n\n    def __init__(self, cache: YokedCache):\n        self.cache = cache\n        self.vector_search = VectorSimilaritySearch()\n        self._cache_data = {}\n        self._fitted = False\n\n    async def set(self, key: str, value, **kwargs):\n        \"\"\"Set cache value and update search index.\"\"\"\n        result = await self.cache.set(key, value, **kwargs)\n\n        # Update search index\n        self._cache_data[key] = value\n        self.vector_search.update_cache_entry(key, value)\n\n        return result\n\n    async def delete(self, key: str):\n        \"\"\"Delete cache value and update search index.\"\"\"\n        result = await self.cache.delete(key)\n\n        # Update search index\n        if key in self._cache_data:\n            del self._cache_data[key]\n            self.vector_search.remove_cache_entry(key)\n\n        return result\n\n    async def search(self, query: str, **kwargs):\n        \"\"\"Search using vector similarity.\"\"\"\n        if not self._fitted:\n            # Initial fit\n            all_keys = await self.cache.get_all_keys(\"*\")\n            for key in all_keys:\n                value = await self.cache.get(key)\n                if value:\n                    self._cache_data[key] = value\n\n            self.vector_search.fit(self._cache_data)\n            self._fitted = True\n\n        return self.vector_search.search(query, self._cache_data, **kwargs)\n</code></pre>"},{"location":"vector-search/#similarity-methods","title":"Similarity Methods","text":""},{"location":"vector-search/#cosine-similarity","title":"Cosine Similarity","text":"<p>Best for text-based content and high-dimensional sparse data.</p> <pre><code>search = VectorSimilaritySearch(similarity_method=\"cosine\")\n</code></pre> <p>Characteristics: - Range: 0.0 to 1.0 (higher is more similar) - Normalized by vector magnitude - Excellent for text similarity - Handles different document lengths well</p> <p>Use Cases: - Document similarity - Content recommendation - Semantic search</p>"},{"location":"vector-search/#euclidean-distance","title":"Euclidean Distance","text":"<p>Measures straight-line distance between vectors in n-dimensional space.</p> <pre><code>search = VectorSimilaritySearch(similarity_method=\"euclidean\")\n</code></pre> <p>Characteristics: - Range: 0.0 to \u221e (lower is more similar, converted to 1/(1+distance)) - Sensitive to magnitude differences - Good for numerical data - Intuitive geometric interpretation</p> <p>Use Cases: - Numerical data comparison - Feature similarity - Spatial data analysis</p>"},{"location":"vector-search/#manhattan-distance","title":"Manhattan Distance","text":"<p>Measures city-block distance between vectors.</p> <pre><code>search = VectorSimilaritySearch(similarity_method=\"manhattan\")\n</code></pre> <p>Characteristics: - Range: 0.0 to \u221e (lower is more similar, converted to 1/(1+distance)) - Less sensitive to outliers than Euclidean - Good for sparse data - Computationally efficient</p> <p>Use Cases: - Categorical data - Sparse feature vectors - Robust similarity measurement</p>"},{"location":"vector-search/#comparison-example","title":"Comparison Example","text":"<pre><code># Test different similarity methods\nmethods = [\"cosine\", \"euclidean\", \"manhattan\"]\nquery = \"machine learning engineer\"\n\nfor method in methods:\n    search = VectorSimilaritySearch(similarity_method=method)\n    search.fit(cache_data)\n    results = search.search(query, cache_data, threshold=0.1, max_results=3)\n\n    print(f\"\\n{method.title()} Similarity Results:\")\n    for result in results:\n        print(f\"  {result.key}: {result.score:.3f}\")\n</code></pre>"},{"location":"vector-search/#performance-optimization","title":"Performance Optimization","text":""},{"location":"vector-search/#vectorizer-optimization","title":"Vectorizer Optimization","text":"<pre><code># For large datasets\nsearch = VectorSimilaritySearch(\n    max_features=10000,         # Larger vocabulary\n    min_df=5,                   # Ignore very rare terms\n    max_df=0.7,                 # Ignore very common terms\n    ngram_range=(1, 2)          # Limit n-gram range\n)\n\n# For small datasets\nsearch = VectorSimilaritySearch(\n    max_features=1000,          # Smaller vocabulary\n    min_df=1,                   # Include rare terms\n    max_df=0.95,                # Keep most terms\n    ngram_range=(1, 3)          # Include trigrams\n)\n</code></pre>"},{"location":"vector-search/#memory-management","title":"Memory Management","text":"<pre><code># Monitor memory usage\nstats = search.get_stats()\nprint(f\"Vector density: {stats['vector_density']:.3f}\")\nprint(f\"Number of features: {stats['num_features']}\")\nprint(f\"Memory efficiency: {stats['vector_density'] * 100:.1f}%\")\n\n# For memory-constrained environments\nsearch = VectorSimilaritySearch(\n    max_features=500,           # Reduce vocabulary\n    min_df=3,                   # Filter rare terms\n    ngram_range=(1, 1)          # Only unigrams\n)\n</code></pre>"},{"location":"vector-search/#batch-operations","title":"Batch Operations","text":"<pre><code># Batch index updates for better performance\nclass BatchVectorSearch:\n    def __init__(self, batch_size=100):\n        self.search = VectorSimilaritySearch()\n        self.pending_updates = {}\n        self.batch_size = batch_size\n\n    def update_entry(self, key: str, value):\n        \"\"\"Add entry to batch update.\"\"\"\n        self.pending_updates[key] = value\n\n        if len(self.pending_updates) &gt;= self.batch_size:\n            self.flush_updates()\n\n    def flush_updates(self):\n        \"\"\"Apply all pending updates.\"\"\"\n        if self.pending_updates:\n            # Merge with existing data and refit\n            self.search.fit(self.pending_updates)\n            self.pending_updates.clear()\n</code></pre>"},{"location":"vector-search/#integration-with-cache","title":"Integration with Cache","text":""},{"location":"vector-search/#automatic-vector-search","title":"Automatic Vector Search","text":"<pre><code>from yokedcache import YokedCache, CacheConfig\nfrom yokedcache.backends import MemoryBackend\n\n# Enable vector search in cache configuration\nconfig = CacheConfig(\n    backend=MemoryBackend(),\n    enable_fuzzy=True,\n    fuzzy_threshold=70,\n    vector_search=True,          # Enable vector search\n    vector_similarity=\"cosine\"   # Choose similarity method\n)\n\ncache = YokedCache(config)\n\n# Search automatically uses vector similarity\nresults = await cache.fuzzy_search(\"python developer\")\n</code></pre>"},{"location":"vector-search/#redis-vector-storage","title":"Redis Vector Storage","text":"<p>For distributed systems, store vectors in Redis:</p> <pre><code>from yokedcache.vector_search import RedisVectorSearch\nimport redis.asyncio as redis\n\n# Setup Redis vector storage\nredis_client = redis.Redis.from_url(\"redis://localhost:6379/1\")\nvector_store = RedisVectorSearch(\n    redis_client,\n    vector_key_prefix=\"vectors:\",\n    similarity_method=\"cosine\"\n)\n\n# Store and retrieve vectors\nimport numpy as np\n\nvector = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\nawait vector_store.store_vector(\"doc:123\", vector)\n\nretrieved = await vector_store.get_vector(\"doc:123\")\nprint(f\"Vectors match: {np.array_equal(vector, retrieved)}\")\n</code></pre>"},{"location":"vector-search/#hybrid-search-strategy","title":"Hybrid Search Strategy","text":"<pre><code>async def hybrid_search(cache, query: str, threshold: float = 0.1):\n    \"\"\"Combine traditional fuzzy search with vector search.\"\"\"\n\n    # Get traditional fuzzy results\n    fuzzy_results = await cache.fuzzy_search(query, threshold=threshold*100)\n\n    # Get vector search results\n    vector_search = VectorSimilaritySearch()\n    all_data = await cache.get_all_data()  # Implement this method\n    vector_search.fit(all_data)\n    vector_results = vector_search.search(query, all_data, threshold=threshold)\n\n    # Combine and rank results\n    combined_results = {}\n\n    # Add fuzzy results\n    for result in fuzzy_results:\n        combined_results[result.key] = {\n            \"value\": result.value,\n            \"fuzzy_score\": result.score / 100.0,\n            \"vector_score\": 0.0\n        }\n\n    # Add vector results\n    for result in vector_results:\n        if result.key in combined_results:\n            combined_results[result.key][\"vector_score\"] = result.score\n        else:\n            combined_results[result.key] = {\n                \"value\": result.value,\n                \"fuzzy_score\": 0.0,\n                \"vector_score\": result.score\n            }\n\n    # Calculate combined score (weighted average)\n    final_results = []\n    for key, data in combined_results.items():\n        combined_score = (data[\"fuzzy_score\"] * 0.3 + data[\"vector_score\"] * 0.7)\n        if combined_score &gt;= threshold:\n            final_results.append({\n                \"key\": key,\n                \"value\": data[\"value\"],\n                \"score\": combined_score,\n                \"fuzzy_score\": data[\"fuzzy_score\"],\n                \"vector_score\": data[\"vector_score\"]\n            })\n\n    # Sort by combined score\n    return sorted(final_results, key=lambda x: x[\"score\"], reverse=True)\n</code></pre>"},{"location":"vector-search/#best-practices","title":"Best Practices","text":""},{"location":"vector-search/#1-data-preparation","title":"1. Data Preparation","text":"<pre><code>def prepare_search_data(data):\n    \"\"\"Prepare data for optimal vector search.\"\"\"\n    if isinstance(data, dict):\n        # Extract meaningful text fields\n        text_fields = []\n        for key, value in data.items():\n            if isinstance(value, str):\n                text_fields.append(f\"{key}:{value}\")\n            elif isinstance(value, list):\n                text_fields.append(f\"{key}:{','.join(map(str, value))}\")\n        return \" \".join(text_fields)\n    return str(data)\n</code></pre>"},{"location":"vector-search/#2-index-management","title":"2. Index Management","text":"<pre><code>class ManagedVectorSearch:\n    \"\"\"Vector search with automatic index management.\"\"\"\n\n    def __init__(self, rebuild_threshold=1000):\n        self.search = VectorSimilaritySearch()\n        self.rebuild_threshold = rebuild_threshold\n        self.updates_since_rebuild = 0\n\n    def should_rebuild_index(self):\n        \"\"\"Check if index should be rebuilt.\"\"\"\n        return self.updates_since_rebuild &gt;= self.rebuild_threshold\n\n    async def update_and_maybe_rebuild(self, cache_data):\n        \"\"\"Update index and rebuild if necessary.\"\"\"\n        self.updates_since_rebuild += 1\n\n        if self.should_rebuild_index():\n            self.search.fit(cache_data)\n            self.updates_since_rebuild = 0\n</code></pre>"},{"location":"vector-search/#3-error-handling","title":"3. Error Handling","text":"<pre><code>async def safe_vector_search(query: str, cache_data: dict):\n    \"\"\"Vector search with graceful error handling.\"\"\"\n    try:\n        search = VectorSimilaritySearch()\n        search.fit(cache_data)\n        return search.search(query, cache_data)\n    except ImportError:\n        logger.warning(\"Vector search dependencies not available, skipping\")\n        return []\n    except Exception as e:\n        logger.error(f\"Vector search failed: {e}\")\n        return []\n</code></pre> <p>Vector-based similarity search opens up powerful possibilities for intelligent caching and data discovery. By understanding semantic relationships in your data, you can build more intuitive and effective applications.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#public-api","title":"Public API","text":"<p>YokedCache - A robust, performance-focused caching library for Python backends.</p> <p>YokedCache provides seamless caching integration for FastAPI applications with Redis, featuring automatic cache invalidation, fuzzy search capabilities, and intelligent database integration.</p>"},{"location":"api/#yokedcache.CacheBackend","title":"<code>CacheBackend</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for cache backends.</p>"},{"location":"api/#yokedcache.CacheBackend.is_connected","title":"<code>is_connected: bool</code>  <code>property</code>","text":"<p>Check if backend is connected.</p>"},{"location":"api/#yokedcache.CacheBackend.connect","title":"<code>connect() -&gt; None</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Establish connection to the backend.</p>"},{"location":"api/#yokedcache.CacheBackend.delete","title":"<code>delete(key: str) -&gt; bool</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete key from cache.</p>"},{"location":"api/#yokedcache.CacheBackend.disconnect","title":"<code>disconnect() -&gt; None</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Close connection to the backend.</p>"},{"location":"api/#yokedcache.CacheBackend.exists","title":"<code>exists(key: str) -&gt; bool</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Check if key exists in cache.</p>"},{"location":"api/#yokedcache.CacheBackend.expire","title":"<code>expire(key: str, ttl: int) -&gt; bool</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Set expiration time for existing key.</p>"},{"location":"api/#yokedcache.CacheBackend.flush_all","title":"<code>flush_all() -&gt; bool</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Flush all cache keys.</p>"},{"location":"api/#yokedcache.CacheBackend.fuzzy_search","title":"<code>fuzzy_search(query: str, threshold: int = 80, max_results: int = 10, tags: Optional[Set[str]] = None) -&gt; List[FuzzySearchResult]</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Perform fuzzy search on cached data.</p>"},{"location":"api/#yokedcache.CacheBackend.get","title":"<code>get(key: str, default: Any = None) -&gt; Any</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get value from cache.</p>"},{"location":"api/#yokedcache.CacheBackend.get_all_keys","title":"<code>get_all_keys(pattern: str = '*') -&gt; List[str]</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get all keys matching pattern.</p>"},{"location":"api/#yokedcache.CacheBackend.get_size_bytes","title":"<code>get_size_bytes() -&gt; int</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get total size of cache in bytes.</p>"},{"location":"api/#yokedcache.CacheBackend.get_stats","title":"<code>get_stats() -&gt; CacheStats</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get current cache statistics.</p>"},{"location":"api/#yokedcache.CacheBackend.health_check","title":"<code>health_check() -&gt; bool</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Check if the backend connection is healthy.</p>"},{"location":"api/#yokedcache.CacheBackend.invalidate_pattern","title":"<code>invalidate_pattern(pattern: str) -&gt; int</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Invalidate all keys matching a pattern.</p>"},{"location":"api/#yokedcache.CacheBackend.invalidate_tags","title":"<code>invalidate_tags(tags: Union[str, List[str], Set[str]]) -&gt; int</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Invalidate all keys associated with given tags.</p>"},{"location":"api/#yokedcache.CacheBackend.set","title":"<code>set(key: str, value: Any, ttl: Optional[int] = None, tags: Optional[Set[str]] = None) -&gt; bool</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Set value in cache.</p>"},{"location":"api/#yokedcache.CacheConnectionError","title":"<code>CacheConnectionError</code>","text":"<p>               Bases: <code>YokedCacheError</code></p> <p>Raised when Redis connection fails or times out.</p>"},{"location":"api/#yokedcache.CacheEntry","title":"<code>CacheEntry</code>  <code>dataclass</code>","text":"<p>Represents a single cache entry with metadata.</p>"},{"location":"api/#yokedcache.CacheEntry.age_seconds","title":"<code>age_seconds: float</code>  <code>property</code>","text":"<p>Get the age of the cache entry in seconds.</p>"},{"location":"api/#yokedcache.CacheEntry.is_expired","title":"<code>is_expired: bool</code>  <code>property</code>","text":"<p>Check if the cache entry has expired.</p>"},{"location":"api/#yokedcache.CacheEntry.touch","title":"<code>touch() -&gt; None</code>","text":"<p>Update the last accessed timestamp and increment hit count.</p>"},{"location":"api/#yokedcache.CacheKeyError","title":"<code>CacheKeyError</code>","text":"<p>               Bases: <code>YokedCacheError</code></p> <p>Raised when cache key operations fail.</p>"},{"location":"api/#yokedcache.CacheMetrics","title":"<code>CacheMetrics</code>","text":"<p>Cache metrics wrapper that handles multiple collectors.</p>"},{"location":"api/#yokedcache.CacheMetrics.add_collector","title":"<code>add_collector(collector: MetricsCollector) -&gt; None</code>","text":"<p>Add a metrics collector.</p>"},{"location":"api/#yokedcache.CacheMetrics.end_timer","title":"<code>end_timer(timer_id: str, operation: str) -&gt; None</code>  <code>async</code>","text":"<p>End timing an operation and record the duration.</p>"},{"location":"api/#yokedcache.CacheMetrics.gauge","title":"<code>gauge(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Set gauge metric across all collectors.</p>"},{"location":"api/#yokedcache.CacheMetrics.histogram","title":"<code>histogram(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Record histogram across all collectors.</p>"},{"location":"api/#yokedcache.CacheMetrics.increment","title":"<code>increment(metric: str, value: int = 1, tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Increment metric across all collectors.</p>"},{"location":"api/#yokedcache.CacheMetrics.start_timer","title":"<code>start_timer(operation: str) -&gt; str</code>","text":"<p>Start timing an operation.</p>"},{"location":"api/#yokedcache.CacheMetrics.timing","title":"<code>timing(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Record timing across all collectors.</p>"},{"location":"api/#yokedcache.CacheSerializationError","title":"<code>CacheSerializationError</code>","text":"<p>               Bases: <code>YokedCacheError</code></p> <p>Raised when data serialization/deserialization fails.</p>"},{"location":"api/#yokedcache.CacheStats","title":"<code>CacheStats</code>  <code>dataclass</code>","text":"<p>Cache performance and usage statistics.</p>"},{"location":"api/#yokedcache.CacheStats.hit_rate","title":"<code>hit_rate: float</code>  <code>property</code>","text":"<p>Calculate cache hit rate as a percentage.</p>"},{"location":"api/#yokedcache.CacheStats.memory_usage","title":"<code>memory_usage: int</code>  <code>property</code>","text":"<p>Alias for total_memory_bytes for backward compatibility.</p>"},{"location":"api/#yokedcache.CacheStats.miss_rate","title":"<code>miss_rate: float</code>  <code>property</code>","text":"<p>Calculate cache miss rate as a percentage.</p>"},{"location":"api/#yokedcache.CacheStats.add_hit","title":"<code>add_hit(table: Optional[str] = None, tags: Optional[Set[str]] = None) -&gt; None</code>","text":"<p>Record a cache hit.</p>"},{"location":"api/#yokedcache.CacheStats.add_miss","title":"<code>add_miss(table: Optional[str] = None, tags: Optional[Set[str]] = None) -&gt; None</code>","text":"<p>Record a cache miss.</p>"},{"location":"api/#yokedcache.CacheTracer","title":"<code>CacheTracer</code>","text":"<p>Manages OpenTelemetry tracing for cache operations.</p>"},{"location":"api/#yokedcache.CacheTracer.add_event","title":"<code>add_event(name: str, **attributes: Any) -&gt; None</code>","text":"<p>Add an event to the current span if active.</p>"},{"location":"api/#yokedcache.CacheTracer.trace_hit","title":"<code>trace_hit(key: str, backend: Optional[str] = None) -&gt; None</code>","text":"<p>Record a cache hit event.</p>"},{"location":"api/#yokedcache.CacheTracer.trace_miss","title":"<code>trace_miss(key: str, backend: Optional[str] = None) -&gt; None</code>","text":"<p>Record a cache miss event.</p>"},{"location":"api/#yokedcache.CacheTracer.trace_operation","title":"<code>trace_operation(operation: str, key: Optional[str] = None, **attributes: Any) -&gt; AsyncGenerator[Optional[Any], None]</code>  <code>async</code>","text":"<p>Trace a cache operation with automatic span management.</p>"},{"location":"api/#yokedcache.InvalidationRule","title":"<code>InvalidationRule</code>  <code>dataclass</code>","text":"<p>Defines when and how to invalidate cache entries.</p>"},{"location":"api/#yokedcache.InvalidationRule.should_invalidate","title":"<code>should_invalidate(operation_type: InvalidationType) -&gt; bool</code>","text":"<p>Check if this rule should trigger for the given operation type.</p>"},{"location":"api/#yokedcache.MemcachedBackend","title":"<code>MemcachedBackend</code>","text":"<p>               Bases: <code>CacheBackend</code></p> <p>Memcached cache backend implementation.</p>"},{"location":"api/#yokedcache.MemcachedBackend.connect","title":"<code>connect() -&gt; None</code>  <code>async</code>","text":"<p>Establish connection to Memcached.</p>"},{"location":"api/#yokedcache.MemcachedBackend.delete","title":"<code>delete(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Delete key from cache.</p>"},{"location":"api/#yokedcache.MemcachedBackend.disconnect","title":"<code>disconnect() -&gt; None</code>  <code>async</code>","text":"<p>Close Memcached connection.</p>"},{"location":"api/#yokedcache.MemcachedBackend.exists","title":"<code>exists(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Check if key exists in cache.</p>"},{"location":"api/#yokedcache.MemcachedBackend.expire","title":"<code>expire(key: str, ttl: int) -&gt; bool</code>  <code>async</code>","text":"<p>Set expiration time for existing key.</p>"},{"location":"api/#yokedcache.MemcachedBackend.flush_all","title":"<code>flush_all() -&gt; bool</code>  <code>async</code>","text":"<p>Flush all cache keys.</p>"},{"location":"api/#yokedcache.MemcachedBackend.fuzzy_search","title":"<code>fuzzy_search(query: str, threshold: int = 80, max_results: int = 10, tags: Optional[Set[str]] = None) -&gt; List[FuzzySearchResult]</code>  <code>async</code>","text":"<p>Perform fuzzy search on cached data.</p>"},{"location":"api/#yokedcache.MemcachedBackend.get","title":"<code>get(key: str, default: Any = None) -&gt; Any</code>  <code>async</code>","text":"<p>Get value from cache.</p>"},{"location":"api/#yokedcache.MemcachedBackend.get_all_keys","title":"<code>get_all_keys(pattern: str = '*') -&gt; List[str]</code>  <code>async</code>","text":"<p>Get all keys matching pattern.</p>"},{"location":"api/#yokedcache.MemcachedBackend.get_size_bytes","title":"<code>get_size_bytes() -&gt; int</code>  <code>async</code>","text":"<p>Get total size of cache in bytes.</p>"},{"location":"api/#yokedcache.MemcachedBackend.get_stats","title":"<code>get_stats() -&gt; CacheStats</code>  <code>async</code>","text":"<p>Get current cache statistics.</p>"},{"location":"api/#yokedcache.MemcachedBackend.health_check","title":"<code>health_check() -&gt; bool</code>  <code>async</code>","text":"<p>Check if Memcached connection is healthy.</p>"},{"location":"api/#yokedcache.MemcachedBackend.invalidate_pattern","title":"<code>invalidate_pattern(pattern: str) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys matching a pattern.</p>"},{"location":"api/#yokedcache.MemcachedBackend.invalidate_tags","title":"<code>invalidate_tags(tags: Union[str, List[str], Set[str]]) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys associated with given tags.</p>"},{"location":"api/#yokedcache.MemcachedBackend.set","title":"<code>set(key: str, value: Any, ttl: Optional[int] = None, tags: Optional[Set[str]] = None) -&gt; bool</code>  <code>async</code>","text":"<p>Set value in cache.</p>"},{"location":"api/#yokedcache.MemoryBackend","title":"<code>MemoryBackend</code>","text":"<p>               Bases: <code>CacheBackend</code></p> <p>In-memory cache backend implementation.</p>"},{"location":"api/#yokedcache.MemoryBackend.connect","title":"<code>connect() -&gt; None</code>  <code>async</code>","text":"<p>Establish connection (start cleanup task).</p>"},{"location":"api/#yokedcache.MemoryBackend.delete","title":"<code>delete(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Delete key from cache.</p>"},{"location":"api/#yokedcache.MemoryBackend.disconnect","title":"<code>disconnect() -&gt; None</code>  <code>async</code>","text":"<p>Close connection (stop cleanup task).</p>"},{"location":"api/#yokedcache.MemoryBackend.exists","title":"<code>exists(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Check if key exists in cache.</p>"},{"location":"api/#yokedcache.MemoryBackend.expire","title":"<code>expire(key: str, ttl: int) -&gt; bool</code>  <code>async</code>","text":"<p>Set expiration time for existing key.</p>"},{"location":"api/#yokedcache.MemoryBackend.flush_all","title":"<code>flush_all() -&gt; bool</code>  <code>async</code>","text":"<p>Flush all cache keys with the configured prefix.</p>"},{"location":"api/#yokedcache.MemoryBackend.fuzzy_search","title":"<code>fuzzy_search(query: str, threshold: int = 80, max_results: int = 10, tags: Optional[Set[str]] = None) -&gt; List[FuzzySearchResult]</code>  <code>async</code>","text":"<p>Perform fuzzy search on cached data.</p>"},{"location":"api/#yokedcache.MemoryBackend.get","title":"<code>get(key: str, default: Any = None) -&gt; Any</code>  <code>async</code>","text":"<p>Get value from cache.</p>"},{"location":"api/#yokedcache.MemoryBackend.get_all_keys","title":"<code>get_all_keys(pattern: str = '*') -&gt; List[str]</code>  <code>async</code>","text":"<p>Get all keys matching pattern.</p>"},{"location":"api/#yokedcache.MemoryBackend.get_size_bytes","title":"<code>get_size_bytes() -&gt; int</code>  <code>async</code>","text":"<p>Get total size of cache in bytes.</p>"},{"location":"api/#yokedcache.MemoryBackend.get_stats","title":"<code>get_stats() -&gt; CacheStats</code>  <code>async</code>","text":"<p>Get current cache statistics.</p>"},{"location":"api/#yokedcache.MemoryBackend.health_check","title":"<code>health_check() -&gt; bool</code>  <code>async</code>","text":"<p>Check if memory backend is healthy.</p>"},{"location":"api/#yokedcache.MemoryBackend.invalidate_pattern","title":"<code>invalidate_pattern(pattern: str) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys matching a pattern.</p>"},{"location":"api/#yokedcache.MemoryBackend.invalidate_tags","title":"<code>invalidate_tags(tags: Union[str, List[str], Set[str]]) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys associated with given tags.</p>"},{"location":"api/#yokedcache.MemoryBackend.set","title":"<code>set(key: str, value: Any, ttl: Optional[int] = None, tags: Optional[Set[str]] = None) -&gt; bool</code>  <code>async</code>","text":"<p>Set value in cache.</p>"},{"location":"api/#yokedcache.NoOpCollector","title":"<code>NoOpCollector</code>","text":"<p>               Bases: <code>MetricsCollector</code></p> <p>No-op metrics collector for when monitoring is disabled.</p>"},{"location":"api/#yokedcache.NoOpCollector.gauge","title":"<code>gauge(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>No-op gauge.</p>"},{"location":"api/#yokedcache.NoOpCollector.histogram","title":"<code>histogram(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>No-op histogram.</p>"},{"location":"api/#yokedcache.NoOpCollector.increment","title":"<code>increment(metric: str, value: int = 1, tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>No-op increment.</p>"},{"location":"api/#yokedcache.NoOpCollector.timing","title":"<code>timing(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>No-op timing.</p>"},{"location":"api/#yokedcache.PrefixRouter","title":"<code>PrefixRouter</code>","text":"<p>Routes cache operations to backends based on key prefixes.</p>"},{"location":"api/#yokedcache.PrefixRouter.add_route","title":"<code>add_route(prefix: str, backend: CacheBackend) -&gt; None</code>","text":"<p>Add a prefix -&gt; backend mapping.</p>"},{"location":"api/#yokedcache.PrefixRouter.connect_all","title":"<code>connect_all() -&gt; None</code>  <code>async</code>","text":"<p>Connect all registered backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.delete","title":"<code>delete(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Route delete operation to appropriate backend.</p>"},{"location":"api/#yokedcache.PrefixRouter.disconnect_all","title":"<code>disconnect_all() -&gt; None</code>  <code>async</code>","text":"<p>Disconnect all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.exists","title":"<code>exists(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Route exists operation to appropriate backend.</p>"},{"location":"api/#yokedcache.PrefixRouter.expire","title":"<code>expire(key: str, ttl: int) -&gt; bool</code>  <code>async</code>","text":"<p>Route expire operation to appropriate backend.</p>"},{"location":"api/#yokedcache.PrefixRouter.flush_all","title":"<code>flush_all() -&gt; bool</code>  <code>async</code>","text":"<p>Flush all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.fuzzy_search","title":"<code>fuzzy_search(query: str, threshold: int = 80, max_results: int = 10, tags: Optional[Set[str]] = None) -&gt; List[FuzzySearchResult]</code>  <code>async</code>","text":"<p>Perform fuzzy search across all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.get","title":"<code>get(key: str, default: Any = None) -&gt; Any</code>  <code>async</code>","text":"<p>Route get operation to appropriate backend.</p>"},{"location":"api/#yokedcache.PrefixRouter.get_all_keys","title":"<code>get_all_keys(pattern: str = '*') -&gt; List[str]</code>  <code>async</code>","text":"<p>Get all keys matching pattern from all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.get_backend","title":"<code>get_backend(key: str) -&gt; CacheBackend</code>","text":"<p>Get the appropriate backend for a given key.</p>"},{"location":"api/#yokedcache.PrefixRouter.get_size_bytes","title":"<code>get_size_bytes() -&gt; int</code>  <code>async</code>","text":"<p>Get total size across all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.get_stats","title":"<code>get_stats() -&gt; Dict[str, CacheStats]</code>  <code>async</code>","text":"<p>Get stats from all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.health_check_all","title":"<code>health_check_all() -&gt; Dict[str, bool]</code>  <code>async</code>","text":"<p>Check health of all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.invalidate_pattern","title":"<code>invalidate_pattern(pattern: str) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate pattern across all relevant backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.invalidate_tags","title":"<code>invalidate_tags(tags: Union[str, List[str], Set[str]]) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate tags across all backends.</p>"},{"location":"api/#yokedcache.PrefixRouter.remove_route","title":"<code>remove_route(prefix: str) -&gt; bool</code>","text":"<p>Remove a prefix route. Returns True if removed.</p>"},{"location":"api/#yokedcache.PrefixRouter.set","title":"<code>set(key: str, value: Any, ttl: Optional[int] = None, tags: Optional[Set[str]] = None) -&gt; bool</code>  <code>async</code>","text":"<p>Route set operation to appropriate backend.</p>"},{"location":"api/#yokedcache.PrometheusCollector","title":"<code>PrometheusCollector</code>","text":"<p>               Bases: <code>MetricsCollector</code></p> <p>Prometheus metrics collector.</p>"},{"location":"api/#yokedcache.PrometheusCollector.gauge","title":"<code>gauge(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Set a gauge metric.</p>"},{"location":"api/#yokedcache.PrometheusCollector.histogram","title":"<code>histogram(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Record a histogram value.</p>"},{"location":"api/#yokedcache.PrometheusCollector.increment","title":"<code>increment(metric: str, value: int = 1, tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Increment a counter metric.</p>"},{"location":"api/#yokedcache.PrometheusCollector.timing","title":"<code>timing(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Record a timing metric.</p>"},{"location":"api/#yokedcache.RedisBackend","title":"<code>RedisBackend</code>","text":"<p>               Bases: <code>CacheBackend</code></p> <p>Redis cache backend implementation.</p>"},{"location":"api/#yokedcache.RedisBackend.connect","title":"<code>connect() -&gt; None</code>  <code>async</code>","text":"<p>Establish connection to Redis.</p>"},{"location":"api/#yokedcache.RedisBackend.delete","title":"<code>delete(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Delete key from cache.</p>"},{"location":"api/#yokedcache.RedisBackend.disconnect","title":"<code>disconnect() -&gt; None</code>  <code>async</code>","text":"<p>Close Redis connection.</p>"},{"location":"api/#yokedcache.RedisBackend.exists","title":"<code>exists(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Check if key exists in cache.</p>"},{"location":"api/#yokedcache.RedisBackend.expire","title":"<code>expire(key: str, ttl: int) -&gt; bool</code>  <code>async</code>","text":"<p>Set expiration time for existing key.</p>"},{"location":"api/#yokedcache.RedisBackend.flush_all","title":"<code>flush_all() -&gt; bool</code>  <code>async</code>","text":"<p>Flush all cache keys with the configured prefix.</p>"},{"location":"api/#yokedcache.RedisBackend.fuzzy_search","title":"<code>fuzzy_search(query: str, threshold: int = 80, max_results: int = 10, tags: Optional[Set[str]] = None) -&gt; List[FuzzySearchResult]</code>  <code>async</code>","text":"<p>Perform fuzzy search on cached data.</p>"},{"location":"api/#yokedcache.RedisBackend.get","title":"<code>get(key: str, default: Any = None) -&gt; Any</code>  <code>async</code>","text":"<p>Get value from cache.</p>"},{"location":"api/#yokedcache.RedisBackend.get_all_keys","title":"<code>get_all_keys(pattern: str = '*') -&gt; List[str]</code>  <code>async</code>","text":"<p>Get all keys matching pattern.</p>"},{"location":"api/#yokedcache.RedisBackend.get_size_bytes","title":"<code>get_size_bytes() -&gt; int</code>  <code>async</code>","text":"<p>Get total size of cache in bytes.</p>"},{"location":"api/#yokedcache.RedisBackend.get_stats","title":"<code>get_stats() -&gt; CacheStats</code>  <code>async</code>","text":"<p>Get current cache statistics.</p>"},{"location":"api/#yokedcache.RedisBackend.health_check","title":"<code>health_check() -&gt; bool</code>  <code>async</code>","text":"<p>Check if Redis connection is healthy.</p>"},{"location":"api/#yokedcache.RedisBackend.invalidate_pattern","title":"<code>invalidate_pattern(pattern: str) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys matching a pattern.</p>"},{"location":"api/#yokedcache.RedisBackend.invalidate_tags","title":"<code>invalidate_tags(tags: Union[str, List[str], Set[str]]) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys associated with given tags.</p>"},{"location":"api/#yokedcache.RedisBackend.set","title":"<code>set(key: str, value: Any, ttl: Optional[int] = None, tags: Optional[Set[str]] = None) -&gt; bool</code>  <code>async</code>","text":"<p>Set value in cache.</p>"},{"location":"api/#yokedcache.SWRScheduler","title":"<code>SWRScheduler</code>","text":"<p>Manages background refresh scheduling for SWR pattern.</p>"},{"location":"api/#yokedcache.SWRScheduler.cancel_refresh","title":"<code>cancel_refresh(key: str) -&gt; bool</code>","text":"<p>Cancel a scheduled refresh for a key.</p>"},{"location":"api/#yokedcache.SWRScheduler.get_active_refreshes","title":"<code>get_active_refreshes() -&gt; Set[str]</code>","text":"<p>Get the set of keys with active refresh tasks.</p>"},{"location":"api/#yokedcache.SWRScheduler.get_stats","title":"<code>get_stats() -&gt; Dict[str, Any]</code>","text":"<p>Get statistics about the SWR scheduler.</p>"},{"location":"api/#yokedcache.SWRScheduler.schedule_refresh","title":"<code>schedule_refresh(key: str, loader: Callable[[], Any], ttl: Optional[int] = None, tags: Optional[Union[str, list, Set[str]]] = None, refresh_threshold: float = 0.1) -&gt; None</code>","text":"<p>Schedule a background refresh for a key.</p>"},{"location":"api/#yokedcache.SWRScheduler.start","title":"<code>start() -&gt; None</code>","text":"<p>Start the SWR scheduler.</p>"},{"location":"api/#yokedcache.SWRScheduler.stop","title":"<code>stop() -&gt; None</code>  <code>async</code>","text":"<p>Stop the SWR scheduler and cancel all refresh tasks.</p>"},{"location":"api/#yokedcache.StatsDCollector","title":"<code>StatsDCollector</code>","text":"<p>               Bases: <code>MetricsCollector</code></p> <p>StatsD metrics collector.</p>"},{"location":"api/#yokedcache.StatsDCollector.gauge","title":"<code>gauge(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Set a gauge metric.</p>"},{"location":"api/#yokedcache.StatsDCollector.histogram","title":"<code>histogram(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Record a histogram value.</p>"},{"location":"api/#yokedcache.StatsDCollector.increment","title":"<code>increment(metric: str, value: int = 1, tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Increment a counter metric.</p>"},{"location":"api/#yokedcache.StatsDCollector.timing","title":"<code>timing(metric: str, value: Union[int, float], tags: Optional[Dict[str, str]] = None) -&gt; None</code>  <code>async</code>","text":"<p>Record a timing metric.</p>"},{"location":"api/#yokedcache.YokedCacheError","title":"<code>YokedCacheError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for all YokedCache errors.</p>"},{"location":"api/#yokedcache.cached","title":"<code>cached(cache: Optional[YokedCache] = None, ttl: Optional[int] = None, key_prefix: Optional[str] = None, tags: Optional[Union[str, List[str], Set[str]]] = None, table: Optional[str] = None, serialization: Optional[SerializationMethod] = None, skip_cache_on_error: bool = True, key_builder: Optional[Callable[..., str]] = None, key_func: Optional[Callable[..., str]] = None, condition: Optional[Callable[..., bool]] = None) -&gt; Callable[[F], F]</code>","text":"<p>Decorator to cache function results.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Optional[YokedCache]</code> <p>YokedCache instance (if None, creates default)</p> <code>None</code> <code>ttl</code> <code>Optional[int]</code> <p>Cache TTL in seconds</p> <code>None</code> <code>key_prefix</code> <code>Optional[str]</code> <p>Custom key prefix for this function</p> <code>None</code> <code>tags</code> <code>Optional[Union[str, List[str], Set[str]]]</code> <p>Tags for cache invalidation</p> <code>None</code> <code>table</code> <code>Optional[str]</code> <p>Database table name for auto-invalidation</p> <code>None</code> <code>serialization</code> <code>Optional[SerializationMethod]</code> <p>Serialization method</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[F], F]</code> <p>Decorated function</p>"},{"location":"api/#yokedcache.cached_dependency","title":"<code>cached_dependency(cache_or_func: Optional[Union[YokedCache, Callable[..., Any]]] = None, *, cache: Optional[YokedCache] = None, ttl: Optional[int] = None, key_prefix: Optional[str] = None, table_name: Optional[str] = None, auto_invalidate: bool = True, dependencies: Optional[Union[str, List[str], Callable[..., Iterable[str]]]] = None) -&gt; Union[Callable[..., Any], Callable[[Callable[..., Any]], Callable[..., Any]]]</code>","text":"<pre><code>cached_dependency(cache_or_func: Callable[..., Any], *, cache: Optional[YokedCache] = ..., ttl: Optional[int] = ..., key_prefix: Optional[str] = ..., table_name: Optional[str] = ..., auto_invalidate: bool = ..., dependencies: Optional[Union[str, List[str], Callable[..., Iterable[str]]]] = ...) -&gt; Callable[..., Any]\n</code></pre><pre><code>cached_dependency(cache_or_func: Optional[YokedCache] = ..., *, cache: Optional[YokedCache] = ..., ttl: Optional[int] = ..., key_prefix: Optional[str] = ..., table_name: Optional[str] = ..., auto_invalidate: bool = ..., dependencies: Optional[Union[str, List[str], Callable[..., Iterable[str]]]] = ...) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]\n</code></pre> <p>Wrap a FastAPI dependency with caching.</p> <p>This is specifically designed for database dependencies like get_db(). Properly handles both regular functions and generator functions.</p> <p>Can be used in two ways: 1. As decorator: @cached_dependency(cache, dependencies=[\"user:123\"]) 2. As function: cached_dependency(func, cache=cache)</p> <p>Parameters:</p> Name Type Description Default <code>cache_or_func</code> <code>Optional[Union[YokedCache, Callable[..., Any]]]</code> <p>Either YokedCache instance or function to wrap</p> <code>None</code> <code>cache</code> <code>Optional[YokedCache]</code> <p>YokedCache instance (when using function style)</p> <code>None</code> <code>ttl</code> <code>Optional[int]</code> <p>Cache TTL in seconds</p> <code>None</code> <code>key_prefix</code> <code>Optional[str]</code> <p>Custom key prefix</p> <code>None</code> <code>table_name</code> <code>Optional[str]</code> <p>Table name for auto-invalidation</p> <code>None</code> <code>auto_invalidate</code> <code>bool</code> <p>Enable auto-invalidation on writes</p> <code>True</code> <code>dependencies</code> <code>Optional[Union[str, List[str], Callable[..., Iterable[str]]]]</code> <p>Cache dependencies for invalidation</p> <code>None</code> <p>Decorator function that wraps the dependency function or wrapped</p>"},{"location":"api/#yokedcache.deserialize_data","title":"<code>deserialize_data(data: bytes, method: SerializationMethod = SerializationMethod.JSON) -&gt; Any</code>","text":"<p>Deserialize data using the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Serialized data as bytes</p> required <code>method</code> <code>SerializationMethod</code> <p>Serialization method that was used</p> <code>JSON</code> <p>Returns:</p> Type Description <code>Any</code> <p>Deserialized data</p> <p>Raises:</p> Type Description <code>CacheSerializationError</code> <p>If deserialization fails</p>"},{"location":"api/#yokedcache.generate_cache_key","title":"<code>generate_cache_key(prefix: str, table: Optional[str] = None, query: Optional[str] = None, params: Optional[Dict[str, Any]] = None, user_id: Optional[Union[str, int]] = None, namespace: Optional[str] = None) -&gt; str</code>","text":"<p>Generate a standardized cache key.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Cache key prefix (usually app name)</p> required <code>table</code> <code>Optional[str]</code> <p>Database table name</p> <code>None</code> <code>query</code> <code>Optional[str]</code> <p>SQL query or operation identifier</p> <code>None</code> <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Query parameters or filters</p> <code>None</code> <code>user_id</code> <code>Optional[Union[str, int]]</code> <p>User identifier for user-specific caching</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Additional namespace for multi-tenancy</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cache key string</p>"},{"location":"api/#yokedcache.initialize_tracing","title":"<code>initialize_tracing(service_name: str = 'yokedcache', enabled: bool = True, sample_rate: float = 1.0) -&gt; CacheTracer</code>","text":"<p>Initialize global tracing configuration.</p>"},{"location":"api/#yokedcache.serialize_data","title":"<code>serialize_data(data: Any, method: SerializationMethod = SerializationMethod.JSON) -&gt; bytes</code>","text":"<p>Serialize data using the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to serialize</p> required <code>method</code> <code>SerializationMethod</code> <p>Serialization method to use</p> <code>JSON</code> <p>Returns:</p> Type Description <code>bytes</code> <p>Serialized data as bytes</p> <p>Raises:</p> Type Description <code>CacheSerializationError</code> <p>If serialization fails</p>"},{"location":"api/#core","title":"Core","text":""},{"location":"api/#cache","title":"Cache","text":"<p>Core YokedCache implementation.</p> <p>This module contains the main YokedCache class that provides the primary caching functionality, including Redis integration, auto-invalidation, and cache management operations.</p>"},{"location":"api/#yokedcache.cache--flake8-noqa","title":"flake8: noqa","text":""},{"location":"api/#yokedcache.cache.YokedCache","title":"<code>YokedCache</code>","text":"<p>Main caching class that provides intelligent caching with Redis backend.</p> <p>Features: - Automatic cache invalidation based on database operations - Variable TTLs per table/query type - Tag-based cache grouping and invalidation - Fuzzy search capabilities - Performance metrics and monitoring - Async/await support for FastAPI integration</p>"},{"location":"api/#yokedcache.cache.YokedCache.add_backend_route","title":"<code>add_backend_route(prefix: str, backend) -&gt; None</code>","text":"<p>Add a prefix -&gt; backend route.</p>"},{"location":"api/#yokedcache.cache.YokedCache.adelete","title":"<code>adelete(*args, **kwargs) -&gt; bool</code>  <code>async</code>","text":"<p>Explicitly async version of delete.</p>"},{"location":"api/#yokedcache.cache.YokedCache.aexists","title":"<code>aexists(*args, **kwargs) -&gt; bool</code>  <code>async</code>","text":"<p>Explicitly async version of exists.</p>"},{"location":"api/#yokedcache.cache.YokedCache.aget","title":"<code>aget(*args, **kwargs) -&gt; Any</code>  <code>async</code>","text":"<p>Explicitly async version of get.</p>"},{"location":"api/#yokedcache.cache.YokedCache.aset","title":"<code>aset(*args, **kwargs) -&gt; bool</code>  <code>async</code>","text":"<p>Explicitly async version of set.</p>"},{"location":"api/#yokedcache.cache.YokedCache.close","title":"<code>close() -&gt; None</code>  <code>async</code>","text":"<p>Close the cache connection.</p>"},{"location":"api/#yokedcache.cache.YokedCache.connect","title":"<code>connect() -&gt; None</code>  <code>async</code>","text":"<p>Establish connection to Redis.</p> <p>Tests patch <code>redis.asyncio.from_url</code>; use that path for compatibility.</p>"},{"location":"api/#yokedcache.cache.YokedCache.delete","title":"<code>delete(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Delete key from cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key to delete</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if key was deleted, False if key didn't exist</p>"},{"location":"api/#yokedcache.cache.YokedCache.delete_sync","title":"<code>delete_sync(key: str) -&gt; bool</code>","text":"<p>Sync version of delete().</p>"},{"location":"api/#yokedcache.cache.YokedCache.detailed_health_check","title":"<code>detailed_health_check() -&gt; Dict[str, Any]</code>  <code>async</code>","text":"<p>Comprehensive health check for monitoring.</p> <p>Returns detailed information about cache health, performance, and system status suitable for monitoring dashboards.</p>"},{"location":"api/#yokedcache.cache.YokedCache.disconnect","title":"<code>disconnect() -&gt; None</code>  <code>async</code>","text":"<p>Close Redis connection.</p>"},{"location":"api/#yokedcache.cache.YokedCache.exists","title":"<code>exists(key: str) -&gt; bool</code>  <code>async</code>","text":"<p>Check if key exists in cache.</p>"},{"location":"api/#yokedcache.cache.YokedCache.exists_sync","title":"<code>exists_sync(key: str) -&gt; bool</code>","text":"<p>Sync version of exists().</p>"},{"location":"api/#yokedcache.cache.YokedCache.expire","title":"<code>expire(key: str, ttl: int) -&gt; bool</code>  <code>async</code>","text":"<p>Set expiration time for existing key.</p>"},{"location":"api/#yokedcache.cache.YokedCache.fetch_or_set","title":"<code>fetch_or_set(key: str, loader: Callable[[], Any], ttl: Optional[int] = None, tags: Optional[Union[str, List[str], Set[str]]] = None, serialization: Optional[SerializationMethod] = None) -&gt; Any</code>  <code>async</code>","text":"<p>Fetch a key or compute and set it atomically (stampede protection).</p> <p>Uses per-key asyncio.Lock to ensure only one loader executes.</p>"},{"location":"api/#yokedcache.cache.YokedCache.flush","title":"<code>flush() -&gt; bool</code>  <code>async</code>","text":"<p>Flush all cache data.</p>"},{"location":"api/#yokedcache.cache.YokedCache.flush_all","title":"<code>flush_all() -&gt; bool</code>  <code>async</code>","text":"<p>Flush all cache keys with the configured prefix.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"api/#yokedcache.cache.YokedCache.fuzzy_search","title":"<code>fuzzy_search(query: str, threshold: int = 80, max_results: int = 10, tags: Optional[Set[str]] = None) -&gt; List[FuzzySearchResult]</code>  <code>async</code>","text":"<p>Perform fuzzy search on cached data.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query</p> required <code>threshold</code> <code>int</code> <p>Similarity threshold (0-100)</p> <code>80</code> <code>max_results</code> <code>int</code> <p>Maximum number of results</p> <code>10</code> <code>tags</code> <code>Optional[Set[str]]</code> <p>Optional tags to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>List[FuzzySearchResult]</code> <p>List of fuzzy search results</p>"},{"location":"api/#yokedcache.cache.YokedCache.get","title":"<code>get(key: str, default: Any = None, touch: bool = True) -&gt; Any</code>  <code>async</code>","text":"<p>Get value from cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key</p> required <code>default</code> <code>Any</code> <p>Default value if key not found</p> <code>None</code> <code>touch</code> <code>bool</code> <p>Whether to update access time and hit count</p> <code>True</code> <p>Returns:</p> Type Description <code>Any</code> <p>Cached value or default</p>"},{"location":"api/#yokedcache.cache.YokedCache.get_comprehensive_metrics","title":"<code>get_comprehensive_metrics() -&gt; Dict[str, Any]</code>  <code>async</code>","text":"<p>Get comprehensive metrics including enhanced performance data.</p>"},{"location":"api/#yokedcache.cache.YokedCache.get_stats","title":"<code>get_stats() -&gt; CacheStats</code>  <code>async</code>","text":"<p>Get current cache statistics.</p>"},{"location":"api/#yokedcache.cache.YokedCache.get_sync","title":"<code>get_sync(key: str, default: Any = None, touch: bool = True) -&gt; Any</code>","text":"<p>Sync version of get() with proper async context detection.</p> <p>Warns when used in async context and suggests using aget() instead.</p>"},{"location":"api/#yokedcache.cache.YokedCache.health","title":"<code>health() -&gt; bool</code>  <code>async</code>","text":"<p>Check if the cache is healthy.</p>"},{"location":"api/#yokedcache.cache.YokedCache.health_check","title":"<code>health_check() -&gt; bool</code>  <code>async</code>","text":"<p>Check if Redis connection is healthy.</p>"},{"location":"api/#yokedcache.cache.YokedCache.invalidate_by_tags","title":"<code>invalidate_by_tags(tags: Union[str, List[str], Set[str]]) -&gt; int</code>  <code>async</code>","text":"<p>Alias for invalidate_tags for backward compatibility.</p>"},{"location":"api/#yokedcache.cache.YokedCache.invalidate_pattern","title":"<code>invalidate_pattern(pattern: str) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys matching a pattern.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>Redis pattern (supports * and ? wildcards)</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of keys invalidated</p>"},{"location":"api/#yokedcache.cache.YokedCache.invalidate_tags","title":"<code>invalidate_tags(tags: Union[str, List[str], Set[str]]) -&gt; int</code>  <code>async</code>","text":"<p>Invalidate all keys associated with given tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str], Set[str]]</code> <p>Tags to invalidate</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of keys invalidated</p>"},{"location":"api/#yokedcache.cache.YokedCache.ping","title":"<code>ping() -&gt; bool</code>  <code>async</code>","text":"<p>Ping the cache backend.</p>"},{"location":"api/#yokedcache.cache.YokedCache.remove_backend_route","title":"<code>remove_backend_route(prefix: str) -&gt; bool</code>","text":"<p>Remove a prefix route.</p>"},{"location":"api/#yokedcache.cache.YokedCache.set","title":"<code>set(key: str, value: Any, ttl: Optional[int] = None, tags: Optional[Union[str, List[str], Set[str]]] = None, serialization: Optional[SerializationMethod] = None) -&gt; bool</code>  <code>async</code>","text":"<p>Set value in cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key</p> required <code>value</code> <code>Any</code> <p>Value to cache</p> required <code>ttl</code> <code>Optional[int]</code> <p>Time to live in seconds</p> <code>None</code> <code>tags</code> <code>Optional[Union[str, List[str], Set[str]]]</code> <p>Tags for grouping and invalidation</p> <code>None</code> <code>serialization</code> <code>Optional[SerializationMethod]</code> <p>Serialization method to use</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p>"},{"location":"api/#yokedcache.cache.YokedCache.set_sync","title":"<code>set_sync(key: str, value: Any, ttl: Optional[int] = None, tags: Optional[Union[str, List[str], Set[str]]] = None, serialization: Optional[SerializationMethod] = None) -&gt; bool</code>","text":"<p>Sync version of set().</p>"},{"location":"api/#yokedcache.cache.YokedCache.setup_prefix_routing","title":"<code>setup_prefix_routing(default_backend_type: str = 'redis') -&gt; None</code>","text":"<p>Setup prefix-based routing with the current cache as default backend.</p>"},{"location":"api/#yokedcache.cache.YokedCache.start_metrics_collection","title":"<code>start_metrics_collection() -&gt; None</code>","text":"<p>Start background metrics collection if enabled.</p>"},{"location":"api/#yokedcache.cache.YokedCache.stop_metrics_collection","title":"<code>stop_metrics_collection() -&gt; None</code>  <code>async</code>","text":"<p>Stop background metrics collection.</p>"},{"location":"api/#decorators","title":"Decorators","text":"<p>Decorators for YokedCache integration.</p> <p>This module provides decorators for easy integration with FastAPI and other Python frameworks, enabling automatic caching of functions and dependencies.</p>"},{"location":"api/#yokedcache.decorators.CachedDatabaseWrapper","title":"<code>CachedDatabaseWrapper</code>","text":"<p>Wrapper for database sessions that adds caching capabilities.</p> <p>This wrapper intercepts database queries and automatically caches results while also handling cache invalidation on write operations.</p>"},{"location":"api/#yokedcache.decorators.CachedDatabaseWrapper.cache","title":"<code>cache</code>  <code>property</code>","text":"<p>Access to the cache instance.</p>"},{"location":"api/#yokedcache.decorators.CachedDatabaseWrapper.pending_invalidations","title":"<code>pending_invalidations</code>  <code>property</code>","text":"<p>Get pending write operations that will trigger invalidation.</p>"},{"location":"api/#yokedcache.decorators.CachedDatabaseWrapper.session","title":"<code>session</code>  <code>property</code>","text":"<p>Access to the underlying database session.</p>"},{"location":"api/#yokedcache.decorators.CachedDatabaseWrapper.commit","title":"<code>commit()</code>  <code>async</code>","text":"<p>Handle commit operations with cache invalidation.</p>"},{"location":"api/#yokedcache.decorators.CachedDatabaseWrapper.invalidate_pending","title":"<code>invalidate_pending()</code>  <code>async</code>","text":"<p>Invalidate pending cache entries based on write operations.</p>"},{"location":"api/#yokedcache.decorators.cached","title":"<code>cached(cache: Optional[YokedCache] = None, ttl: Optional[int] = None, key_prefix: Optional[str] = None, tags: Optional[Union[str, List[str], Set[str]]] = None, table: Optional[str] = None, serialization: Optional[SerializationMethod] = None, skip_cache_on_error: bool = True, key_builder: Optional[Callable[..., str]] = None, key_func: Optional[Callable[..., str]] = None, condition: Optional[Callable[..., bool]] = None) -&gt; Callable[[F], F]</code>","text":"<p>Decorator to cache function results.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Optional[YokedCache]</code> <p>YokedCache instance (if None, creates default)</p> <code>None</code> <code>ttl</code> <code>Optional[int]</code> <p>Cache TTL in seconds</p> <code>None</code> <code>key_prefix</code> <code>Optional[str]</code> <p>Custom key prefix for this function</p> <code>None</code> <code>tags</code> <code>Optional[Union[str, List[str], Set[str]]]</code> <p>Tags for cache invalidation</p> <code>None</code> <code>table</code> <code>Optional[str]</code> <p>Database table name for auto-invalidation</p> <code>None</code> <code>serialization</code> <code>Optional[SerializationMethod]</code> <p>Serialization method</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[F], F]</code> <p>Decorated function</p>"},{"location":"api/#yokedcache.decorators.cached_dependency","title":"<code>cached_dependency(cache_or_func: Optional[Union[YokedCache, Callable[..., Any]]] = None, *, cache: Optional[YokedCache] = None, ttl: Optional[int] = None, key_prefix: Optional[str] = None, table_name: Optional[str] = None, auto_invalidate: bool = True, dependencies: Optional[Union[str, List[str], Callable[..., Iterable[str]]]] = None) -&gt; Union[Callable[..., Any], Callable[[Callable[..., Any]], Callable[..., Any]]]</code>","text":"<pre><code>cached_dependency(cache_or_func: Callable[..., Any], *, cache: Optional[YokedCache] = ..., ttl: Optional[int] = ..., key_prefix: Optional[str] = ..., table_name: Optional[str] = ..., auto_invalidate: bool = ..., dependencies: Optional[Union[str, List[str], Callable[..., Iterable[str]]]] = ...) -&gt; Callable[..., Any]\n</code></pre><pre><code>cached_dependency(cache_or_func: Optional[YokedCache] = ..., *, cache: Optional[YokedCache] = ..., ttl: Optional[int] = ..., key_prefix: Optional[str] = ..., table_name: Optional[str] = ..., auto_invalidate: bool = ..., dependencies: Optional[Union[str, List[str], Callable[..., Iterable[str]]]] = ...) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]\n</code></pre> <p>Wrap a FastAPI dependency with caching.</p> <p>This is specifically designed for database dependencies like get_db(). Properly handles both regular functions and generator functions.</p> <p>Can be used in two ways: 1. As decorator: @cached_dependency(cache, dependencies=[\"user:123\"]) 2. As function: cached_dependency(func, cache=cache)</p> <p>Parameters:</p> Name Type Description Default <code>cache_or_func</code> <code>Optional[Union[YokedCache, Callable[..., Any]]]</code> <p>Either YokedCache instance or function to wrap</p> <code>None</code> <code>cache</code> <code>Optional[YokedCache]</code> <p>YokedCache instance (when using function style)</p> <code>None</code> <code>ttl</code> <code>Optional[int]</code> <p>Cache TTL in seconds</p> <code>None</code> <code>key_prefix</code> <code>Optional[str]</code> <p>Custom key prefix</p> <code>None</code> <code>table_name</code> <code>Optional[str]</code> <p>Table name for auto-invalidation</p> <code>None</code> <code>auto_invalidate</code> <code>bool</code> <p>Enable auto-invalidation on writes</p> <code>True</code> <code>dependencies</code> <code>Optional[Union[str, List[str], Callable[..., Iterable[str]]]]</code> <p>Cache dependencies for invalidation</p> <code>None</code> <p>Decorator function that wraps the dependency function or wrapped</p>"},{"location":"api/#yokedcache.decorators.warm_cache","title":"<code>warm_cache(cache: YokedCache, functions_to_warm: List[Dict[str, Any]]) -&gt; int</code>  <code>async</code>","text":"<p>Warm cache by pre-executing functions.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>YokedCache</code> <p>YokedCache instance</p> required <code>functions_to_warm</code> <code>List[Dict[str, Any]]</code> <p>List of function configurations [{\"func\": function, \"args\": [], \"kwargs\": {}, \"ttl\": 300}, ...]</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of functions successfully warmed</p>"},{"location":"api/#configuration","title":"Configuration","text":"<p>Configuration management for YokedCache.</p> <p>This module handles loading and managing configuration from files, environment variables, and programmatic settings.</p>"},{"location":"api/#yokedcache.config.CacheConfig","title":"<code>CacheConfig</code>  <code>dataclass</code>","text":"<p>Main configuration class for YokedCache.</p>"},{"location":"api/#yokedcache.config.CacheConfig.add_table_config","title":"<code>add_table_config(config: TableCacheConfig) -&gt; None</code>","text":"<p>Add or update table-specific configuration.</p>"},{"location":"api/#yokedcache.config.CacheConfig.get_connection_pool_config","title":"<code>get_connection_pool_config() -&gt; Dict[str, Any]</code>","text":"<p>Get connection pool configuration including custom kwargs.</p>"},{"location":"api/#yokedcache.config.CacheConfig.get_table_config","title":"<code>get_table_config(table_name: str) -&gt; TableCacheConfig</code>","text":"<p>Get configuration for a specific table, with fallbacks.</p>"},{"location":"api/#yokedcache.config.CacheConfig.to_dict","title":"<code>to_dict() -&gt; Dict[str, Any]</code>","text":"<p>Convert configuration to dictionary.</p>"},{"location":"api/#yokedcache.config.create_default_config","title":"<code>create_default_config() -&gt; CacheConfig</code>","text":"<p>Create a default configuration instance.</p>"},{"location":"api/#yokedcache.config.load_config_from_file","title":"<code>load_config_from_file(file_path: Union[str, Path]) -&gt; CacheConfig</code>","text":"<p>Load configuration from a YAML file.</p>"},{"location":"api/#yokedcache.config.save_config_to_file","title":"<code>save_config_to_file(config: CacheConfig, file_path: Union[str, Path]) -&gt; None</code>","text":"<p>Save configuration to a YAML file.</p>"},{"location":"api/#models","title":"Models","text":"<p>Data models and structures for YokedCache.</p> <p>This module defines the core data structures used throughout YokedCache, including cache entries, statistics, and configuration models.</p>"},{"location":"api/#yokedcache.models.CacheEntry","title":"<code>CacheEntry</code>  <code>dataclass</code>","text":"<p>Represents a single cache entry with metadata.</p>"},{"location":"api/#yokedcache.models.CacheEntry.age_seconds","title":"<code>age_seconds: float</code>  <code>property</code>","text":"<p>Get the age of the cache entry in seconds.</p>"},{"location":"api/#yokedcache.models.CacheEntry.is_expired","title":"<code>is_expired: bool</code>  <code>property</code>","text":"<p>Check if the cache entry has expired.</p>"},{"location":"api/#yokedcache.models.CacheEntry.touch","title":"<code>touch() -&gt; None</code>","text":"<p>Update the last accessed timestamp and increment hit count.</p>"},{"location":"api/#yokedcache.models.CacheOperation","title":"<code>CacheOperation</code>  <code>dataclass</code>","text":"<p>Represents a cache operation for logging/debugging.</p>"},{"location":"api/#yokedcache.models.CacheStats","title":"<code>CacheStats</code>  <code>dataclass</code>","text":"<p>Cache performance and usage statistics.</p>"},{"location":"api/#yokedcache.models.CacheStats.hit_rate","title":"<code>hit_rate: float</code>  <code>property</code>","text":"<p>Calculate cache hit rate as a percentage.</p>"},{"location":"api/#yokedcache.models.CacheStats.memory_usage","title":"<code>memory_usage: int</code>  <code>property</code>","text":"<p>Alias for total_memory_bytes for backward compatibility.</p>"},{"location":"api/#yokedcache.models.CacheStats.miss_rate","title":"<code>miss_rate: float</code>  <code>property</code>","text":"<p>Calculate cache miss rate as a percentage.</p>"},{"location":"api/#yokedcache.models.CacheStats.add_hit","title":"<code>add_hit(table: Optional[str] = None, tags: Optional[Set[str]] = None) -&gt; None</code>","text":"<p>Record a cache hit.</p>"},{"location":"api/#yokedcache.models.CacheStats.add_miss","title":"<code>add_miss(table: Optional[str] = None, tags: Optional[Set[str]] = None) -&gt; None</code>","text":"<p>Record a cache miss.</p>"},{"location":"api/#yokedcache.models.ConnectionPoolStats","title":"<code>ConnectionPoolStats</code>  <code>dataclass</code>","text":"<p>Redis connection pool statistics.</p>"},{"location":"api/#yokedcache.models.FuzzySearchResult","title":"<code>FuzzySearchResult</code>  <code>dataclass</code>","text":"<p>Result from a fuzzy search operation.</p>"},{"location":"api/#yokedcache.models.InvalidationRule","title":"<code>InvalidationRule</code>  <code>dataclass</code>","text":"<p>Defines when and how to invalidate cache entries.</p>"},{"location":"api/#yokedcache.models.InvalidationRule.should_invalidate","title":"<code>should_invalidate(operation_type: InvalidationType) -&gt; bool</code>","text":"<p>Check if this rule should trigger for the given operation type.</p>"},{"location":"api/#yokedcache.models.InvalidationType","title":"<code>InvalidationType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Types of cache invalidation triggers.</p>"},{"location":"api/#yokedcache.models.SerializationMethod","title":"<code>SerializationMethod</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Supported data serialization methods.</p>"},{"location":"api/#yokedcache.models.TableCacheConfig","title":"<code>TableCacheConfig</code>  <code>dataclass</code>","text":"<p>Cache configuration for a specific database table.</p>"},{"location":"api/#utils","title":"Utils","text":"<p>Utility functions for YokedCache.</p> <p>This module provides common utility functions for key generation, data serialization, hashing, and other helper operations.</p>"},{"location":"api/#yokedcache.utils.calculate_ttl_with_jitter","title":"<code>calculate_ttl_with_jitter(base_ttl: int, jitter_percent: float = 10.0) -&gt; int</code>","text":"<p>Calculate TTL with random jitter to prevent thundering herd.</p> <p>Parameters:</p> Name Type Description Default <code>base_ttl</code> <code>int</code> <p>Base TTL in seconds</p> required <code>jitter_percent</code> <code>float</code> <p>Percentage of jitter to add (0-100)</p> <code>10.0</code> <p>Returns:</p> Type Description <code>int</code> <p>TTL with jitter applied</p>"},{"location":"api/#yokedcache.utils.deserialize_data","title":"<code>deserialize_data(data: bytes, method: SerializationMethod = SerializationMethod.JSON) -&gt; Any</code>","text":"<p>Deserialize data using the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Serialized data as bytes</p> required <code>method</code> <code>SerializationMethod</code> <p>Serialization method that was used</p> <code>JSON</code> <p>Returns:</p> Type Description <code>Any</code> <p>Deserialized data</p> <p>Raises:</p> Type Description <code>CacheSerializationError</code> <p>If deserialization fails</p>"},{"location":"api/#yokedcache.utils.extract_table_from_query","title":"<code>extract_table_from_query(query: str) -&gt; Optional[str]</code>","text":"<p>Extract table name from SQL query (simple heuristic).</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL query string</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Extracted table name or None if not found</p>"},{"location":"api/#yokedcache.utils.format_bytes","title":"<code>format_bytes(bytes_value: int) -&gt; str</code>","text":"<p>Format bytes value in human-readable format.</p> <p>Parameters:</p> Name Type Description Default <code>bytes_value</code> <code>int</code> <p>Number of bytes</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted string (e.g., \"1.5 MB\")</p>"},{"location":"api/#yokedcache.utils.generate_cache_key","title":"<code>generate_cache_key(prefix: str, table: Optional[str] = None, query: Optional[str] = None, params: Optional[Dict[str, Any]] = None, user_id: Optional[Union[str, int]] = None, namespace: Optional[str] = None) -&gt; str</code>","text":"<p>Generate a standardized cache key.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Cache key prefix (usually app name)</p> required <code>table</code> <code>Optional[str]</code> <p>Database table name</p> <code>None</code> <code>query</code> <code>Optional[str]</code> <p>SQL query or operation identifier</p> <code>None</code> <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Query parameters or filters</p> <code>None</code> <code>user_id</code> <code>Optional[Union[str, int]]</code> <p>User identifier for user-specific caching</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Additional namespace for multi-tenancy</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cache key string</p>"},{"location":"api/#yokedcache.utils.get_current_timestamp","title":"<code>get_current_timestamp() -&gt; float</code>","text":"<p>Get current UTC timestamp.</p>"},{"location":"api/#yokedcache.utils.get_operation_type_from_query","title":"<code>get_operation_type_from_query(query: str) -&gt; str</code>","text":"<p>Determine operation type from SQL query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL query string</p> required <p>Returns:</p> Type Description <code>str</code> <p>Operation type ('select', 'insert', 'update', 'delete', 'unknown')</p>"},{"location":"api/#yokedcache.utils.normalize_tags","title":"<code>normalize_tags(tags: Union[str, List[str], Set[str]]) -&gt; Set[str]</code>","text":"<p>Normalize tags to a consistent set format.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str], Set[str]]</code> <p>Tags in various formats</p> required <p>Returns:</p> Type Description <code>Set[str]</code> <p>Normalized set of tags</p>"},{"location":"api/#yokedcache.utils.parse_redis_url","title":"<code>parse_redis_url(url: str) -&gt; Dict[str, Any]</code>","text":"<p>Parse Redis URL into connection parameters.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Redis URL (e.g., redis://user:pass@host:port/db)</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of connection parameters</p>"},{"location":"api/#yokedcache.utils.sanitize_key","title":"<code>sanitize_key(key: str) -&gt; str</code>","text":"<p>Sanitize cache key to ensure Redis compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Original cache key</p> required <p>Returns:</p> Type Description <code>str</code> <p>Sanitized cache key</p>"},{"location":"api/#yokedcache.utils.serialize_data","title":"<code>serialize_data(data: Any, method: SerializationMethod = SerializationMethod.JSON) -&gt; bytes</code>","text":"<p>Serialize data using the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to serialize</p> required <code>method</code> <code>SerializationMethod</code> <p>Serialization method to use</p> <code>JSON</code> <p>Returns:</p> Type Description <code>bytes</code> <p>Serialized data as bytes</p> <p>Raises:</p> Type Description <code>CacheSerializationError</code> <p>If serialization fails</p>"},{"location":"api/#yokedcache.utils.timestamp_to_datetime","title":"<code>timestamp_to_datetime(timestamp: float) -&gt; datetime</code>","text":"<p>Convert timestamp to UTC datetime.</p>"},{"location":"api/#yokedcache.utils.timing_decorator","title":"<code>timing_decorator(func)</code>","text":"<p>Decorator to measure function execution time.</p>"},{"location":"api/#yokedcache.utils.timing_decorator_async","title":"<code>timing_decorator_async(func)</code>","text":"<p>Async decorator to measure function execution time.</p>"},{"location":"tutorials/fastapi-redis-caching/","title":"Python FastAPI Caching with Redis Auto-Invalidation","text":"<p>This comprehensive tutorial shows you how to implement high-performance caching in your FastAPI applications using YokedCache, the premier Python caching library for FastAPI with Redis auto-invalidation.</p>"},{"location":"tutorials/fastapi-redis-caching/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to set up Redis caching in FastAPI applications</li> <li>Implementing automatic cache invalidation on database changes</li> <li>Vector search caching for semantic similarity</li> <li>Performance optimization techniques for Python web applications</li> <li>Production-ready caching strategies</li> </ul>"},{"location":"tutorials/fastapi-redis-caching/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>FastAPI application</li> <li>Redis server (local or cloud)</li> <li>Basic understanding of async/await</li> </ul>"},{"location":"tutorials/fastapi-redis-caching/#step-1-installation","title":"Step 1: Installation","text":"<p>Install YokedCache with full features for your FastAPI application:</p> <pre><code>pip install yokedcache[full]\n</code></pre> <p>This includes: - Redis caching backend - Vector search capabilities - Monitoring and metrics - Fuzzy search features</p>"},{"location":"tutorials/fastapi-redis-caching/#step-2-basic-fastapi-redis-caching-setup","title":"Step 2: Basic FastAPI Redis Caching Setup","text":"<pre><code>from fastapi import FastAPI, Depends, HTTPException\nfrom sqlalchemy.orm import Session\nfrom yokedcache import YokedCache, cached_dependency\nfrom .database import get_db\nfrom .models import User\nfrom .schemas import UserResponse\n\napp = FastAPI(title=\"FastAPI with Redis Caching\")\n\n# Initialize YokedCache with Redis\ncache = YokedCache(\n    redis_url=\"redis://localhost:6379/0\",\n    default_ttl=300  # 5 minutes default cache\n)\n\n# Create cached database dependency\ncached_get_db = cached_dependency(\n    get_db,\n    cache=cache,\n    ttl=300,\n    tags=[\"database\"]\n)\n\n@app.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(\n    user_id: int,\n    db: Session = Depends(cached_get_db)\n):\n    \"\"\"\n    Get user by ID with automatic Redis caching.\n\n    This endpoint demonstrates:\n    - Automatic caching of database queries\n    - Cache invalidation on user updates\n    - Zero-code caching integration\n    \"\"\"\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@app.put(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    user_data: UserUpdate,\n    db: Session = Depends(get_db)\n):\n    \"\"\"\n    Update user with automatic cache invalidation.\n\n    YokedCache automatically invalidates related cache entries\n    when database modifications occur.\n    \"\"\"\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # Update user data\n    for field, value in user_data.dict(exclude_unset=True).items():\n        setattr(user, field, value)\n\n    db.commit()\n    db.refresh(user)\n\n    # Cache is automatically invalidated\n    return user\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#step-3-advanced-configuration","title":"Step 3: Advanced Configuration","text":"<p>Configure YokedCache for production use:</p> <pre><code>from yokedcache import YokedCache, CacheConfig\n\n# Production configuration\nconfig = CacheConfig(\n    redis_url=\"redis://your-redis-cluster:6379\",\n    max_connections=50,\n\n    # Circuit breaker for reliability\n    enable_circuit_breaker=True,\n    circuit_breaker_failure_threshold=5,\n    circuit_breaker_timeout=60.0,\n\n    # Connection pool optimization\n    connection_pool_kwargs={\n        \"socket_connect_timeout\": 5.0,\n        \"socket_timeout\": 5.0,\n        \"socket_keepalive\": True,\n        \"retry_on_timeout\": True,\n        \"health_check_interval\": 30\n    },\n\n    # Error handling\n    fallback_enabled=True,\n    connection_retries=3,\n    retry_delay=0.1\n)\n\ncache = YokedCache(config=config)\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#step-4-vector-search-caching","title":"Step 4: Vector Search Caching","text":"<p>Implement semantic similarity caching:</p> <pre><code>from yokedcache.vector_search import VectorSimilaritySearch\n\n# Initialize vector search\nvector_search = VectorSimilaritySearch(\n    similarity_method=\"cosine\",\n    max_features=1000\n)\n\n@app.get(\"/search/products\")\nasync def search_products_semantic(\n    query: str,\n    threshold: float = 0.5,\n    max_results: int = 10\n):\n    \"\"\"\n    Semantic product search with vector caching.\n\n    Uses TF-IDF and cosine similarity for intelligent\n    product recommendations with Redis persistence.\n    \"\"\"\n    # Check cache first\n    cache_key = f\"vector_search:{query}:{threshold}\"\n    cached_results = await cache.get(cache_key)\n\n    if cached_results:\n        return cached_results\n\n    # Perform vector search\n    results = await cache.vector_search(\n        query=query,\n        threshold=threshold,\n        max_results=max_results\n    )\n\n    # Cache results for 1 hour\n    await cache.set(cache_key, results, ttl=3600, tags=[\"vector_search\"])\n\n    return results\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#step-5-monitoring-and-metrics","title":"Step 5: Monitoring and Metrics","text":"<p>Add production monitoring:</p> <pre><code>from yokedcache.monitoring import PrometheusCollector, CacheMetrics\n\n# Set up monitoring\nprometheus = PrometheusCollector(namespace=\"fastapi_app\")\ncache_metrics = CacheMetrics([prometheus])\n\n# Initialize cache with monitoring\ncache = YokedCache(\n    config=config,\n    metrics=cache_metrics\n)\n\n@app.get(\"/health/cache\")\nasync def cache_health():\n    \"\"\"Check Redis cache health and performance metrics.\"\"\"\n    health = await cache.detailed_health_check()\n    metrics = cache.get_comprehensive_metrics()\n\n    return {\n        \"status\": health[\"status\"],\n        \"hit_rate\": f\"{metrics.hit_rate:.2%}\",\n        \"avg_response_time\": f\"{metrics.avg_response_time:.3f}s\",\n        \"connections\": health[\"connection_pool\"][\"available\"]\n    }\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#step-6-cli-management","title":"Step 6: CLI Management","text":"<p>Use YokedCache CLI for cache management:</p> <pre><code># Monitor cache performance\nyokedcache stats --watch\n\n# Export metrics to CSV\nyokedcache stats --format csv --output cache_metrics.csv\n\n# Search cached data\nyokedcache search \"user data\" --method vector --threshold 0.5\n\n# Flush specific cache tags\nyokedcache flush --tags \"user_data,product_cache\"\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/fastapi-redis-caching/#1-cache-key-strategy","title":"1. Cache Key Strategy","text":"<pre><code># Use consistent, hierarchical keys\ncache_key = f\"user:{user_id}:profile\"\ncache_key = f\"product:{category}:{product_id}\"\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#2-ttl-configuration","title":"2. TTL Configuration","text":"<pre><code># Different TTL for different data types\nuser_cache_ttl = 3600      # 1 hour for user data\nproduct_cache_ttl = 7200   # 2 hours for product data\nsearch_cache_ttl = 1800    # 30 minutes for search results\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#3-error-handling","title":"3. Error Handling","text":"<pre><code>try:\n    cached_data = await cache.get(cache_key)\n    if cached_data is None:\n        # Cache miss - fetch from database\n        data = await fetch_from_database()\n        await cache.set(cache_key, data, ttl=3600)\n        return data\n    return cached_data\nexcept Exception as e:\n    # Log error and fallback to database\n    logger.error(f\"Cache error: {e}\")\n    return await fetch_from_database()\n</code></pre>"},{"location":"tutorials/fastapi-redis-caching/#performance-results","title":"Performance Results","text":"<p>With YokedCache implementation:</p> <ul> <li>Database Load: 60-90% reduction</li> <li>API Response Time: 200-500ms improvement</li> <li>Memory Efficiency: Optimized serialization</li> <li>Reliability: 99.9% uptime with circuit breaker</li> </ul>"},{"location":"tutorials/fastapi-redis-caching/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Vector Search Caching</li> <li>Learn about Production Monitoring</li> <li>Check out Advanced Configuration</li> <li>Read the Performance Guide</li> </ul>"},{"location":"tutorials/fastapi/","title":"Tutorial: FastAPI Integration","text":"<p>Learn how to integrate YokedCache with FastAPI applications for high-performance caching with automatic invalidation.</p>"},{"location":"tutorials/fastapi/#what-youll-build","title":"What You'll Build","text":"<p>By the end of this tutorial, you'll have a FastAPI application with: - Cached database queries that dramatically improve response times - Automatic cache invalidation when data changes - Real-time monitoring and statistics - Production-ready error handling</p>"},{"location":"tutorials/fastapi/#prerequisites","title":"Prerequisites","text":"<pre><code># Install dependencies\npip install yokedcache[full] fastapi uvicorn sqlalchemy psycopg2-binary\n\n# Start Redis (using Docker)\ndocker run -d --name redis -p 6379:6379 redis:7\n</code></pre>"},{"location":"tutorials/fastapi/#step-1-basic-fastapi-setup","title":"Step 1: Basic FastAPI Setup","text":"<p>Create a simple FastAPI application with a database:</p> <pre><code># app.py\nfrom fastapi import FastAPI, Depends, HTTPException\nfrom sqlalchemy import create_engine, Column, Integer, String, DateTime, Boolean\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session\nfrom datetime import datetime\nfrom typing import Optional\nimport os\n\n# Database setup\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///./app.db\")\nengine = create_engine(DATABASE_URL, connect_args={\"check_same_thread\": False} if \"sqlite\" in DATABASE_URL else {})\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\nBase = declarative_base()\n\n# Models\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String, index=True)\n    email = Column(String, unique=True, index=True)\n    active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\nclass Product(Base):\n    __tablename__ = \"products\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String, index=True)\n    description = Column(String)\n    price = Column(Integer)  # Price in cents\n    category = Column(String, index=True)\n    active = Column(Boolean, default=True)\n\nBase.metadata.create_all(bind=engine)\n\n# FastAPI app\napp = FastAPI(title=\"YokedCache FastAPI Tutorial\", version=\"1.0.0\")\n\n# Database dependency\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n# Basic endpoints without caching (we'll improve these)\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db: Session = Depends(get_db)):\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@app.get(\"/products\")\nasync def list_products(category: Optional[str] = None, db: Session = Depends(get_db)):\n    query = db.query(Product).filter(Product.active == True)\n    if category:\n        query = query.filter(Product.category == category)\n    return query.all()\n</code></pre> <p>Test the basic setup: <pre><code>uvicorn app:app --reload --port 8000\ncurl http://localhost:8000/users/1\n</code></pre></p>"},{"location":"tutorials/fastapi/#step-2-add-yokedcache-integration","title":"Step 2: Add YokedCache Integration","text":"<p>Now let's add caching to dramatically improve performance:</p> <pre><code># Add these imports at the top\nfrom yokedcache import YokedCache, cached, cached_dependency\nfrom yokedcache.models import SerializationMethod\nimport asyncio\nimport time\n\n# Initialize cache\ncache = YokedCache()\n\n# Create cached database dependency\ncached_get_db = cached_dependency(\n    get_db,\n    cache=cache,\n    ttl=300,  # 5 minutes default\n    table_name=\"auto_detect\"  # Auto-detect tables from queries\n)\n\n# Add performance timing middleware\n@app.middleware(\"http\")\nasync def add_timing_header(request, call_next):\n    start_time = time.time()\n    response = await call_next(request)\n    process_time = time.time() - start_time\n    response.headers[\"X-Process-Time\"] = str(process_time)\n    return response\n\n# Cached database operations\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db: Session = Depends(cached_get_db)):\n    \"\"\"Get user by ID - cached automatically\"\"\"\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@app.get(\"/users\")\nasync def list_users(\n    active_only: bool = True,\n    limit: int = 100,\n    db: Session = Depends(cached_get_db)\n):\n    \"\"\"List users - cached with different keys based on parameters\"\"\"\n    query = db.query(User)\n    if active_only:\n        query = query.filter(User.active == True)\n    return query.limit(limit).all()\n\n@app.get(\"/products\")\nasync def list_products(\n    category: Optional[str] = None,\n    active_only: bool = True,\n    limit: int = 100,\n    db: Session = Depends(cached_get_db)\n):\n    \"\"\"List products - cached by category and parameters\"\"\"\n    query = db.query(Product)\n    if active_only:\n        query = query.filter(Product.active == True)\n    if category:\n        query = query.filter(Product.category == category)\n    return query.limit(limit).all()\n\n@app.get(\"/products/{product_id}\")\nasync def get_product(product_id: int, db: Session = Depends(cached_get_db)):\n    \"\"\"Get product by ID - cached automatically\"\"\"\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return product\n</code></pre>"},{"location":"tutorials/fastapi/#step-3-add-write-operations-with-auto-invalidation","title":"Step 3: Add Write Operations with Auto-Invalidation","text":"<p>Add endpoints that modify data and automatically invalidate related cache entries:</p> <pre><code>from pydantic import BaseModel\n\n# Request models\nclass UserCreate(BaseModel):\n    name: str\n    email: str\n    active: bool = True\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    active: Optional[bool] = None\n\nclass ProductCreate(BaseModel):\n    name: str\n    description: str\n    price: int\n    category: str\n    active: bool = True\n\nclass ProductUpdate(BaseModel):\n    name: Optional[str] = None\n    description: Optional[str] = None\n    price: Optional[int] = None\n    category: Optional[str] = None\n    active: Optional[bool] = None\n\n# Write operations with automatic cache invalidation\n@app.post(\"/users\", response_model=dict)\nasync def create_user(user: UserCreate, db: Session = Depends(cached_get_db)):\n    \"\"\"Create user - automatically invalidates user cache on commit\"\"\"\n    db_user = User(**user.dict())\n    db.add(db_user)\n    await db.commit()  # This triggers automatic cache invalidation\n    await db.refresh(db_user)\n    return {\"id\": db_user.id, \"message\": \"User created successfully\"}\n\n@app.put(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    user: UserUpdate,\n    db: Session = Depends(cached_get_db)\n):\n    \"\"\"Update user - automatically invalidates user cache on commit\"\"\"\n    db_user = db.query(User).filter(User.id == user_id).first()\n    if not db_user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # Update only provided fields\n    update_data = user.dict(exclude_unset=True)\n    for key, value in update_data.items():\n        setattr(db_user, key, value)\n\n    await db.commit()  # Triggers cache invalidation\n    await db.refresh(db_user)\n    return db_user\n\n@app.delete(\"/users/{user_id}\")\nasync def delete_user(user_id: int, db: Session = Depends(cached_get_db)):\n    \"\"\"Delete user - automatically invalidates user cache on commit\"\"\"\n    db_user = db.query(User).filter(User.id == user_id).first()\n    if not db_user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    db.delete(db_user)\n    await db.commit()  # Triggers cache invalidation\n    return {\"message\": \"User deleted successfully\"}\n\n@app.post(\"/products\")\nasync def create_product(product: ProductCreate, db: Session = Depends(cached_get_db)):\n    \"\"\"Create product - automatically invalidates product cache on commit\"\"\"\n    db_product = Product(**product.dict())\n    db.add(db_product)\n    await db.commit()\n    await db.refresh(db_product)\n    return {\"id\": db_product.id, \"message\": \"Product created successfully\"}\n\n@app.put(\"/products/{product_id}\")\nasync def update_product(\n    product_id: int,\n    product: ProductUpdate,\n    db: Session = Depends(cached_get_db)\n):\n    \"\"\"Update product - automatically invalidates product cache on commit\"\"\"\n    db_product = db.query(Product).filter(Product.id == product_id).first()\n    if not db_product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n\n    update_data = product.dict(exclude_unset=True)\n    for key, value in update_data.items():\n        setattr(db_product, key, value)\n\n    await db.commit()\n    await db.refresh(db_product)\n    return db_product\n</code></pre>"},{"location":"tutorials/fastapi/#step-4-add-cache-management-endpoints","title":"Step 4: Add Cache Management Endpoints","text":"<p>Add endpoints to monitor and manage your cache:</p> <pre><code>@app.get(\"/cache/stats\")\nasync def cache_stats():\n    \"\"\"Get comprehensive cache statistics\"\"\"\n    stats = await cache.get_stats()\n    return {\n        \"hit_rate\": f\"{stats.hit_rate:.2%}\",\n        \"miss_rate\": f\"{stats.miss_rate:.2%}\",\n        \"total_requests\": stats.total_requests,\n        \"cache_hits\": stats.cache_hits,\n        \"cache_misses\": stats.cache_misses,\n        \"total_keys\": stats.key_count,\n        \"memory_usage_mb\": f\"{stats.memory_usage_mb:.2f}\",\n        \"uptime_seconds\": stats.uptime_seconds\n    }\n\n@app.get(\"/cache/health\")\nasync def cache_health():\n    \"\"\"Check cache health\"\"\"\n    health = await cache.health_check()\n    return {\n        \"healthy\": health.is_healthy,\n        \"backend_type\": health.backend_type,\n        \"response_time_ms\": health.response_time_ms,\n        \"details\": health.details\n    }\n\n@app.post(\"/cache/invalidate/users\")\nasync def invalidate_users_cache():\n    \"\"\"Manually invalidate all user-related cache entries\"\"\"\n    await cache.invalidate_tags([\"table:users\"])\n    return {\"message\": \"User cache invalidated\"}\n\n@app.post(\"/cache/invalidate/products\")\nasync def invalidate_products_cache():\n    \"\"\"Manually invalidate all product-related cache entries\"\"\"\n    await cache.invalidate_tags([\"table:products\"])\n    return {\"message\": \"Product cache invalidated\"}\n\n@app.post(\"/cache/invalidate/all\")\nasync def invalidate_all_cache():\n    \"\"\"Clear all cache entries (use with caution!)\"\"\"\n    await cache.flush_all()\n    return {\"message\": \"All cache invalidated\"}\n\n@app.get(\"/cache/keys\")\nasync def list_cache_keys(pattern: Optional[str] = None, limit: int = 100):\n    \"\"\"List cache keys (for debugging)\"\"\"\n    if pattern:\n        keys = await cache.get_keys_by_pattern(pattern, limit=limit)\n    else:\n        keys = await cache.get_all_keys(limit=limit)\n    return {\"keys\": keys, \"count\": len(keys)}\n</code></pre>"},{"location":"tutorials/fastapi/#step-5-add-function-level-caching","title":"Step 5: Add Function-Level Caching","text":"<p>For expensive computations, add function-level caching:</p> <pre><code>@cached(ttl=600, tags=[\"analytics\"])\nasync def calculate_user_analytics(db: Session):\n    \"\"\"Expensive analytics calculation - cached for 10 minutes\"\"\"\n    print(\"Calculating user analytics...\")  # You'll see this only when cache misses\n\n    # Simulate expensive computation\n    await asyncio.sleep(2)\n\n    total_users = db.query(User).count()\n    active_users = db.query(User).filter(User.active == True).count()\n    inactive_users = total_users - active_users\n\n    return {\n        \"total_users\": total_users,\n        \"active_users\": active_users,\n        \"inactive_users\": inactive_users,\n        \"activity_rate\": f\"{(active_users / total_users * 100):.1f}%\" if total_users &gt; 0 else \"0%\",\n        \"calculated_at\": datetime.utcnow().isoformat()\n    }\n\n@cached(ttl=300, tags=[\"analytics\", \"products\"])\nasync def calculate_product_analytics(db: Session, category: Optional[str] = None):\n    \"\"\"Product analytics - cached by category\"\"\"\n    print(f\"Calculating product analytics for category: {category}\")\n\n    await asyncio.sleep(1)  # Simulate expensive computation\n\n    query = db.query(Product)\n    if category:\n        query = query.filter(Product.category == category)\n\n    products = query.all()\n    total_products = len(products)\n    active_products = len([p for p in products if p.active])\n    avg_price = sum(p.price for p in products) / total_products if total_products &gt; 0 else 0\n\n    return {\n        \"category\": category or \"all\",\n        \"total_products\": total_products,\n        \"active_products\": active_products,\n        \"average_price_cents\": int(avg_price),\n        \"average_price_dollars\": f\"${avg_price / 100:.2f}\",\n        \"calculated_at\": datetime.utcnow().isoformat()\n    }\n\n@app.get(\"/analytics/users\")\nasync def get_user_analytics(db: Session = Depends(get_db)):\n    \"\"\"Get user analytics - cached for performance\"\"\"\n    return await calculate_user_analytics(db)\n\n@app.get(\"/analytics/products\")\nasync def get_product_analytics(\n    category: Optional[str] = None,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get product analytics - cached by category\"\"\"\n    return await calculate_product_analytics(db, category)\n</code></pre>"},{"location":"tutorials/fastapi/#step-6-add-production-configuration","title":"Step 6: Add Production Configuration","text":"<p>Create production-ready configuration:</p> <pre><code># config.py\nfrom yokedcache import CacheConfig, TableCacheConfig\nfrom yokedcache.models import SerializationMethod\nimport os\n\ndef get_cache_config():\n    \"\"\"Get cache configuration based on environment\"\"\"\n\n    environment = os.getenv(\"ENVIRONMENT\", \"development\")\n\n    if environment == \"production\":\n        return CacheConfig(\n            redis_url=os.getenv(\"REDIS_URL\", \"redis://localhost:6379/0\"),\n            default_ttl=600,  # 10 minutes default in production\n            key_prefix=f\"myapp_prod\",\n            max_connections=100,\n\n            # Table-specific configurations\n            tables={\n                \"users\": TableCacheConfig(\n                    ttl=3600,  # 1 hour for user data\n                    tags={\"user_data\"},\n                    serialization_method=SerializationMethod.JSON\n                ),\n                \"products\": TableCacheConfig(\n                    ttl=1800,  # 30 minutes for product data\n                    tags={\"product_data\"},\n                    serialization_method=SerializationMethod.JSON\n                )\n            },\n\n            # Enable monitoring\n            enable_metrics=True,\n            log_level=\"WARNING\"\n        )\n\n    elif environment == \"staging\":\n        return CacheConfig(\n            redis_url=os.getenv(\"REDIS_URL\", \"redis://localhost:6379/1\"),\n            default_ttl=300,\n            key_prefix=f\"myapp_staging\",\n            max_connections=50,\n\n            tables={\n                \"users\": TableCacheConfig(ttl=1800, tags={\"user_data\"}),\n                \"products\": TableCacheConfig(ttl=900, tags={\"product_data\"})\n            },\n\n            enable_metrics=True,\n            log_level=\"INFO\"\n        )\n\n    else:  # development\n        return CacheConfig(\n            redis_url=os.getenv(\"REDIS_URL\", \"redis://localhost:6379/2\"),\n            default_ttl=60,  # Short TTL for development\n            key_prefix=f\"myapp_dev\",\n            max_connections=10,\n\n            tables={\n                \"users\": TableCacheConfig(ttl=300, tags={\"user_data\"}),\n                \"products\": TableCacheConfig(ttl=300, tags={\"product_data\"})\n            },\n\n            enable_fuzzy=True,  # Enable fuzzy search in development\n            log_level=\"DEBUG\"\n        )\n\n# Update your app.py\ncache = YokedCache(config=get_cache_config())\n</code></pre>"},{"location":"tutorials/fastapi/#step-7-testing-your-implementation","title":"Step 7: Testing Your Implementation","text":"<p>Create a comprehensive test script:</p> <pre><code># test_cache_performance.py\nimport asyncio\nimport time\nimport httpx\nfrom typing import List\n\nasync def test_cache_performance():\n    \"\"\"Test cache performance improvements\"\"\"\n\n    base_url = \"http://localhost:8000\"\n\n    async with httpx.AsyncClient() as client:\n        # Test 1: Database query performance\n        print(\"Testing cache performance...\")\n\n        # First request (cache miss)\n        start_time = time.time()\n        response = await client.get(f\"{base_url}/users/1\")\n        first_request_time = time.time() - start_time\n        print(f\"First request (cache miss): {first_request_time:.3f}s\")\n\n        # Second request (cache hit)\n        start_time = time.time()\n        response = await client.get(f\"{base_url}/users/1\")\n        second_request_time = time.time() - start_time\n        print(f\"Second request (cache hit): {second_request_time:.3f}s\")\n\n        speedup = first_request_time / second_request_time\n        print(f\"Cache speedup: {speedup:.1f}x faster\")\n\n        # Test 2: Analytics caching\n        print(\"\\nTesting analytics caching...\")\n\n        start_time = time.time()\n        response = await client.get(f\"{base_url}/analytics/users\")\n        first_analytics_time = time.time() - start_time\n        print(f\"First analytics request: {first_analytics_time:.3f}s\")\n\n        start_time = time.time()\n        response = await client.get(f\"{base_url}/analytics/users\")\n        second_analytics_time = time.time() - start_time\n        print(f\"Second analytics request: {second_analytics_time:.3f}s\")\n\n        analytics_speedup = first_analytics_time / second_analytics_time\n        print(f\"Analytics cache speedup: {analytics_speedup:.1f}x faster\")\n\n        # Test 3: Cache invalidation\n        print(\"\\nTesting cache invalidation...\")\n\n        # Create a user\n        await client.post(f\"{base_url}/users\", json={\n            \"name\": \"Test User\",\n            \"email\": \"test@example.com\"\n        })\n\n        # Check cache stats\n        stats_response = await client.get(f\"{base_url}/cache/stats\")\n        stats = stats_response.json()\n        print(f\"Cache hit rate: {stats['hit_rate']}\")\n        print(f\"Total keys: {stats['total_keys']}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(test_cache_performance())\n</code></pre>"},{"location":"tutorials/fastapi/#step-8-monitoring-and-maintenance","title":"Step 8: Monitoring and Maintenance","text":"<p>Add monitoring endpoints and scripts:</p> <pre><code># monitoring.sh\n#!/bin/bash\n\necho \"YokedCache FastAPI Application Monitoring\"\necho \"========================================\"\n\n# Check application health\necho \"Application Health:\"\ncurl -s http://localhost:8000/cache/health | jq .\n\necho -e \"\\nCache Statistics:\"\ncurl -s http://localhost:8000/cache/stats | jq .\n\necho -e \"\\nCache Keys (sample):\"\ncurl -s \"http://localhost:8000/cache/keys?limit=10\" | jq .\n\necho -e \"\\nCLI Statistics:\"\nyokedcache stats --format json | jq .\n</code></pre>"},{"location":"tutorials/fastapi/#running-the-complete-example","title":"Running the Complete Example","text":"<ol> <li> <p>Start Redis: <pre><code>docker run -d --name redis -p 6379:6379 redis:7\n</code></pre></p> </li> <li> <p>Create some test data: <pre><code># seed_data.py\nimport asyncio\nimport httpx\n\nasync def seed_data():\n    async with httpx.AsyncClient() as client:\n        # Create users\n        users = [\n            {\"name\": \"Alice Johnson\", \"email\": \"alice@example.com\"},\n            {\"name\": \"Bob Smith\", \"email\": \"bob@example.com\"},\n            {\"name\": \"Charlie Brown\", \"email\": \"charlie@example.com\"},\n        ]\n\n        for user in users:\n            await client.post(\"http://localhost:8000/users\", json=user)\n\n        # Create products\n        products = [\n            {\"name\": \"Laptop\", \"description\": \"Gaming laptop\", \"price\": 149999, \"category\": \"electronics\"},\n            {\"name\": \"Book\", \"description\": \"Python programming\", \"price\": 2999, \"category\": \"books\"},\n            {\"name\": \"Coffee\", \"description\": \"Premium coffee\", \"price\": 1299, \"category\": \"food\"},\n        ]\n\n        for product in products:\n            await client.post(\"http://localhost:8000/products\", json=product)\n\nasyncio.run(seed_data())\n</code></pre></p> </li> <li> <p>Run the application: <pre><code>uvicorn app:app --reload --port 8000\npython seed_data.py\npython test_cache_performance.py\n</code></pre></p> </li> <li> <p>Monitor with CLI: <pre><code>yokedcache stats --watch\n</code></pre></p> </li> </ol>"},{"location":"tutorials/fastapi/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Automatic Caching: Using <code>cached_dependency</code> automatically caches database queries</li> <li>Auto-Invalidation: Cache entries are automatically cleared when data changes</li> <li>Performance Gains: Typical speedups of 10-100x for cached operations</li> <li>Function Caching: Use <code>@cached</code> decorator for expensive computations</li> <li>Monitoring: Built-in statistics and health checks for production monitoring</li> <li>Configuration: Environment-specific configurations for development, staging, and production</li> </ol> <p>This tutorial demonstrates a production-ready FastAPI application with comprehensive caching. The patterns shown here can be adapted to any FastAPI application for significant performance improvements.</p>"},{"location":"tutorials/sqlalchemy/","title":"Tutorial: SQLAlchemy Integration","text":"<p>Learn how to integrate YokedCache with SQLAlchemy for high-performance database caching with intelligent invalidation patterns.</p>"},{"location":"tutorials/sqlalchemy/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to cache SQLAlchemy queries effectively</li> <li>Different caching patterns for different use cases</li> <li>Automatic cache invalidation on database writes</li> <li>Performance optimization techniques</li> <li>Production-ready patterns</li> </ul>"},{"location":"tutorials/sqlalchemy/#prerequisites","title":"Prerequisites","text":"<pre><code># Install dependencies\npip install yokedcache[full] sqlalchemy psycopg2-binary\n\n# Start Redis\ndocker run -d --name redis -p 6379:6379 redis:7\n</code></pre>"},{"location":"tutorials/sqlalchemy/#basic-sqlalchemy-setup","title":"Basic SQLAlchemy Setup","text":"<p>First, let's create a standard SQLAlchemy setup:</p> <pre><code># models.py\nfrom sqlalchemy import create_engine, Column, Integer, String, DateTime, ForeignKey, Text, Boolean\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, relationship\nfrom datetime import datetime\nimport os\n\n# Database configuration\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///./tutorial.db\")\nengine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\nBase = declarative_base()\n\n# Models\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    username = Column(String(50), unique=True, index=True)\n    email = Column(String(100), unique=True, index=True)\n    full_name = Column(String(100))\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    # Relationships\n    posts = relationship(\"Post\", back_populates=\"author\")\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    title = Column(String(200), index=True)\n    content = Column(Text)\n    published = Column(Boolean, default=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    # Foreign keys\n    author_id = Column(Integer, ForeignKey(\"users.id\"))\n\n    # Relationships\n    author = relationship(\"User\", back_populates=\"posts\")\n\n# Create tables\nBase.metadata.create_all(bind=engine)\n\n# Session factory\ndef get_session():\n    session = SessionLocal()\n    try:\n        yield session\n    finally:\n        session.close()\n</code></pre>"},{"location":"tutorials/sqlalchemy/#pattern-1-function-level-caching","title":"Pattern 1: Function-Level Caching","text":"<p>Cache individual database queries using function decorators:</p> <pre><code># cached_queries.py\nfrom yokedcache import YokedCache, cached\nfrom models import User, Post, get_session\nfrom typing import List, Optional\n\n# Initialize cache\ncache = YokedCache()\n\n@cached(ttl=600, tags=[\"users\"])\nasync def get_user_by_id(user_id: int) -&gt; Optional[dict]:\n    \"\"\"Get user by ID - cached for 10 minutes\"\"\"\n    with next(get_session()) as session:\n        user = session.query(User).filter(User.id == user_id).first()\n        if user:\n            return {\n                \"id\": user.id,\n                \"username\": user.username,\n                \"email\": user.email,\n                \"full_name\": user.full_name,\n                \"is_active\": user.is_active,\n                \"created_at\": user.created_at.isoformat()\n            }\n        return None\n\n@cached(ttl=180, tags=[\"posts\"])\nasync def get_published_posts(limit: int = 10) -&gt; List[dict]:\n    \"\"\"Get published posts - cached for 3 minutes\"\"\"\n    with next(get_session()) as session:\n        posts = (session.query(Post)\n                .filter(Post.published == True)\n                .order_by(Post.created_at.desc())\n                .limit(limit)\n                .all())\n\n        return [{\n            \"id\": post.id,\n            \"title\": post.title,\n            \"content\": post.content[:200] + \"...\" if len(post.content) &gt; 200 else post.content,\n            \"created_at\": post.created_at.isoformat(),\n            \"author\": {\n                \"id\": post.author.id,\n                \"username\": post.author.username,\n                \"full_name\": post.author.full_name\n            }\n        } for post in posts]\n\n@cached(ttl=900, tags=[\"analytics\"])\nasync def get_user_stats() -&gt; dict:\n    \"\"\"Get user statistics - cached for 15 minutes\"\"\"\n    with next(get_session()) as session:\n        total_users = session.query(User).count()\n        active_users = session.query(User).filter(User.is_active == True).count()\n        total_posts = session.query(Post).count()\n        published_posts = session.query(Post).filter(Post.published == True).count()\n\n        return {\n            \"total_users\": total_users,\n            \"active_users\": active_users,\n            \"total_posts\": total_posts,\n            \"published_posts\": published_posts,\n            \"calculated_at\": datetime.utcnow().isoformat()\n        }\n</code></pre>"},{"location":"tutorials/sqlalchemy/#pattern-2-session-level-caching","title":"Pattern 2: Session-Level Caching","text":"<p>Cache at the session level for dependency injection:</p> <pre><code># cached_sessions.py\nfrom yokedcache import cached_dependency\nfrom models import get_session\n\n# Create cached session dependency\ncached_get_session = cached_dependency(\n    get_session,\n    cache=cache,\n    ttl=300,  # 5 minutes default\n    table_name=\"auto_detect\"  # Auto-detect table names from queries\n)\n\n# Table-specific cached sessions\nusers_cached_session = cached_dependency(\n    get_session,\n    cache=cache,\n    ttl=600,  # 10 minutes for user queries\n    table_name=\"users\"\n)\n\nposts_cached_session = cached_dependency(\n    get_session,\n    cache=cache,\n    ttl=180,  # 3 minutes for post queries\n    table_name=\"posts\"\n)\n</code></pre>"},{"location":"tutorials/sqlalchemy/#pattern-3-repository-pattern-with-caching","title":"Pattern 3: Repository Pattern with Caching","text":"<p>Implement the repository pattern with built-in caching:</p> <pre><code># repositories.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any\nfrom yokedcache import cached\nfrom models import User, Post\nfrom sqlalchemy.orm import Session\n\nclass BaseRepository(ABC):\n    def __init__(self, session: Session):\n        self.session = session\n\nclass UserRepository(BaseRepository):\n\n    @cached(ttl=600, tags=[\"users\"])\n    async def get_by_id(self, user_id: int) -&gt; Optional[User]:\n        \"\"\"Get user by ID with caching\"\"\"\n        return self.session.query(User).filter(User.id == user_id).first()\n\n    @cached(ttl=300, tags=[\"users\"])\n    async def get_by_username(self, username: str) -&gt; Optional[User]:\n        \"\"\"Get user by username with caching\"\"\"\n        return self.session.query(User).filter(User.username == username).first()\n\n    @cached(ttl=180, tags=[\"users\"])\n    async def get_active_users(self, limit: int = 50) -&gt; List[User]:\n        \"\"\"Get active users with caching\"\"\"\n        return (self.session.query(User)\n                .filter(User.is_active == True)\n                .limit(limit)\n                .all())\n\n    async def create(self, user_data: Dict[str, Any]) -&gt; User:\n        \"\"\"Create user and invalidate cache\"\"\"\n        user = User(**user_data)\n        self.session.add(user)\n        await self.session.commit()\n\n        # Invalidate user-related cache\n        await cache.invalidate_tags([\"users\"])\n\n        return user\n\nclass PostRepository(BaseRepository):\n\n    @cached(ttl=300, tags=[\"posts\"])\n    async def get_by_id(self, post_id: int) -&gt; Optional[Post]:\n        \"\"\"Get post by ID with caching\"\"\"\n        return self.session.query(Post).filter(Post.id == post_id).first()\n\n    @cached(ttl=180, tags=[\"posts\"])\n    async def get_published(self, limit: int = 10) -&gt; List[Post]:\n        \"\"\"Get published posts with caching\"\"\"\n        return (self.session.query(Post)\n                .filter(Post.published == True)\n                .order_by(Post.created_at.desc())\n                .limit(limit)\n                .all())\n\n    async def create(self, post_data: Dict[str, Any]) -&gt; Post:\n        \"\"\"Create post and invalidate cache\"\"\"\n        post = Post(**post_data)\n        self.session.add(post)\n        await self.session.commit()\n\n        # Invalidate post-related cache\n        await cache.invalidate_tags([\"posts\"])\n\n        return post\n</code></pre>"},{"location":"tutorials/sqlalchemy/#cache-warming-strategies","title":"Cache Warming Strategies","text":"<p>Implement cache warming for frequently accessed data:</p> <pre><code># cache_warming.py\nimport asyncio\nfrom cached_queries import *\n\nasync def warm_user_cache(user_ids: List[int]):\n    \"\"\"Warm cache for specific users\"\"\"\n    print(f\"Warming cache for {len(user_ids)} users...\")\n\n    tasks = []\n    for user_id in user_ids:\n        tasks.append(get_user_by_id(user_id))\n\n    await asyncio.gather(*tasks)\n    print(\"User cache warmed successfully\")\n\nasync def warm_popular_content():\n    \"\"\"Warm cache for popular content\"\"\"\n    print(\"Warming popular content cache...\")\n\n    # Warm popular posts\n    await get_published_posts(limit=20)\n\n    # Warm user statistics\n    await get_user_stats()\n\n    print(\"Popular content cache warmed successfully\")\n\nasync def full_cache_warm():\n    \"\"\"Perform full cache warming\"\"\"\n    print(\"Starting full cache warming...\")\n\n    # Warm user cache for first 50 users\n    user_ids = list(range(1, 51))\n    await warm_user_cache(user_ids)\n\n    # Warm popular content\n    await warm_popular_content()\n\n    print(\"Full cache warming completed\")\n</code></pre>"},{"location":"tutorials/sqlalchemy/#performance-monitoring","title":"Performance Monitoring","text":"<p>Monitor cache performance and database query patterns:</p> <pre><code># monitoring.py\nimport time\nimport asyncio\nfrom contextlib import asynccontextmanager\n\nclass QueryPerformanceMonitor:\n    def __init__(self):\n        self.query_stats = {}\n\n    @asynccontextmanager\n    async def monitor_query(self, query_name: str):\n        \"\"\"Context manager to monitor query performance\"\"\"\n        start_time = time.time()\n\n        try:\n            yield\n        finally:\n            end_time = time.time()\n            execution_time = end_time - start_time\n\n            if query_name not in self.query_stats:\n                self.query_stats[query_name] = {\n                    \"total_calls\": 0,\n                    \"total_time\": 0,\n                    \"avg_time\": 0\n                }\n\n            stats = self.query_stats[query_name]\n            stats[\"total_calls\"] += 1\n            stats[\"total_time\"] += execution_time\n            stats[\"avg_time\"] = stats[\"total_time\"] / stats[\"total_calls\"]\n\n    def get_stats(self):\n        \"\"\"Get performance statistics\"\"\"\n        return self.query_stats\n\n# Global monitor instance\nmonitor = QueryPerformanceMonitor()\n\nasync def performance_test():\n    \"\"\"Test cache performance vs database performance\"\"\"\n    print(\"Running performance tests...\")\n\n    user_id = 1\n\n    # First call (cache miss)\n    async with monitor.monitor_query(\"cached_user_first_call\"):\n        await get_user_by_id(user_id)\n\n    # Second call (cache hit)\n    async with monitor.monitor_query(\"cached_user_second_call\"):\n        await get_user_by_id(user_id)\n\n    # Print statistics\n    stats = monitor.get_stats()\n    for query_name, query_stats in stats.items():\n        print(f\"{query_name}: {query_stats['avg_time']:.4f}s avg\")\n</code></pre>"},{"location":"tutorials/sqlalchemy/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"tutorials/sqlalchemy/#1-cache-ttl-strategy","title":"1. Cache TTL Strategy","text":"<ul> <li>Hot data (frequently changing): 30-300 seconds</li> <li>Warm data (occasionally changing): 300-1800 seconds</li> <li>Cold data (rarely changing): 1800-3600 seconds</li> <li>Analytics data (expensive to compute): 900-3600 seconds</li> </ul>"},{"location":"tutorials/sqlalchemy/#2-cache-key-design","title":"2. Cache Key Design","text":"<ul> <li>Use descriptive function names for automatic key generation</li> <li>Include all relevant parameters in function signatures</li> <li>Consider using table-specific tags for easier invalidation</li> </ul>"},{"location":"tutorials/sqlalchemy/#3-invalidation-strategy","title":"3. Invalidation Strategy","text":"<ul> <li>Use <code>cached_dependency</code> for automatic invalidation on writes</li> <li>Group related data with common tags</li> <li>Implement manual invalidation for complex scenarios</li> </ul>"},{"location":"tutorials/sqlalchemy/#4-performance-optimization","title":"4. Performance Optimization","text":"<ul> <li>Cache expensive queries and computations</li> <li>Monitor cache hit rates and adjust TTL values accordingly</li> <li>Implement cache warming for critical data</li> </ul> <p>This SQLAlchemy integration tutorial demonstrates key patterns for implementing high-performance caching in database-driven applications.</p>"}]}